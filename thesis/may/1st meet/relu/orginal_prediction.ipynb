{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "429_a6BA217K"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install vtk\n",
        "\n",
        "import vtk\n",
        "from vtk.util import numpy_support\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# Load the VTI file\n",
        "reader = vtk.vtkXMLImageDataReader()\n",
        "reader.SetFileName(\"Isabel_3D.vti\")\n",
        "reader.Update()\n",
        "image_data = reader.GetOutput()\n",
        "\n",
        "# Get dimensions and spacing\n",
        "dims = image_data.GetDimensions()\n",
        "spacing = image_data.GetSpacing()\n",
        "origin = image_data.GetOrigin()\n",
        "\n",
        "# Get the scalar data\n",
        "scalars = image_data.GetPointData().GetScalars()\n",
        "scalar_array = numpy_support.vtk_to_numpy(scalars)\n",
        "\n",
        "# Generate (x, y, z) coordinates based on image geometry\n",
        "x_coords = [origin[0] + i * spacing[0] for i in range(dims[0])]\n",
        "y_coords = [origin[1] + j * spacing[1] for j in range(dims[1])]\n",
        "z_coords = [origin[2] + k * spacing[2] for k in range(dims[2])]\n",
        "\n",
        "# Create a full grid of coordinates\n",
        "data = []\n",
        "index = 0\n",
        "for z in z_coords:\n",
        "    for y in y_coords:\n",
        "        for x in x_coords:\n",
        "            value = scalar_array[index]\n",
        "            data.append([x, y, z, value])\n",
        "            index += 1\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data, columns=[\"x\", \"y\", \"z\", \"value\"])\n",
        "# Min-max normalization for inputs (x, y, z) to [0, 1]\n",
        "X = df[[\"x\", \"y\", \"z\"]].values\n",
        "X_min = X.min(axis=0)\n",
        "X_max = X.max(axis=0)\n",
        "X_norm = (X - X_min) / (X_max - X_min)\n",
        "\n",
        "# Min-max normalization for output (value) to [-1, 1]\n",
        "y = df[\"value\"].values.reshape(-1, 1)\n",
        "y_min = y.min()\n",
        "y_max = y.max()\n",
        "y_norm = 2 * (y - y_min) / (y_max - y_min) - 1\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "X_tensor = torch.tensor(X_norm, dtype=torch.float32).to(device)\n",
        "y_tensor = torch.tensor(y_norm, dtype=torch.float32).to(device)\n",
        "\n",
        "# Dataset and Dataloader\n",
        "batch_size = 1024\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#Neural Network\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(3, 50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(50, 50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(50, 50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(50, 50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(50, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Train the model\n",
        "model = NeuralNet().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "epochs = 500\n",
        "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for batch_X, batch_y in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item() * batch_X.size(0)\n",
        "    avg_loss = epoch_loss / len(dataset)\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.6f}\")\n",
        "\n",
        "#Prediction\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(X_tensor).cpu().numpy()\n",
        "\n",
        "# Denormalize predictions back to original scale\n",
        "preds_denorm = 0.5 * (preds + 1) * (y_max - y_min) + y_min\n",
        "# Prepare VTK array\n",
        "vtk_array = numpy_support.numpy_to_vtk(preds_denorm.ravel(), deep=True, array_type=vtk.VTK_FLOAT)\n",
        "vtk_array.SetName(\"PredictedScalar\")\n",
        "# Create new vtkImageData object\n",
        "output_image = vtk.vtkImageData()\n",
        "output_image.SetDimensions(dims)\n",
        "output_image.SetSpacing(spacing)\n",
        "output_image.SetOrigin(origin)\n",
        "output_image.GetPointData().SetScalars(vtk_array)\n",
        "# Write to file\n",
        "writer = vtk.vtkXMLImageDataWriter()\n",
        "writer.SetFileName(\"Isabel_3D_Predicted.vti\")\n",
        "writer.SetInputData(output_image)\n",
        "writer.Write()\n",
        "\n",
        "print(\" Predicted VTI file saved as 'Isabel_3D_Predicted.vti'\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
