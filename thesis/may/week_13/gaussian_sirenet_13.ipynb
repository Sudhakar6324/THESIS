{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10578389,
          "sourceType": "datasetVersion",
          "datasetId": 6546447
        },
        {
          "sourceId": 11041818,
          "sourceType": "datasetVersion",
          "datasetId": 6878023
        },
        {
          "sourceId": 11251078,
          "sourceType": "datasetVersion",
          "datasetId": 7030699
        },
        {
          "sourceId": 11389139,
          "sourceType": "datasetVersion",
          "datasetId": 7132144
        },
        {
          "sourceId": 11421576,
          "sourceType": "datasetVersion",
          "datasetId": 7153051
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import vtk\n",
        "from vtk import *\n",
        "from vtk.util.numpy_support import vtk_to_numpy\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from argparse import Namespace"
      ],
      "metadata": {
        "_uuid": "d33f75d4-5445-4e48-8179-f0c5dd333f79",
        "_cell_guid": "240889c7-74eb-4fd4-a5b1-ec2aead81dac",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:13.755511Z",
          "iopub.execute_input": "2025-05-26T20:25:13.755738Z",
          "iopub.status.idle": "2025-05-26T20:25:19.575599Z",
          "shell.execute_reply.started": "2025-05-26T20:25:13.755716Z",
          "shell.execute_reply": "2025-05-26T20:25:19.574610Z"
        },
        "id": "y_VQm4XFXF8H"
      },
      "outputs": [],
      "execution_count": 78
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters (simulating argparse in a Jupyter Notebook)\n",
        "args = Namespace(\n",
        "    n_neurons=320,\n",
        "    n_layers=6,\n",
        "    epochs=20,  # Required argument: Set the number of epochs\n",
        "    batchsize=512,\n",
        "    lr=0.00005,\n",
        "    no_decay=False,\n",
        "    decay_rate=0.8,\n",
        "    decay_at_interval=True,\n",
        "    decay_interval=15,\n",
        "    file_name=\"\",\n",
        "    datapath='/content/downsampled_Gaussian.vti',  # Required: Set the path to your data\n",
        "    outpath='./models/',\n",
        "    exp_path='../logs/',\n",
        "    modified_data_path='./data/',\n",
        "    dataset_name='3d_data',  # Required: Set the dataset name\n",
        "    vti_name='gmm_predicted.vti',  # Required: Name of the dataset\n",
        "    vti_path='./data/'\n",
        "\n",
        ")\n",
        "\n",
        "print(args, end='\\n\\n')\n",
        "\n",
        "# Assigning parameters to variables\n",
        "LR = args.lr\n",
        "BATCH_SIZE = args.batchsize\n",
        "decay_rate = args.decay_rate\n",
        "decay_at_equal_interval = args.decay_at_interval\n",
        "\n",
        "decay = not args.no_decay\n",
        "MAX_EPOCH = args.epochs\n",
        "\n",
        "n_neurons = args.n_neurons\n",
        "n_layers = args.n_layers + 2\n",
        "decay_interval = args.decay_interval\n",
        "outpath = args.outpath\n",
        "exp_path = args.exp_path\n",
        "datapath = args.datapath\n",
        "modified_data_path = args.modified_data_path\n",
        "dataset_name = args.dataset_name\n",
        "vti_name = args.file_name+args.vti_name\n",
        "vti_path = args.vti_path\n",
        "\n",
        "# Displaying the final configuration\n",
        "print(f\"Learning Rate: {LR}\", flush=True)\n",
        "print(f\"Batch Size: {BATCH_SIZE}\", flush=True)\n",
        "print(f\"Decay Rate: {decay_rate}\", flush=True)\n",
        "print(f\"Max Epochs: {MAX_EPOCH}\", flush=True)\n",
        "print(f\"Number of Neurons per Layer: {n_neurons}\", flush=True)\n",
        "print(f\"Number of Layers (including input/output): {n_layers}\", flush=True)\n",
        "print(f\"Data Path: {datapath}\", flush=True)\n",
        "print(f\"Output Path: {outpath}\", flush=True)\n",
        "print(f\"Dataset Name: {dataset_name}\", flush=True)\n",
        "print(f\"Vti Name: {vti_name}\", flush=True)"
      ],
      "metadata": {
        "_uuid": "07692dd4-4d61-4352-8b23-bff56509856c",
        "_cell_guid": "4204ef20-76e1-416f-b261-20a979ca06e6",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.781711Z",
          "iopub.execute_input": "2025-05-26T20:25:19.782004Z",
          "iopub.status.idle": "2025-05-26T20:25:19.797158Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.781976Z",
          "shell.execute_reply": "2025-05-26T20:25:19.796521Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16HbUm7oXF8P",
        "outputId": "43c8fa0e-ac09-4841-f27a-66f825fc4b86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(n_neurons=320, n_layers=6, epochs=20, batchsize=512, lr=5e-05, no_decay=False, decay_rate=0.8, decay_at_interval=True, decay_interval=15, file_name='', datapath='/content/downsampled_Gaussian.vti', outpath='./models/', exp_path='../logs/', modified_data_path='./data/', dataset_name='3d_data', vti_name='gmm_predicted.vti', vti_path='./data/')\n",
            "\n",
            "Learning Rate: 5e-05\n",
            "Batch Size: 512\n",
            "Decay Rate: 0.8\n",
            "Max Epochs: 20\n",
            "Number of Neurons per Layer: 320\n",
            "Number of Layers (including input/output): 8\n",
            "Data Path: /content/downsampled_Gaussian.vti\n",
            "Output Path: ./models/\n",
            "Dataset Name: 3d_data\n",
            "Vti Name: gmm_predicted.vti\n"
          ]
        }
      ],
      "execution_count": 79
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print('Device running:', device)"
      ],
      "metadata": {
        "_uuid": "43d958cf-562d-4fb8-9670-43075fd82174",
        "_cell_guid": "bda30f3b-5c85-404f-8cdc-861e65b7ae69",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.576562Z",
          "iopub.execute_input": "2025-05-26T20:25:19.576994Z",
          "iopub.status.idle": "2025-05-26T20:25:19.654026Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.576972Z",
          "shell.execute_reply": "2025-05-26T20:25:19.653204Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Te7puuMtXF8K",
        "outputId": "9e3439b6-511d-422c-eaf7-e878a20598a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device running: cuda\n"
          ]
        }
      ],
      "execution_count": 80
    },
    {
      "cell_type": "code",
      "source": [
        "class SineLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, bias=True, is_first=False, omega_0=30):\n",
        "        super().__init__()\n",
        "        self.omega_0 = omega_0\n",
        "        self.is_first = is_first\n",
        "        # self.enable_dropout = enable_dropout\n",
        "        # self.dropout_prob = dropout_prob\n",
        "        self.in_features = in_features\n",
        "        # if enable_dropout:\n",
        "        #     if not self.is_first:\n",
        "        #         self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        with torch.no_grad():\n",
        "            if self.is_first:\n",
        "                self.linear.weight.uniform_(-1 / self.in_features,\n",
        "                                             1 / self.in_features)\n",
        "            else:\n",
        "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0,\n",
        "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        # if self.enable_dropout:\n",
        "        #     if not self.is_first:\n",
        "        #         x = self.dropout(x)\n",
        "        return torch.sin(self.omega_0 * x)"
      ],
      "metadata": {
        "_uuid": "c6d00f8a-3e62-40d1-81e8-b30fd44e994f",
        "_cell_guid": "47639dbe-7c29-4716-ad12-c245edbd4925",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.654942Z",
          "iopub.execute_input": "2025-05-26T20:25:19.655223Z",
          "iopub.status.idle": "2025-05-26T20:25:19.667030Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.655199Z",
          "shell.execute_reply": "2025-05-26T20:25:19.666295Z"
        },
        "id": "Ii_muljZXF8K"
      },
      "outputs": [],
      "execution_count": 81
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualSineLayer(nn.Module):\n",
        "    def __init__(self, features, bias=True, ave_first=False, ave_second=False, omega_0=30):\n",
        "        super().__init__()\n",
        "        self.omega_0 = omega_0\n",
        "        # self.enable_dropout = enable_dropout\n",
        "        # self.dropout_prob = dropout_prob\n",
        "        self.features = features\n",
        "        # if enable_dropout:\n",
        "        #     self.dropout_1 = nn.Dropout(dropout_prob)\n",
        "        self.linear_1 = nn.Linear(features, features, bias=bias)\n",
        "        self.linear_2 = nn.Linear(features, features, bias=bias)\n",
        "        self.weight_1 = .5 if ave_first else 1\n",
        "        self.weight_2 = .5 if ave_second else 1\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "\n",
        "    def init_weights(self):\n",
        "        with torch.no_grad():\n",
        "            self.linear_1.weight.uniform_(-np.sqrt(6 / self.features) / self.omega_0,\n",
        "                                           np.sqrt(6 / self.features) / self.omega_0)\n",
        "            self.linear_2.weight.uniform_(-np.sqrt(6 / self.features) / self.omega_0,\n",
        "                                           np.sqrt(6 / self.features) / self.omega_0)\n",
        "\n",
        "    def forward(self, input):\n",
        "        linear_1 = self.linear_1(self.weight_1*input)\n",
        "        # if self.enable_dropout:\n",
        "        #     linear_1 = self.dropout_1(linear_1)\n",
        "        sine_1 = torch.sin(self.omega_0 * linear_1)\n",
        "        sine_2 = torch.sin(self.omega_0 * self.linear_2(sine_1))\n",
        "        return self.weight_2*(input+sine_2)"
      ],
      "metadata": {
        "_uuid": "286fbfd2-ba2c-4fbe-8ac6-cfebd4a21e55",
        "_cell_guid": "ef7cdfa6-ccb1-405d-a306-c83170e479b4",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.667767Z",
          "iopub.execute_input": "2025-05-26T20:25:19.668045Z",
          "iopub.status.idle": "2025-05-26T20:25:19.679335Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.668025Z",
          "shell.execute_reply": "2025-05-26T20:25:19.678679Z"
        },
        "id": "UPvBLZe9XF8L"
      },
      "outputs": [],
      "execution_count": 82
    },
    {
      "cell_type": "code",
      "source": [
        "class MyResidualSirenNet(nn.Module):\n",
        "    def __init__(self, obj):\n",
        "        super(MyResidualSirenNet, self).__init__()\n",
        "        # self.enable_dropout = obj['enable_dropout']\n",
        "        # self.dropout_prob = obj['dropout_prob']\n",
        "        self.Omega_0=30\n",
        "        self.n_layers = obj['n_layers']\n",
        "        self.input_dim = obj['dim']\n",
        "        self.output_dim = obj['total_vars']\n",
        "        self.neurons_per_layer = obj['n_neurons']\n",
        "        self.layers = [self.input_dim]\n",
        "        for i in range(self.n_layers-1):\n",
        "            self.layers.append(self.neurons_per_layer)\n",
        "        self.layers.append(self.output_dim)\n",
        "        self.net_layers = nn.ModuleList()\n",
        "        for idx in np.arange(self.n_layers):\n",
        "            layer_in = self.layers[idx]\n",
        "            layer_out = self.layers[idx+1]\n",
        "            ## if not the final layer\n",
        "            if idx != self.n_layers-1:\n",
        "                ## if first layer\n",
        "                if idx==0:\n",
        "                    self.net_layers.append(SineLayer(layer_in,layer_out,bias=True,is_first=idx==0))\n",
        "                ## if an intermdeiate layer\n",
        "                else:\n",
        "                    self.net_layers.append(ResidualSineLayer(layer_in,bias=True,ave_first=idx>1,ave_second=idx==(self.n_layers-2)))\n",
        "            ## if final layer\n",
        "            else:\n",
        "                final_linear = nn.Linear(layer_in,layer_out)\n",
        "                ## initialize weights for the final layer\n",
        "                with torch.no_grad():\n",
        "                    final_linear.weight.uniform_(-np.sqrt(6 / (layer_in)) / self.Omega_0, np.sqrt(6 / (layer_in)) / self.Omega_0)\n",
        "                self.net_layers.append(final_linear)\n",
        "\n",
        "    def forward(self,x):\n",
        "        for net_layer in self.net_layers:\n",
        "            x = net_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "_uuid": "e1400ad9-b3ed-49fc-81e0-929816a0aaf2",
        "_cell_guid": "807361ca-2c71-4799-83d0-2da9ccf9fac0",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.680067Z",
          "iopub.execute_input": "2025-05-26T20:25:19.680289Z",
          "iopub.status.idle": "2025-05-26T20:25:19.693684Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.680270Z",
          "shell.execute_reply": "2025-05-26T20:25:19.693049Z"
        },
        "id": "sgqfUsDBXF8L"
      },
      "outputs": [],
      "execution_count": 83
    },
    {
      "cell_type": "code",
      "source": [
        "def size_of_network(n_layers, n_neurons, d_in, d_out, is_residual = True):\n",
        "    # Adding input layer\n",
        "    layers = [d_in]\n",
        "    # layers = [3]\n",
        "\n",
        "    # Adding hidden layers\n",
        "    layers.extend([n_neurons]*n_layers)\n",
        "    # layers = [3, 5, 5, 5]\n",
        "\n",
        "    # Adding output layer\n",
        "    layers.append(d_out)\n",
        "    # layers = [3, 5, 5, 5, 1]\n",
        "\n",
        "    # Number of steps\n",
        "    n_layers = len(layers)-1\n",
        "    # n_layers = 5 - 1 = 4\n",
        "\n",
        "    n_params = 0\n",
        "\n",
        "    # np.arange(4) = [0, 1, 2, 3]\n",
        "    for ndx in np.arange(n_layers):\n",
        "\n",
        "        # number of neurons in below layer\n",
        "        layer_in = layers[ndx]\n",
        "\n",
        "        # number of neurons in above layer\n",
        "        layer_out = layers[ndx+1]\n",
        "\n",
        "        # max number of neurons in both the layer\n",
        "        og_layer_in = max(layer_in,layer_out)\n",
        "\n",
        "        # if lower layer is the input layer\n",
        "        # or the upper layer is the output layer\n",
        "        if ndx==0 or ndx==(n_layers-1):\n",
        "            # Adding weight corresponding to every neuron for every input neuron\n",
        "            # Adding bias for every neuron in the upper layer\n",
        "            n_params += ((layer_in+1)*layer_out)\n",
        "\n",
        "        else:\n",
        "\n",
        "            # If the layer is residual then proceed as follows as there will be more weights if residual layer is included\n",
        "            if is_residual:\n",
        "                # doubt in the following two lines\n",
        "                n_params += (layer_in*og_layer_in)+og_layer_in\n",
        "                n_params += (og_layer_in*layer_out)+layer_out\n",
        "\n",
        "            # if the layer is non residual then simply add number of weights and biases as follows\n",
        "            else:\n",
        "                n_params += ((layer_in+1)*layer_out)\n",
        "            #\n",
        "        #\n",
        "    #\n",
        "\n",
        "    return n_params"
      ],
      "metadata": {
        "_uuid": "49e23bf9-3de6-417b-8de1-53aaf02fd323",
        "_cell_guid": "7342b7cd-612f-4c56-ad94-ecd81203519a",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.695847Z",
          "iopub.execute_input": "2025-05-26T20:25:19.696059Z",
          "iopub.status.idle": "2025-05-26T20:25:19.707241Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.696041Z",
          "shell.execute_reply": "2025-05-26T20:25:19.706562Z"
        },
        "id": "UX18e90QXF8M"
      },
      "outputs": [],
      "execution_count": 84
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_PSNR(arrgt,arr_recon):\n",
        "    diff = arrgt - arr_recon\n",
        "    sqd_max_diff = (np.max(arrgt)-np.min(arrgt))**2\n",
        "    snr = 10*np.log10(sqd_max_diff/np.mean(diff**2))\n",
        "    return snr"
      ],
      "metadata": {
        "_uuid": "4bee2b5f-d501-4d1c-b226-410b2624c2d5",
        "_cell_guid": "c8d04a55-6de3-4520-9cf7-45a568420b31",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.708470Z",
          "iopub.execute_input": "2025-05-26T20:25:19.708697Z",
          "iopub.status.idle": "2025-05-26T20:25:19.720894Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.708678Z",
          "shell.execute_reply": "2025-05-26T20:25:19.720185Z"
        },
        "id": "9RvmW787XF8M"
      },
      "outputs": [],
      "execution_count": 85
    },
    {
      "cell_type": "code",
      "source": [
        "def srs(numOfPoints, valid_pts, percentage, isMaskPresent, mask_array):\n",
        "\n",
        "    # getting total number of sampled points\n",
        "    numberOfSampledPoints = int((valid_pts/100) * percentage)\n",
        "\n",
        "    # storing corner indices in indices variable\n",
        "    indices = set()\n",
        "\n",
        "    # As long as we don't get the required amount of sample points keep finding the random numbers\n",
        "    while(len(indices) < numberOfSampledPoints):\n",
        "        rp = random.randint(0, numOfPoints-1)\n",
        "        if isMaskPresent and mask_array[rp] == 0:\n",
        "            continue\n",
        "        indices.add(rp)\n",
        "\n",
        "    # return indices\n",
        "    return indices"
      ],
      "metadata": {
        "_uuid": "9b219fbe-1596-4e3b-a0a7-6eb88db2f52d",
        "_cell_guid": "415f4118-71de-4504-b39f-a7bd40cdcc02",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.721825Z",
          "iopub.execute_input": "2025-05-26T20:25:19.722096Z",
          "iopub.status.idle": "2025-05-26T20:25:19.732038Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.722064Z",
          "shell.execute_reply": "2025-05-26T20:25:19.731249Z"
        },
        "id": "SGawqet4XF8N"
      },
      "outputs": [],
      "execution_count": 86
    },
    {
      "cell_type": "code",
      "source": [
        "def findMultiVariatePSNR(var_name, total_vars, actual, pred):\n",
        "    # print('Printing PSNR')\n",
        "    tot = 0\n",
        "    psnr_list = []\n",
        "    for j in range(total_vars):\n",
        "        psnr = compute_PSNR(actual[:,j], pred[:,j])\n",
        "        psnr_list.append(psnr)\n",
        "        tot += psnr\n",
        "        print(var_name[j], ' PSNR:', psnr,flush=True)\n",
        "    avg_psnr = tot/total_vars\n",
        "    print('\\nAverage psnr : ', avg_psnr,flush=True)\n",
        "     #this function is calculating the psnr of final epoch (or whenever it is called) of each variable and then averaging it\n",
        "     #Thus individual epochs psnr is not calculated\n",
        "\n",
        "    return psnr_list, avg_psnr"
      ],
      "metadata": {
        "_uuid": "964befc2-020d-46d4-bd1b-ef061a65b9e8",
        "_cell_guid": "c20e48d5-ebad-408b-b564-627ba81d02f9",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.732800Z",
          "iopub.execute_input": "2025-05-26T20:25:19.733052Z",
          "iopub.status.idle": "2025-05-26T20:25:19.745670Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.733032Z",
          "shell.execute_reply": "2025-05-26T20:25:19.744868Z"
        },
        "id": "VOC2Z6bgXF8N"
      },
      "outputs": [],
      "execution_count": 87
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_rmse(actual, predicted):\n",
        "    mse = np.mean((actual - predicted) ** 2)\n",
        "    return np.sqrt(mse)\n",
        "\n",
        "def denormalizeValue(total_vars, to, ref):\n",
        "    to_arr = np.array(to)\n",
        "    for i in range(total_vars):\n",
        "        min_data = np.min(ref[:, i])\n",
        "        max_data = np.max(ref[:, i])\n",
        "        to_arr[:, i] = (((to[:, i] * 0.5) + 0.5) * (max_data - min_data)) + min_data\n",
        "    return to_arr"
      ],
      "metadata": {
        "_uuid": "2face64a-1559-415e-9527-5a581fab1db5",
        "_cell_guid": "716ccaed-b6c8-4cc4-83a6-643495093c02",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.746505Z",
          "iopub.execute_input": "2025-05-26T20:25:19.746788Z",
          "iopub.status.idle": "2025-05-26T20:25:19.755298Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.746760Z",
          "shell.execute_reply": "2025-05-26T20:25:19.754436Z"
        },
        "id": "y1WNMImEXF8O"
      },
      "outputs": [],
      "execution_count": 88
    },
    {
      "cell_type": "code",
      "source": [
        "def makeVTI(data, val, n_predictions, n_pts, total_vars, var_name, dim, isMaskPresent, mask_arr, vti_path, vti_name, normalizedVersion = False):\n",
        "    nn_predictions = denormalizeValue(total_vars, n_predictions, val) if not normalizedVersion else n_predictions\n",
        "    writer = vtkXMLImageDataWriter()\n",
        "    writer.SetFileName(vti_path + vti_name)\n",
        "    img = vtkImageData()\n",
        "    img.CopyStructure(data)\n",
        "    if not isMaskPresent:\n",
        "        for i in range(total_vars):\n",
        "            f = var_name[i]\n",
        "            temp = nn_predictions[:, i]\n",
        "            arr = vtkFloatArray()\n",
        "            for j in range(n_pts):\n",
        "                arr.InsertNextValue(temp[j])\n",
        "            arr.SetName(f)\n",
        "            img.GetPointData().AddArray(arr)\n",
        "        # print(img)\n",
        "        writer.SetInputData(img)\n",
        "        writer.Write()\n",
        "        print(f'Vti File written successfully at {vti_path}{vti_name}',flush=True)\n",
        "    else:\n",
        "        for i in range(total_vars):\n",
        "            f = var_name[i]\n",
        "            temp = nn_predictions[:, i]\n",
        "            idx = 0\n",
        "            arr = vtkFloatArray()\n",
        "            for j in range(n_pts):\n",
        "                if(mask_arr[j] == 1):\n",
        "                    arr.InsertNextValue(temp[idx])\n",
        "                    idx += 1\n",
        "                else:\n",
        "                    arr.InsertNextValue(0.0)\n",
        "            arr.SetName('p_' + f)\n",
        "            data.GetPointData().AddArray(arr)\n",
        "        # print(data)\n",
        "        writer.SetInputData(data)\n",
        "        writer.Write()\n",
        "        print(f'Vti File written successfully at {vti_path}{vti_name}')"
      ],
      "metadata": {
        "_uuid": "88d4128a-9484-48bb-b8cd-21abe4801eb1",
        "_cell_guid": "4d173df2-a1ab-442d-8eeb-bd0f1e71b9ee",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.756183Z",
          "iopub.execute_input": "2025-05-26T20:25:19.756430Z",
          "iopub.status.idle": "2025-05-26T20:25:19.768524Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.756410Z",
          "shell.execute_reply": "2025-05-26T20:25:19.767693Z"
        },
        "id": "uFd63SqWXF8O"
      },
      "outputs": [],
      "execution_count": 89
    },
    {
      "cell_type": "code",
      "source": [
        "def getImageData(actual_img, val, n_pts, var_name, isMaskPresent, mask_arr):\n",
        "    img = vtkImageData()\n",
        "    img.CopyStructure(actual_img)\n",
        "    # if isMaskPresent:\n",
        "    #     img.DeepCopy(actual_img)\n",
        "    # img.SetDimensions(dim)\n",
        "    # img.SetOrigin(actual_img.GetOrigin())\n",
        "    # img.SetSpacing(actual_img.GetSpacing())\n",
        "    if not isMaskPresent:\n",
        "        f = var_name\n",
        "        data = val\n",
        "        arr = vtkFloatArray()\n",
        "        for j in range(n_pts):\n",
        "            arr.InsertNextValue(data[j])\n",
        "        arr.SetName(f)\n",
        "        img.GetPointData().SetScalars(arr)\n",
        "    else:\n",
        "        f = var_name\n",
        "        data = val\n",
        "        idx = 0\n",
        "        arr = vtkFloatArray()\n",
        "        for j in range(n_pts):\n",
        "            if(mask_arr[j] == 1):\n",
        "                arr.InsertNextValue(data[idx])\n",
        "                idx += 1\n",
        "            else:\n",
        "                arr.InsertNextValue(0.0)\n",
        "        arr.SetName(f)\n",
        "        img.GetPointData().SetScalars(arr)\n",
        "    return img"
      ],
      "metadata": {
        "_uuid": "99a2cbb5-4737-4a6d-b398-c37e117de5a7",
        "_cell_guid": "7042e60f-eafc-446d-87ab-ec4298dd9276",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.769381Z",
          "iopub.execute_input": "2025-05-26T20:25:19.769639Z",
          "iopub.status.idle": "2025-05-26T20:25:19.780625Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.769609Z",
          "shell.execute_reply": "2025-05-26T20:25:19.779903Z"
        },
        "id": "LjbKmuEwXF8O"
      },
      "outputs": [],
      "execution_count": 90
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable Initialization\n",
        "var_name = []\n",
        "total_vars = None  # Number of variables\n",
        "univariate = None  # True if dataset has one variable, else False\n",
        "group_size = 5000  # Group size during testing"
      ],
      "metadata": {
        "_uuid": "844184e9-6479-45d0-8d31-b1d3a9a4a116",
        "_cell_guid": "cd516584-ec76-4358-888f-79e1116c82d2",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.797890Z",
          "iopub.execute_input": "2025-05-26T20:25:19.798155Z",
          "iopub.status.idle": "2025-05-26T20:25:19.810981Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.798129Z",
          "shell.execute_reply": "2025-05-26T20:25:19.810268Z"
        },
        "id": "Vmw7EqtiXF8P"
      },
      "outputs": [],
      "execution_count": 91
    },
    {
      "cell_type": "code",
      "source": [
        "n_pts = None  # Number of points in the dataset\n",
        "n_dim = None  # Dimensionality of the data\n",
        "dim = None  # Other dimension-specific information\n",
        "\n",
        "print(\"Decay:\", decay,flush=True)\n",
        "print(f'Extracting variables from path: {datapath}', end=\"\\n\\n\",flush=True)\n",
        "\n",
        "# Placeholder for data\n",
        "data_array = []\n",
        "scalar_data = None"
      ],
      "metadata": {
        "_uuid": "bc8c0631-eaaf-4af9-acb9-35bd7467277a",
        "_cell_guid": "c45f69dd-0524-4855-a64e-801e6bfb5765",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.811760Z",
          "iopub.execute_input": "2025-05-26T20:25:19.812043Z",
          "iopub.status.idle": "2025-05-26T20:25:19.825096Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.812017Z",
          "shell.execute_reply": "2025-05-26T20:25:19.824332Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxEtA-lEXF8Q",
        "outputId": "10fe350f-c2bc-47d6-9d2a-a79ffab4a7fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decay: True\n",
            "Extracting variables from path: /content/downsampled_Gaussian.vti\n",
            "\n"
          ]
        }
      ],
      "execution_count": 92
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading values from .vti files\n",
        "reader = vtk.vtkXMLImageDataReader()\n",
        "reader.SetFileName(datapath)\n",
        "reader.Update()\n",
        "\n",
        "data = reader.GetOutput()\n",
        "scalar_data = data\n",
        "pdata = data.GetPointData()\n",
        "n_pts = data.GetNumberOfPoints()\n",
        "dim = data.GetDimensions()\n",
        "n_dim = len(dim)\n",
        "total_arr = pdata.GetNumberOfArrays()\n",
        "\n",
        "print(\"n_pts:\", n_pts, \"dim:\", dim, \"n_dim:\", n_dim, \"total_arr:\", total_arr,flush=True)\n",
        "\n",
        "var_name = []\n",
        "data_array = []\n",
        "\n",
        "# Extracting data from the .vti file\n",
        "for i in range(total_arr):\n",
        "    a_name = pdata.GetArrayName(i)\n",
        "\n",
        "    cur_arr = pdata.GetArray(a_name)\n",
        "    n_components = cur_arr.GetNumberOfComponents()\n",
        "\n",
        "    if n_components == 1:\n",
        "        var_name.append(a_name)\n",
        "        data_array.append(vtk_to_numpy(cur_arr))\n",
        "    else:\n",
        "        component_names = [f\"{a_name}_{c}\" for c in ['x', 'y', 'z'][:n_components]]\n",
        "        var_name.extend(component_names)\n",
        "        for c in range(n_components):\n",
        "            c_data = [cur_arr.GetComponent(j, c) for j in range(n_pts)]\n",
        "            data_array.append(np.array(c_data))\n",
        "\n",
        "total_vars = len(var_name)\n",
        "univariate = total_vars == 1\n",
        "\n",
        "# Prepare numpy arrays for coordinates and variable values\n",
        "cord = np.zeros((n_pts, n_dim))\n",
        "val = np.zeros((n_pts, total_vars))\n",
        "\n",
        "# Store data in numpy arrays\n",
        "for i in range(n_pts):\n",
        "    pt = scalar_data.GetPoint(i)\n",
        "    cord[i, :] = pt\n",
        "    val[i, :] = [arr[i] for arr in data_array]\n",
        "\n",
        "# Display final information\n",
        "print(\"Total Variables:\", total_vars, flush=True)\n",
        "print(\"Univariate:\", univariate, flush=True)\n",
        "print(\"Coordinates Shape:\", cord.shape, flush=True)\n",
        "print(\"Values Shape:\", val.shape, flush=True)"
      ],
      "metadata": {
        "_uuid": "01428998-749b-433d-8d00-0ad9ac906055",
        "_cell_guid": "2f13ab5d-71b7-4829-8d28-4a08f4f9a1cf",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.825827Z",
          "iopub.execute_input": "2025-05-26T20:25:19.826013Z",
          "iopub.status.idle": "2025-05-26T20:25:21.280626Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.825996Z",
          "shell.execute_reply": "2025-05-26T20:25:21.279633Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddYuEPn6XF8Q",
        "outputId": "bd388e33-7397-41ca-f045-4b56f472f1dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_pts: 512 dim: (8, 8, 8) n_dim: 3 total_arr: 2\n",
            "Total Variables: 2\n",
            "Univariate: False\n",
            "Coordinates Shape: (512, 3)\n",
            "Values Shape: (512, 2)\n"
          ]
        }
      ],
      "execution_count": 93
    },
    {
      "cell_type": "code",
      "source": [
        "real_data=val.copy()\n",
        "# Normalize values between -1 and 1\n",
        "for i in range(total_vars):\n",
        "    min_data = np.min(val[:, i])\n",
        "    max_data = np.max(val[:, i])\n",
        "    # norm_params[var_name[i]] = (min_data, max_data)\n",
        "    val[:, i] = 2.0 * ((val[:, i] - min_data) / (max_data - min_data) - 0.5)\n",
        "\n",
        "# Normalize Coordinates to [-1,1]\n",
        "for i in range(n_dim):\n",
        "    # Use (dim[i]-1] so that coordinates go from 0 to dim[i]-1.\n",
        "    cord[:, i] = 2.0 * (cord[:, i] / (dim[i] - 1) - 0.5)\n",
        "\n",
        "\n",
        "# # Save normalized values and coordinates\n",
        "\n",
        "n_cord = cord.copy()\n",
        "n_val = val.copy()\n",
        "\n",
        "# Convert normalized data to PyTorch tensors\n",
        "torch_coords = torch.from_numpy(n_cord)\n",
        "torch_vals = torch.from_numpy(n_val)\n",
        "\n",
        "# Display dataset details\n",
        "print('Dataset Name:', dataset_name, flush=True)\n",
        "print('Total Variables:', total_vars, flush=True)\n",
        "print('Variables Name:', var_name, end=\"\\n\\n\", flush=True)\n",
        "print('Total Points in Data:', n_pts, flush=True)\n",
        "print('Dimension of the Dataset:', dim, flush=True)\n",
        "print('Number of Dimensions:', n_dim, flush=True)\n",
        "print('Coordinate Tensor Shape:', torch_coords.shape, flush=True)\n",
        "print('Scalar Values Tensor Shape:', torch_vals.shape, flush=True)\n",
        "\n",
        "print('\\n###### Data setup is complete, now starting training ######\\n', flush=True)\n"
      ],
      "metadata": {
        "_uuid": "521f7f9c-9a01-41f9-a149-1d15ff3fd1b8",
        "_cell_guid": "b0cbd8a2-2b80-4d5e-a135-f3c4b8b3c6c2",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:21.281683Z",
          "iopub.execute_input": "2025-05-26T20:25:21.282051Z",
          "iopub.status.idle": "2025-05-26T20:25:21.356747Z",
          "shell.execute_reply.started": "2025-05-26T20:25:21.282027Z",
          "shell.execute_reply": "2025-05-26T20:25:21.356094Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLmT0ZbJXF8R",
        "outputId": "4a65efcb-7f3f-4000-d88c-1a1bbb39162a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Name: 3d_data\n",
            "Total Variables: 2\n",
            "Variables Name: ['Mean', 'Std']\n",
            "\n",
            "Total Points in Data: 512\n",
            "Dimension of the Dataset: (8, 8, 8)\n",
            "Number of Dimensions: 3\n",
            "Coordinate Tensor Shape: torch.Size([512, 3])\n",
            "Scalar Values Tensor Shape: torch.Size([512, 2])\n",
            "\n",
            "###### Data setup is complete, now starting training ######\n",
            "\n"
          ]
        }
      ],
      "execution_count": 94
    },
    {
      "cell_type": "code",
      "source": [
        "# Split targets into two tensors: shape (512, 1) each\n",
        "torch_vals_means = torch_vals[:, 0]\n",
        "torch_vals_stds= torch_vals[:,1]\n",
        "print(torch_vals_means.shape)\n",
        "print(torch_vals_stds.shape)\n",
        "\n",
        "print(torch_coords.shape)\n",
        "\n",
        "# --- 1. Set global seeds ---\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# For deterministic CUDA behavior (slower but reproducible)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# --- 2. Create a generator for DataLoader ---\n",
        "g = torch.Generator()\n",
        "g.manual_seed(SEED)\n",
        "\n",
        "# --- 3. DataLoaders with fixed generator ---\n",
        "train_dataloader_m = DataLoader(\n",
        "    TensorDataset(torch_coords, torch_vals_means),\n",
        "    batch_size=BATCH_SIZE, pin_memory=True, shuffle=True,\n",
        "    num_workers=4, generator=g\n",
        ")\n",
        "\n",
        "train_dataloader_s = DataLoader(\n",
        "    TensorDataset(torch_coords, torch_vals_stds),\n",
        "    batch_size=BATCH_SIZE, pin_memory=True, shuffle=True,\n",
        "    num_workers=4, generator=g\n",
        ")\n",
        "if not os.path.exists(outpath):\n",
        "    os.makedirs(outpath)\n",
        "# Create a function to train one model on one target\n",
        "def train_single_target(target_id, dataloader,obj):\n",
        "    model = MyResidualSirenNet(obj).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR, betas=(0.9, 0.999))\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    train_loss_list = []\n",
        "    best_epoch = -1\n",
        "    best_loss = 1e8\n",
        "\n",
        "    for epoch in tqdm(range(MAX_EPOCH)):\n",
        "        model.train()\n",
        "        temp_loss_list = []\n",
        "        start = time.time()\n",
        "\n",
        "        for X_train, y_train in dataloader:\n",
        "            X_train = X_train.type(torch.float32).to(device)\n",
        "            y_train = y_train.type(torch.float32).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(X_train).squeeze()\n",
        "            loss = criterion(predictions, y_train.squeeze())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            temp_loss_list.append(loss.item())\n",
        "\n",
        "        epoch_loss = np.mean(temp_loss_list)\n",
        "\n",
        "        # Learning rate decay\n",
        "        if decay:\n",
        "            if decay_at_equal_interval:\n",
        "                if epoch >= decay_interval and epoch % decay_interval == 0:\n",
        "                    for param_group in optimizer.param_groups:\n",
        "                        param_group['lr'] *= decay_rate\n",
        "            elif epoch > 0 and epoch_loss > train_loss_list[-1]:\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] *= decay_rate\n",
        "\n",
        "        train_loss_list.append(epoch_loss)\n",
        "        if epoch_loss < best_loss:\n",
        "            best_loss = epoch_loss\n",
        "            best_epoch = epoch + 1\n",
        "            torch.save(\n",
        "                {\"epoch\": best_epoch, \"model_state_dict\": model.state_dict()},\n",
        "                os.path.join(outpath, f'best_model_{target_id}.pth')\n",
        "            )\n",
        "\n",
        "        end = time.time()\n",
        "        print(f\"[Target {target_id}] Epoch {epoch+1}/{MAX_EPOCH} \"\n",
        "              f\"| Loss: {epoch_loss} || LR: {optimizer.param_groups[0]['lr']}\",flush=True)\n",
        "\n",
        "    print(f\"\\n[Target {target_id}] Best Epoch: {best_epoch}, Best Loss: {best_loss:.6f}\\n\",flush=True)\n",
        "obj = {\n",
        "    'total_vars': 1,\n",
        "    'dim': n_dim,\n",
        "    'n_neurons': n_neurons,\n",
        "    'n_layers': n_layers\n",
        "}\n",
        "\n",
        "# Train two separate models\n",
        "mean_id=\"means\"\n",
        "train_single_target(mean_id, train_dataloader_m,obj)\n",
        "std_id=\"std\"\n",
        "train_single_target(std_id, train_dataloader_s,obj)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE1MAOOceZvl",
        "outputId": "705ab08a-d3ac-4594-d8fe-2658a642a457"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 3])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 1/20 | Loss: 0.28799548745155334 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [00:00<00:03,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 2/20 | Loss: 0.16995522379875183 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:00<00:03,  5.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 3/20 | Loss: 0.17227232456207275 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:00<00:02,  6.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 4/20 | Loss: 0.15459132194519043 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:00<00:02,  5.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 5/20 | Loss: 0.1485404372215271 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [00:00<00:02,  5.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 6/20 | Loss: 0.1356130838394165 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [00:01<00:02,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 7/20 | Loss: 0.11934396624565125 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [00:01<00:02,  5.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 8/20 | Loss: 0.10685203224420547 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [00:01<00:02,  5.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 9/20 | Loss: 0.08659203350543976 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [00:01<00:01,  5.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 10/20 | Loss: 0.07028145343065262 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [00:01<00:01,  5.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 11/20 | Loss: 0.04940208047628403 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:01<00:01,  5.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 12/20 | Loss: 0.03790580481290817 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [00:02<00:01,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 13/20 | Loss: 0.024666260927915573 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:02<00:01,  5.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 14/20 | Loss: 0.020935561507940292 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [00:03<00:02,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 15/20 | Loss: 0.018399957567453384 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [00:03<00:01,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 16/20 | Loss: 0.01251994539052248 || LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [00:03<00:01,  3.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 17/20 | Loss: 0.013241753913462162 || LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [00:04<00:00,  3.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 18/20 | Loss: 0.00785981398075819 || LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [00:04<00:00,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 19/20 | Loss: 0.009040283039212227 || LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [00:05<00:00,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target means] Epoch 20/20 | Loss: 0.007270320318639278 || LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:05<00:00,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Target means] Best Epoch: 20, Best Loss: 0.007270\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 1/20 | Loss: 0.27774375677108765 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [00:00<00:05,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 2/20 | Loss: 0.306547611951828 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:00<00:07,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 3/20 | Loss: 0.24573197960853577 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:01<00:10,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 4/20 | Loss: 0.23683695495128632 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:01<00:08,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 5/20 | Loss: 0.2277493178844452 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [00:02<00:06,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 6/20 | Loss: 0.205328568816185 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [00:02<00:05,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 7/20 | Loss: 0.1864250898361206 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [00:02<00:04,  2.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 8/20 | Loss: 0.16579271852970123 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [00:03<00:03,  3.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 9/20 | Loss: 0.13775716722011566 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [00:03<00:03,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 10/20 | Loss: 0.11208410561084747 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [00:03<00:02,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 11/20 | Loss: 0.08034591376781464 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:03<00:02,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 12/20 | Loss: 0.0571773499250412 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [00:03<00:01,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 13/20 | Loss: 0.035433992743492126 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:04<00:01,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 14/20 | Loss: 0.02828488126397133 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [00:04<00:01,  5.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 15/20 | Loss: 0.025284020230174065 || LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [00:04<00:00,  5.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 16/20 | Loss: 0.021330121904611588 || LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [00:04<00:00,  5.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 17/20 | Loss: 0.022552985697984695 || LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [00:04<00:00,  5.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 18/20 | Loss: 0.013599824160337448 || LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [00:04<00:00,  5.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 19/20 | Loss: 0.01246025413274765 || LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [00:05<00:00,  5.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target std] Epoch 20/20 | Loss: 0.00965617410838604 || LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:05<00:00,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Target std] Best Epoch: 20, Best Loss: 0.009656\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Paths to saved best models\n",
        "model_paths = [\n",
        "    os.path.join(outpath, f\"best_model_{mean_id}.pth\"),\n",
        "    os.path.join(outpath, f\"best_model_{std_id}.pth\"),\n",
        "]\n",
        "\n",
        "# Both models will have total_vars = 1\n",
        "obj_single = {\n",
        "    'total_vars': 1,\n",
        "    'dim': n_dim,\n",
        "    'n_neurons': n_neurons,\n",
        "    'n_layers': n_layers\n",
        "}\n",
        "\n",
        "# Load models\n",
        "models = []\n",
        "for path in model_paths:\n",
        "    m = MyResidualSirenNet(obj_single).to(device)\n",
        "    checkpoint = torch.load(path, map_location=device)\n",
        "    m.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    m.eval()\n",
        "    models.append(m)\n",
        "\n",
        "# Inference: collect predictions from both models\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for m in models:\n",
        "        pred_list = []\n",
        "        for i in range(0, torch_coords.shape[0], group_size):\n",
        "            coords = torch_coords[i:min(i + group_size, torch_coords.shape[0])].type(torch.float32).to(device)\n",
        "            vals = m(coords)  # shape [group, 1]\n",
        "            pred_list.append(vals.cpu())\n",
        "        pred_tensor = torch.cat(pred_list, dim=0)  # [512, 1]\n",
        "        predictions.append(pred_tensor)\n",
        "\n",
        "# Combine into shape [512, 2]\n",
        "n_predictions = torch.cat(predictions, dim=1)\n",
        "n_predictions=np.array(n_predictions)\n",
        "print(n_predictions.shape)  # torch.Size([512, 2])\n",
        "# Compute PSNR\n",
        "findMultiVariatePSNR(var_name, total_vars, n_val, n_predictions)\n",
        "\n",
        "# Compute RMSE\n",
        "rmse = compute_rmse(n_val, n_predictions)\n",
        "print(\"RMSE:\", rmse,flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXEeQ7TqiY7G",
        "outputId": "90a73c2a-b5df-4226-ed78-a2bdddc772fa"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 2)\n",
            "Mean  PSNR: 27.64842535121715\n",
            "Std  PSNR: 25.683287704364822\n",
            "\n",
            "Average psnr :  26.665856527790986\n",
            "RMSE: 0.09402599168229316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vti saving path\n",
        "vti_path = args.vti_path\n",
        "if not os.path.exists(vti_path):\n",
        "    os.makedirs(vti_path)\n",
        "# vti name\n",
        "vti_name = args.vti_name\n",
        "mask_arr=False\n",
        "isMaskPresent=False\n",
        "makeVTI(data,real_data, n_predictions, n_pts, total_vars, var_name, dim, isMaskPresent, mask_arr, vti_path, vti_name)"
      ],
      "metadata": {
        "_uuid": "8987b9b8-de2f-448c-995c-28bee1a033eb",
        "_cell_guid": "6f9d6b16-aa9c-4808-81e8-a4d1e00459d2",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:39:05.443004Z",
          "iopub.status.idle": "2025-05-26T20:39:05.443267Z",
          "shell.execute_reply": "2025-05-26T20:39:05.443158Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "083S4UyeXF8U",
        "outputId": "f93344f9-72dc-4d23-83ac-efcf79213de3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vti File written successfully at ./data/gmm_predicted.vti\n"
          ]
        }
      ],
      "execution_count": 97
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i0EnJfeas4yt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}