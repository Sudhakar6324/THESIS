# -*- coding: utf-8 -*-
"""MUTLI HASH_with_original.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ngelz2HhGxmfQ9OVkNPb2smyCaqDdJ-P
"""


import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from tqdm import tqdm

import vtk
import numpy as np
from vtk.util.numpy_support import vtk_to_numpy

def compute_per_channel_psnr(pred, target, max_val=1.0):
    psnrs = []
    for i in range(pred.shape[1]):  # loop over 9 variables
        mse = F.mse_loss(pred[:, i], target[:, i])
        psnr = 10 * torch.log10(max_val ** 2 / mse)
        psnrs.append(psnr.item())
    return psnrs

def load_vti(filepath):
    reader = vtk.vtkXMLImageDataReader()
    reader.SetFileName(filepath)
    reader.Update()
    data = reader.GetOutput()

    # Get 3D coordinates
    n_points = data.GetNumberOfPoints()
    coords = np.array([data.GetPoint(i) for i in range(n_points)], dtype=np.float32)

    # Read all data arrays and stack them
    arrays = []
    pd = data.GetPointData()
    for i in range(pd.GetNumberOfArrays()):
        arr = vtk_to_numpy(pd.GetArray(i))
        arrays.append(arr)

    full_data = np.array(arrays).T
    print(full_data.shape)
    print(coords.shape) # shape: (N, 9)
    return coords, full_data

coords_np, values_np = load_vti("new_gmm_isabel_week_6.vti")
coords = torch.tensor((coords_np - coords_np.min(0)) / (coords_np.max(0) - coords_np.min(0)), dtype=torch.float32).cuda()
# values_np shape: (N, 9)
mins = values_np.min(axis=0)        # Shape: (9,)
maxs = values_np.max(axis=0)        # Shape: (9,)
ranges = maxs - mins + 1e-8         # Avoid division by zero

# Normalize each channel independently
values_np_normalized = (values_np - mins) / ranges

# Convert to torch tensor
values = torch.tensor(values_np_normalized, dtype=torch.float32).cuda()
print(values.shape)

# ðŸ›  Install dependencies if needed

# ----------------------------------------
# ðŸ§  Step 1: Simulated Input Data (replace with .vti loader)
# ----------------------------------------

# Simulated 3D grid (e.g., 32x32x32)
coords = coords.cuda()
targets = values.cuda()

# ----------------------------------------
# ðŸ§© Step 2: Hash Encoding Implementation
# ----------------------------------------

class HashEncoder(nn.Module):
    def __init__(self, n_levels=16, n_features=2, log2_hashmap_size=19, base_res=16, finest_res=512):
        super().__init__()
        self.n_levels = n_levels
        self.n_features = n_features
        self.log2_hashmap_size = log2_hashmap_size
        self.hashmap_size = 2 ** log2_hashmap_size

        # Compute resolutions
        b = np.exp((np.log(finest_res) - np.log(base_res)) / (n_levels - 1))
        self.resolutions = [int(base_res * (b ** i)) for i in range(n_levels)]

        # Create trainable hash tables (1 per level)
        self.hash_tables = nn.ParameterList([
            nn.Parameter(torch.randn(self.hashmap_size, n_features) * 0.01)
            for _ in range(n_levels)
        ])

    def hash(self, idx):
        # Simple spatial hash function: (x * 1) ^ (y * 2654435761) ^ (z * 805459861)
        primes = torch.tensor([1, 2654435761, 805459861], device=idx.device)
        x = (idx * primes).sum(dim=-1)
        return x & (self.hashmap_size - 1)

    def forward(self, x):
        B = x.shape[0]
        outputs = []

        for level, res in enumerate(self.resolutions):
            # Scale to grid
            scaled = x * res
            idx_lo = torch.floor(scaled).long()
            idx_hi = idx_lo + 1
            w = scaled - idx_lo.float()  # interpolation weights

            # 8 corners
            corners = torch.stack([
                idx_lo,
                torch.stack([idx_hi[:, 0], idx_lo[:, 1], idx_lo[:, 2]], dim=1),
                torch.stack([idx_lo[:, 0], idx_hi[:, 1], idx_lo[:, 2]], dim=1),
                torch.stack([idx_hi[:, 0], idx_hi[:, 1], idx_lo[:, 2]], dim=1),
                torch.stack([idx_lo[:, 0], idx_lo[:, 1], idx_hi[:, 2]], dim=1),
                torch.stack([idx_hi[:, 0], idx_lo[:, 1], idx_hi[:, 2]], dim=1),
                torch.stack([idx_lo[:, 0], idx_hi[:, 1], idx_hi[:, 2]], dim=1),
                idx_hi,
            ], dim=1)

            # Hash and fetch features
            h_idx = self.hash(corners % res)  # wrap with modulo
            feats = self.hash_tables[level][h_idx]  # (B, 8, F)

            # Trilinear interpolation
            wx, wy, wz = w[:, 0], w[:, 1], w[:, 2]
            w000 = (1 - wx) * (1 - wy) * (1 - wz)
            w100 = wx * (1 - wy) * (1 - wz)
            w010 = (1 - wx) * wy * (1 - wz)
            w110 = wx * wy * (1 - wz)
            w001 = (1 - wx) * (1 - wy) * wz
            w101 = wx * (1 - wy) * wz
            w011 = (1 - wx) * wy * wz
            w111 = wx * wy * wz

            weights = torch.stack([w000, w100, w010, w110, w001, w101, w011, w111], dim=1).unsqueeze(-1)
            out = (feats * weights).sum(dim=1)
            outputs.append(out)

        return torch.cat(outputs, dim=-1)  # (B, n_levels * n_features)

# ----------------------------------------
# ðŸ§  Step 3: Define MLP
# ----------------------------------------

class MLP(nn.Module):
    def __init__(self, in_dim, out_dim=9):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 64),
            nn.ReLU(),
            nn.Linear(64, out_dim)
        )

    def forward(self, x):
        return self.net(x)

# ----------------------------------------
# ðŸš€ Step 4: Training
# ----------------------------------------

encoder = HashEncoder().cuda()
mlp = MLP(encoder.n_levels * encoder.n_features).cuda()
optimizer = torch.optim.Adam(list(encoder.parameters()) + list(mlp.parameters()), lr=1e-3)

BATCH_SIZE = 2048
from torch.utils.data import TensorDataset, DataLoader

# Create a PyTorch Dataset
dataset = TensorDataset(coords, targets)
dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)

import matplotlib.pyplot as plt

# Tracking variables
group1_losses, group2_losses, group3_losses, epoch_ids = [], [], [], []

NUM_EPOCHS = 200
best_loss = float('inf')
save_path = "best_model_by_loss.pth"

for epoch in tqdm(range(NUM_EPOCHS)):
    epoch_loss = 0
    g1_total, g2_total, g3_total = 0.0, 0.0, 0.0

    for x_batch, y_batch in dataloader:
        x_batch = x_batch.cuda()
        y_batch = y_batch.cuda()

        pred = mlp(encoder(x_batch))

        # Split into groups
        g1_pred, g2_pred, g3_pred = pred[:, 0:3], pred[:, 3:6], pred[:, 6:9]
        g1_target, g2_target, g3_target = y_batch[:, 0:3], y_batch[:, 3:6], y_batch[:, 6:9]

        # Compute per-group loss
        g1_loss = F.mse_loss(g1_pred, g1_target)
        g2_loss = F.mse_loss(g2_pred, g2_target)
        g3_loss = F.mse_loss(g3_pred, g3_target)

        # Total loss
        loss = F.mse_loss(pred,y_batch)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item() * len(x_batch)
        g1_total += g1_loss.item() * len(x_batch)
        g2_total += g2_loss.item() * len(x_batch)
        g3_total += g3_loss.item() * len(x_batch)

    # Average loss for full dataset
    avg_loss = epoch_loss / len(dataset)
    g1_avg = g1_total / len(dataset)
    g2_avg = g2_total / len(dataset)
    g3_avg = g3_total / len(dataset)

    print(f"\nEpoch {epoch+1}/{NUM_EPOCHS}, Loss = {avg_loss:.6f}",flush=True)
    print(f"\nComponent Losses: mean: {g1_avg:.6f}, stds: {g2_avg:.6f}, gmm weights: {g3_avg:.6f}",flush=True)

    # Track for plotting
    group1_losses.append(g1_avg)
    group2_losses.append(g2_avg)
    group3_losses.append(g3_avg)
    epoch_ids.append(epoch + 1)

    # Save if loss improves
    if avg_loss < best_loss:
        best_loss = avg_loss
        #print(f"Saving new best model at Epoch {epoch+1} with Loss {avg_loss:.6f}")
        torch.save({
            'encoder_state_dict': encoder.state_dict(),
            'mlp_state_dict': mlp.state_dict(),
            'loss': avg_loss,
            'epoch': epoch + 1
        }, save_path)

    # Optional: Show PSNR info
    if (epoch + 1) % 25 == 0:
        with torch.no_grad():
            pred_all = mlp(encoder(coords))
            psnr = compute_per_channel_psnr(pred_all, targets)
            print(f"PSNR @ Epoch {epoch+1}: {psnr}")
# Plot component group losses
plt.figure(figsize=(10, 6))
plt.plot(epoch_ids, group1_losses, label="Channels means", color='blue')
plt.plot(epoch_ids, group2_losses, label="Channels stds", color='green')
plt.plot(epoch_ids, group3_losses, label="Channels weights", color='red')
plt.xlabel("Epoch")
plt.ylabel("MSE Loss")
plt.title("Per-Component Group Loss vs Epoch")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("final_component_loss_plot.png")
print("Saved final component loss plot as final_component_loss_plot.png")

# ----------------------------------------
# ðŸ§ª Step 5: PSNR Evaluation
# ----------------------------------------

def compute_psnr(pred, target, max_val=1.0):
    mse = F.mse_loss(pred, target)
    psnr = 10 * torch.log10(max_val ** 2 / mse)
    return psnr.item()
