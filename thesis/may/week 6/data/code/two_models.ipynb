{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10578389,
          "sourceType": "datasetVersion",
          "datasetId": 6546447
        },
        {
          "sourceId": 11041818,
          "sourceType": "datasetVersion",
          "datasetId": 6878023
        },
        {
          "sourceId": 11251078,
          "sourceType": "datasetVersion",
          "datasetId": 7030699
        },
        {
          "sourceId": 11389139,
          "sourceType": "datasetVersion",
          "datasetId": 7132144
        },
        {
          "sourceId": 11421576,
          "sourceType": "datasetVersion",
          "datasetId": 7153051
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install vtk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5RN3QEr9B8B",
        "outputId": "96b4ae8d-0705-42f0-e4e3-7598de75dbdf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vtk in /usr/local/lib/python3.11/dist-packages (9.5.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from vtk) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->vtk) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import vtk\n",
        "from vtk import *\n",
        "from vtk.util.numpy_support import vtk_to_numpy\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "import time"
      ],
      "metadata": {
        "_uuid": "d33f75d4-5445-4e48-8179-f0c5dd333f79",
        "_cell_guid": "240889c7-74eb-4fd4-a5b1-ec2aead81dac",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:13.755511Z",
          "iopub.execute_input": "2025-05-26T20:25:13.755738Z",
          "iopub.status.idle": "2025-05-26T20:25:19.575599Z",
          "shell.execute_reply.started": "2025-05-26T20:25:13.755716Z",
          "shell.execute_reply": "2025-05-26T20:25:19.574610Z"
        },
        "id": "2_BwBIYQ5lmI"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print('Device running:', device)"
      ],
      "metadata": {
        "_uuid": "43d958cf-562d-4fb8-9670-43075fd82174",
        "_cell_guid": "bda30f3b-5c85-404f-8cdc-861e65b7ae69",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.576562Z",
          "iopub.execute_input": "2025-05-26T20:25:19.576994Z",
          "iopub.status.idle": "2025-05-26T20:25:19.654026Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.576972Z",
          "shell.execute_reply": "2025-05-26T20:25:19.653204Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_OdVX9C5lmL",
        "outputId": "18afb553-c0ad-4a21-992c-c0a026a9c0f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device running: cuda\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "class SineLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, bias=True, is_first=False, omega_0=30):\n",
        "        super().__init__()\n",
        "        self.omega_0 = omega_0\n",
        "        self.is_first = is_first\n",
        "        # self.enable_dropout = enable_dropout\n",
        "        # self.dropout_prob = dropout_prob\n",
        "        self.in_features = in_features\n",
        "        # if enable_dropout:\n",
        "        #     if not self.is_first:\n",
        "        #         self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        with torch.no_grad():\n",
        "            if self.is_first:\n",
        "                self.linear.weight.uniform_(-1 / self.in_features,\n",
        "                                             1 / self.in_features)\n",
        "            else:\n",
        "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0,\n",
        "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        # if self.enable_dropout:\n",
        "        #     if not self.is_first:\n",
        "        #         x = self.dropout(x)\n",
        "        return torch.sin(self.omega_0 * x)"
      ],
      "metadata": {
        "_uuid": "c6d00f8a-3e62-40d1-81e8-b30fd44e994f",
        "_cell_guid": "47639dbe-7c29-4716-ad12-c245edbd4925",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.654942Z",
          "iopub.execute_input": "2025-05-26T20:25:19.655223Z",
          "iopub.status.idle": "2025-05-26T20:25:19.667030Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.655199Z",
          "shell.execute_reply": "2025-05-26T20:25:19.666295Z"
        },
        "id": "3u8dXB2i5lmL"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualSineLayer(nn.Module):\n",
        "    def __init__(self, features, bias=True, ave_first=False, ave_second=False, omega_0=30):\n",
        "        super().__init__()\n",
        "        self.omega_0 = omega_0\n",
        "        # self.enable_dropout = enable_dropout\n",
        "        # self.dropout_prob = dropout_prob\n",
        "        self.features = features\n",
        "        # if enable_dropout:\n",
        "        #     self.dropout_1 = nn.Dropout(dropout_prob)\n",
        "        self.linear_1 = nn.Linear(features, features, bias=bias)\n",
        "        self.linear_2 = nn.Linear(features, features, bias=bias)\n",
        "        self.weight_1 = .5 if ave_first else 1\n",
        "        self.weight_2 = .5 if ave_second else 1\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "\n",
        "    def init_weights(self):\n",
        "        with torch.no_grad():\n",
        "            self.linear_1.weight.uniform_(-np.sqrt(6 / self.features) / self.omega_0,\n",
        "                                           np.sqrt(6 / self.features) / self.omega_0)\n",
        "            self.linear_2.weight.uniform_(-np.sqrt(6 / self.features) / self.omega_0,\n",
        "                                           np.sqrt(6 / self.features) / self.omega_0)\n",
        "\n",
        "    def forward(self, input):\n",
        "        linear_1 = self.linear_1(self.weight_1*input)\n",
        "        # if self.enable_dropout:\n",
        "        #     linear_1 = self.dropout_1(linear_1)\n",
        "        sine_1 = torch.sin(self.omega_0 * linear_1)\n",
        "        sine_2 = torch.sin(self.omega_0 * self.linear_2(sine_1))\n",
        "        return self.weight_2*(input+sine_2)"
      ],
      "metadata": {
        "_uuid": "286fbfd2-ba2c-4fbe-8ac6-cfebd4a21e55",
        "_cell_guid": "ef7cdfa6-ccb1-405d-a306-c83170e479b4",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.667767Z",
          "iopub.execute_input": "2025-05-26T20:25:19.668045Z",
          "iopub.status.idle": "2025-05-26T20:25:19.679335Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.668025Z",
          "shell.execute_reply": "2025-05-26T20:25:19.678679Z"
        },
        "id": "vOXwLGmJ5lmM"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "class MyResidualSirenNet(nn.Module):\n",
        "    def __init__(self, obj):\n",
        "        super(MyResidualSirenNet, self).__init__()\n",
        "        # self.enable_dropout = obj['enable_dropout']\n",
        "        # self.dropout_prob = obj['dropout_prob']\n",
        "        self.Omega_0=30\n",
        "        self.n_layers = obj['n_layers']\n",
        "        self.input_dim = obj['dim']\n",
        "        self.output_dim = obj['total_vars']\n",
        "        self.neurons_per_layer = obj['n_neurons']\n",
        "        self.layers = [self.input_dim]\n",
        "        for i in range(self.n_layers-1):\n",
        "            self.layers.append(self.neurons_per_layer)\n",
        "        self.layers.append(self.output_dim)\n",
        "        self.net_layers = nn.ModuleList()\n",
        "        for idx in np.arange(self.n_layers):\n",
        "            layer_in = self.layers[idx]\n",
        "            layer_out = self.layers[idx+1]\n",
        "            ## if not the final layer\n",
        "            if idx != self.n_layers-1:\n",
        "                ## if first layer\n",
        "                if idx==0:\n",
        "                    self.net_layers.append(SineLayer(layer_in,layer_out,bias=True,is_first=idx==0))\n",
        "                ## if an intermdeiate layer\n",
        "                else:\n",
        "                    self.net_layers.append(ResidualSineLayer(layer_in,bias=True,ave_first=idx>1,ave_second=idx==(self.n_layers-2)))\n",
        "            ## if final layer\n",
        "            else:\n",
        "                final_linear = nn.Linear(layer_in,layer_out)\n",
        "                ## initialize weights for the final layer\n",
        "                with torch.no_grad():\n",
        "                    final_linear.weight.uniform_(-np.sqrt(6 / (layer_in)) / self.Omega_0, np.sqrt(6 / (layer_in)) / self.Omega_0)\n",
        "                self.net_layers.append(final_linear)\n",
        "\n",
        "    def forward(self,x):\n",
        "        for net_layer in self.net_layers:\n",
        "            x = net_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "_uuid": "e1400ad9-b3ed-49fc-81e0-929816a0aaf2",
        "_cell_guid": "807361ca-2c71-4799-83d0-2da9ccf9fac0",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.680067Z",
          "iopub.execute_input": "2025-05-26T20:25:19.680289Z",
          "iopub.status.idle": "2025-05-26T20:25:19.693684Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.680270Z",
          "shell.execute_reply": "2025-05-26T20:25:19.693049Z"
        },
        "id": "Cae86SYg5lmM"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "def size_of_network(n_layers, n_neurons, d_in, d_out, is_residual = True):\n",
        "    # Adding input layer\n",
        "    layers = [d_in]\n",
        "    # layers = [3]\n",
        "\n",
        "    # Adding hidden layers\n",
        "    layers.extend([n_neurons]*n_layers)\n",
        "    # layers = [3, 5, 5, 5]\n",
        "\n",
        "    # Adding output layer\n",
        "    layers.append(d_out)\n",
        "    # layers = [3, 5, 5, 5, 1]\n",
        "\n",
        "    # Number of steps\n",
        "    n_layers = len(layers)-1\n",
        "    # n_layers = 5 - 1 = 4\n",
        "\n",
        "    n_params = 0\n",
        "\n",
        "    # np.arange(4) = [0, 1, 2, 3]\n",
        "    for ndx in np.arange(n_layers):\n",
        "\n",
        "        # number of neurons in below layer\n",
        "        layer_in = layers[ndx]\n",
        "\n",
        "        # number of neurons in above layer\n",
        "        layer_out = layers[ndx+1]\n",
        "\n",
        "        # max number of neurons in both the layer\n",
        "        og_layer_in = max(layer_in,layer_out)\n",
        "\n",
        "        # if lower layer is the input layer\n",
        "        # or the upper layer is the output layer\n",
        "        if ndx==0 or ndx==(n_layers-1):\n",
        "            # Adding weight corresponding to every neuron for every input neuron\n",
        "            # Adding bias for every neuron in the upper layer\n",
        "            n_params += ((layer_in+1)*layer_out)\n",
        "\n",
        "        else:\n",
        "\n",
        "            # If the layer is residual then proceed as follows as there will be more weights if residual layer is included\n",
        "            if is_residual:\n",
        "                # doubt in the following two lines\n",
        "                n_params += (layer_in*og_layer_in)+og_layer_in\n",
        "                n_params += (og_layer_in*layer_out)+layer_out\n",
        "\n",
        "            # if the layer is non residual then simply add number of weights and biases as follows\n",
        "            else:\n",
        "                n_params += ((layer_in+1)*layer_out)\n",
        "            #\n",
        "        #\n",
        "    #\n",
        "\n",
        "    return n_params"
      ],
      "metadata": {
        "_uuid": "49e23bf9-3de6-417b-8de1-53aaf02fd323",
        "_cell_guid": "7342b7cd-612f-4c56-ad94-ecd81203519a",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.695847Z",
          "iopub.execute_input": "2025-05-26T20:25:19.696059Z",
          "iopub.status.idle": "2025-05-26T20:25:19.707241Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.696041Z",
          "shell.execute_reply": "2025-05-26T20:25:19.706562Z"
        },
        "id": "Gmzb8rVy5lmN"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_PSNR(arrgt,arr_recon):\n",
        "    diff = arrgt - arr_recon\n",
        "    sqd_max_diff = (np.max(arrgt)-np.min(arrgt))**2\n",
        "    snr = 10*np.log10(sqd_max_diff/np.mean(diff**2))\n",
        "    return snr"
      ],
      "metadata": {
        "_uuid": "4bee2b5f-d501-4d1c-b226-410b2624c2d5",
        "_cell_guid": "c8d04a55-6de3-4520-9cf7-45a568420b31",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.708470Z",
          "iopub.execute_input": "2025-05-26T20:25:19.708697Z",
          "iopub.status.idle": "2025-05-26T20:25:19.720894Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.708678Z",
          "shell.execute_reply": "2025-05-26T20:25:19.720185Z"
        },
        "id": "Tr_FvTLA5lmN"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "def srs(numOfPoints, valid_pts, percentage, isMaskPresent, mask_array):\n",
        "\n",
        "    # getting total number of sampled points\n",
        "    numberOfSampledPoints = int((valid_pts/100) * percentage)\n",
        "\n",
        "    # storing corner indices in indices variable\n",
        "    indices = set()\n",
        "\n",
        "    # As long as we don't get the required amount of sample points keep finding the random numbers\n",
        "    while(len(indices) < numberOfSampledPoints):\n",
        "        rp = random.randint(0, numOfPoints-1)\n",
        "        if isMaskPresent and mask_array[rp] == 0:\n",
        "            continue\n",
        "        indices.add(rp)\n",
        "\n",
        "    # return indices\n",
        "    return indices"
      ],
      "metadata": {
        "_uuid": "9b219fbe-1596-4e3b-a0a7-6eb88db2f52d",
        "_cell_guid": "415f4118-71de-4504-b39f-a7bd40cdcc02",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.721825Z",
          "iopub.execute_input": "2025-05-26T20:25:19.722096Z",
          "iopub.status.idle": "2025-05-26T20:25:19.732038Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.722064Z",
          "shell.execute_reply": "2025-05-26T20:25:19.731249Z"
        },
        "id": "F1W8L5oG5lmO"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "def findMultiVariatePSNR(var_name, total_vars, actual, pred):\n",
        "    # print('Printing PSNR')\n",
        "    tot = 0\n",
        "    psnr_list = []\n",
        "    for j in range(total_vars):\n",
        "        psnr = compute_PSNR(actual[:,j], pred[:,j])\n",
        "        psnr_list.append(psnr)\n",
        "        tot += psnr\n",
        "        print(var_name, ' PSNR:', psnr)\n",
        "    avg_psnr = tot/total_vars\n",
        "    print('\\nAverage psnr : ', avg_psnr)\n",
        "     #this function is calculating the psnr of final epoch (or whenever it is called) of each variable and then averaging it\n",
        "     #Thus individual epochs psnr is not calculated\n",
        "\n",
        "    return psnr_list, avg_psnr"
      ],
      "metadata": {
        "_uuid": "964befc2-020d-46d4-bd1b-ef061a65b9e8",
        "_cell_guid": "c20e48d5-ebad-408b-b564-627ba81d02f9",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.732800Z",
          "iopub.execute_input": "2025-05-26T20:25:19.733052Z",
          "iopub.status.idle": "2025-05-26T20:25:19.745670Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.733032Z",
          "shell.execute_reply": "2025-05-26T20:25:19.744868Z"
        },
        "id": "4pFO0AYF5lmO"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_rmse(actual, predicted):\n",
        "    mse = np.mean((actual - predicted) ** 2)\n",
        "    return np.sqrt(mse)\n",
        "\n",
        "def denormalizeValue(total_vars, to, ref):\n",
        "    to_arr = np.array(to)\n",
        "    for i in range(total_vars):\n",
        "        min_data = np.min(ref[:, i])\n",
        "        max_data = np.max(ref[:, i])\n",
        "        to_arr[:, i] = (((to[:, i] * 0.5) + 0.5) * (max_data - min_data)) + min_data\n",
        "    return to_arr"
      ],
      "metadata": {
        "_uuid": "2face64a-1559-415e-9527-5a581fab1db5",
        "_cell_guid": "716ccaed-b6c8-4cc4-83a6-643495093c02",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.746505Z",
          "iopub.execute_input": "2025-05-26T20:25:19.746788Z",
          "iopub.status.idle": "2025-05-26T20:25:19.755298Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.746760Z",
          "shell.execute_reply": "2025-05-26T20:25:19.754436Z"
        },
        "id": "8InIQVwb5lmP"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "def makeVTI(data, val, n_predictions, n_pts, total_vars, var_name, dim, isMaskPresent, mask_arr, vti_path, vti_name, normalizedVersion = False):\n",
        "    nn_predictions = denormalizeValue(total_vars, n_predictions, val) if not normalizedVersion else n_predictions\n",
        "    writer = vtkXMLImageDataWriter()\n",
        "    writer.SetFileName(vti_path + vti_name)\n",
        "    img = vtkImageData()\n",
        "    img.CopyStructure(data)\n",
        "    if not isMaskPresent:\n",
        "        for i in range(total_vars):\n",
        "            f = var_name[i]\n",
        "            temp = nn_predictions[:, i]\n",
        "            arr = vtkFloatArray()\n",
        "            for j in range(n_pts):\n",
        "                arr.InsertNextValue(temp[j])\n",
        "            arr.SetName(f)\n",
        "            img.GetPointData().AddArray(arr)\n",
        "        # print(img)\n",
        "        writer.SetInputData(img)\n",
        "        writer.Write()\n",
        "        print(f'Vti File written successfully at {vti_path}{vti_name}')\n",
        "    else:\n",
        "        for i in range(total_vars):\n",
        "            f = var_name[i]\n",
        "            temp = nn_predictions[:, i]\n",
        "            idx = 0\n",
        "            arr = vtkFloatArray()\n",
        "            for j in range(n_pts):\n",
        "                if(mask_arr[j] == 1):\n",
        "                    arr.InsertNextValue(temp[idx])\n",
        "                    idx += 1\n",
        "                else:\n",
        "                    arr.InsertNextValue(0.0)\n",
        "            arr.SetName('p_' + f)\n",
        "            data.GetPointData().AddArray(arr)\n",
        "        # print(data)\n",
        "        writer.SetInputData(data)\n",
        "        writer.Write()\n",
        "        print(f'Vti File written successfully at {vti_path}{vti_name}')"
      ],
      "metadata": {
        "_uuid": "88d4128a-9484-48bb-b8cd-21abe4801eb1",
        "_cell_guid": "4d173df2-a1ab-442d-8eeb-bd0f1e71b9ee",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.756183Z",
          "iopub.execute_input": "2025-05-26T20:25:19.756430Z",
          "iopub.status.idle": "2025-05-26T20:25:19.768524Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.756410Z",
          "shell.execute_reply": "2025-05-26T20:25:19.767693Z"
        },
        "id": "Vl1XdT_T5lmP"
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "def getImageData(actual_img, val, n_pts, var_name, isMaskPresent, mask_arr):\n",
        "    img = vtkImageData()\n",
        "    img.CopyStructure(actual_img)\n",
        "    # if isMaskPresent:\n",
        "    #     img.DeepCopy(actual_img)\n",
        "    # img.SetDimensions(dim)\n",
        "    # img.SetOrigin(actual_img.GetOrigin())\n",
        "    # img.SetSpacing(actual_img.GetSpacing())\n",
        "    if not isMaskPresent:\n",
        "        f = var_name\n",
        "        data = val\n",
        "        arr = vtkFloatArray()\n",
        "        for j in range(n_pts):\n",
        "            arr.InsertNextValue(data[j])\n",
        "        arr.SetName(f)\n",
        "        img.GetPointData().SetScalars(arr)\n",
        "    else:\n",
        "        f = var_name\n",
        "        data = val\n",
        "        idx = 0\n",
        "        arr = vtkFloatArray()\n",
        "        for j in range(n_pts):\n",
        "            if(mask_arr[j] == 1):\n",
        "                arr.InsertNextValue(data[idx])\n",
        "                idx += 1\n",
        "            else:\n",
        "                arr.InsertNextValue(0.0)\n",
        "        arr.SetName(f)\n",
        "        img.GetPointData().SetScalars(arr)\n",
        "    return img"
      ],
      "metadata": {
        "_uuid": "99a2cbb5-4737-4a6d-b398-c37e117de5a7",
        "_cell_guid": "7042e60f-eafc-446d-87ab-ec4298dd9276",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.769381Z",
          "iopub.execute_input": "2025-05-26T20:25:19.769639Z",
          "iopub.status.idle": "2025-05-26T20:25:19.780625Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.769609Z",
          "shell.execute_reply": "2025-05-26T20:25:19.779903Z"
        },
        "id": "XsWI84C-5lmP"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import Namespace\n",
        "\n",
        "# Parameters (simulating argparse in a Jupyter Notebook)\n",
        "args = Namespace(\n",
        "    n_neurons=150,\n",
        "    n_layers=6,\n",
        "    epochs=200,  # Required argument: Set the number of epochs\n",
        "    batchsize=512,\n",
        "    lr=0.00005,\n",
        "    no_decay=False,\n",
        "    decay_rate=0.8,\n",
        "    decay_at_interval=True,\n",
        "    decay_interval=15,\n",
        "    datapath='/content/Teardrop_Gaussian.vti',  # Required: Set the path to your data\n",
        "    outpath='./models/',\n",
        "    exp_path='../logs/',\n",
        "    modified_data_path='./data/',\n",
        "    dataset_name='3d_data',  # Required: Set the dataset name\n",
        "    vti_name='predicted.vti',  # Required: Name of the dataset\n",
        "    vti_path='./data/'\n",
        ")\n",
        "\n",
        "print(args, end='\\n\\n')\n",
        "\n",
        "# Assigning parameters to variables\n",
        "LR = args.lr\n",
        "BATCH_SIZE = args.batchsize\n",
        "decay_rate = args.decay_rate\n",
        "decay_at_equal_interval = args.decay_at_interval\n",
        "\n",
        "decay = not args.no_decay\n",
        "MAX_EPOCH = args.epochs\n",
        "\n",
        "n_neurons = args.n_neurons\n",
        "n_layers = args.n_layers + 2\n",
        "decay_interval = args.decay_interval\n",
        "outpath = args.outpath\n",
        "exp_path = args.exp_path\n",
        "datapath = args.datapath\n",
        "modified_data_path = args.modified_data_path\n",
        "dataset_name = args.dataset_name\n",
        "vti_name = args.vti_name\n",
        "vti_path = args.vti_path\n",
        "\n",
        "# Displaying the final configuration\n",
        "print(f\"Learning Rate: {LR}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Decay Rate: {decay_rate}\")\n",
        "print(f\"Max Epochs: {MAX_EPOCH}\")\n",
        "print(f\"Number of Neurons per Layer: {n_neurons}\")\n",
        "print(f\"Number of Layers (including input/output): {n_layers}\")\n",
        "print(f\"Data Path: {datapath}\")\n",
        "print(f\"Output Path: {outpath}\")\n",
        "print(f\"Dataset Name: {dataset_name}\")\n",
        "print(f\"Vti Name: {vti_name}\")"
      ],
      "metadata": {
        "_uuid": "07692dd4-4d61-4352-8b23-bff56509856c",
        "_cell_guid": "4204ef20-76e1-416f-b261-20a979ca06e6",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.781711Z",
          "iopub.execute_input": "2025-05-26T20:25:19.782004Z",
          "iopub.status.idle": "2025-05-26T20:25:19.797158Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.781976Z",
          "shell.execute_reply": "2025-05-26T20:25:19.796521Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN1Tmd7t5lmP",
        "outputId": "20a20c1f-79f2-4389-a0ac-79bddb3a3bea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(n_neurons=150, n_layers=6, epochs=200, batchsize=512, lr=5e-05, no_decay=False, decay_rate=0.8, decay_at_interval=True, decay_interval=15, datapath='/content/Teardrop_Gaussian.vti', outpath='./models/', exp_path='../logs/', modified_data_path='./data/', dataset_name='3d_data', vti_name='predicted.vti', vti_path='./data/')\n",
            "\n",
            "Learning Rate: 5e-05\n",
            "Batch Size: 512\n",
            "Decay Rate: 0.8\n",
            "Max Epochs: 200\n",
            "Number of Neurons per Layer: 150\n",
            "Number of Layers (including input/output): 8\n",
            "Data Path: /content/Teardrop_Gaussian.vti\n",
            "Output Path: ./models/\n",
            "Dataset Name: 3d_data\n",
            "Vti Name: predicted.vti\n"
          ]
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable Initialization\n",
        "var_name = []\n",
        "total_vars = None  # Number of variables\n",
        "univariate = None  # True if dataset has one variable, else False\n",
        "group_size = 5000  # Group size during testing\n",
        "\n",
        "\n",
        "# Constructing the log file name\n",
        "log_file = (\n",
        "    f'train_{dataset_name}_{n_layers-2}rb_{n_neurons}n_{BATCH_SIZE}bs_'\n",
        "    f'{LR}lr_{decay}decay_{decay_rate}dr_'\n",
        "    f'{\"decayingAtInterval\" + str(decay_interval) if decay_at_equal_interval else \"decayingWhenLossIncr\"}'\n",
        ")\n",
        "\n",
        "print(log_file)"
      ],
      "metadata": {
        "_uuid": "844184e9-6479-45d0-8d31-b1d3a9a4a116",
        "_cell_guid": "cd516584-ec76-4358-888f-79e1116c82d2",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.797890Z",
          "iopub.execute_input": "2025-05-26T20:25:19.798155Z",
          "iopub.status.idle": "2025-05-26T20:25:19.810981Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.798129Z",
          "shell.execute_reply": "2025-05-26T20:25:19.810268Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cu5ZJmn5lmQ",
        "outputId": "3dd47849-7416-42b8-f541-0393f4359ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_3d_data_6rb_150n_512bs_5e-05lr_Truedecay_0.8dr_decayingAtInterval15\n"
          ]
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "n_pts = None  # Number of points in the dataset\n",
        "n_dim = None  # Dimensionality of the data\n",
        "dim = None  # Other dimension-specific information\n",
        "\n",
        "print(\"Decay:\", decay)\n",
        "print(f'Extracting variables from path: {datapath}', end=\"\\n\\n\")\n",
        "\n",
        "# Placeholder for data\n",
        "data_array = []\n",
        "scalar_data = None"
      ],
      "metadata": {
        "_uuid": "bc8c0631-eaaf-4af9-acb9-35bd7467277a",
        "_cell_guid": "c45f69dd-0524-4855-a64e-801e6bfb5765",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.811760Z",
          "iopub.execute_input": "2025-05-26T20:25:19.812043Z",
          "iopub.status.idle": "2025-05-26T20:25:19.825096Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.812017Z",
          "shell.execute_reply": "2025-05-26T20:25:19.824332Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hIB3Y5i5lmQ",
        "outputId": "a44607b9-a5d7-4aad-85e5-592851924ccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decay: True\n",
            "Extracting variables from path: /content/Teardrop_Gaussian.vti\n",
            "\n"
          ]
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": [
        "# # Reading values from .vti files\n",
        "# reader = vtk.vtkXMLImageDataReader()\n",
        "# reader.SetFileName(datapath)\n",
        "# reader.Update()\n",
        "\n",
        "# data = reader.GetOutput()\n",
        "# scalar_data = data\n",
        "# pdata = data.GetPointData()\n",
        "# n_pts = data.GetNumberOfPoints()\n",
        "# dim = data.GetDimensions()\n",
        "# n_dim = len(dim)\n",
        "# total_arr = pdata.GetNumberOfArrays()\n",
        "\n",
        "# print(\"n_pts:\", n_pts, \"dim:\", dim, \"n_dim:\", n_dim, \"total_arr:\", total_arr)\n",
        "\n",
        "# mask_arr = []\n",
        "# valid_pts = 0\n",
        "# var_name = []\n",
        "# data_array = []\n",
        "\n",
        "# # Extracting data from the .vti file\n",
        "# for i in range(total_arr):\n",
        "#     a_name = pdata.GetArrayName(i)\n",
        "#     if a_name in ['vtkValidPointMask', 'Swirl']:\n",
        "#         continue\n",
        "\n",
        "#     cur_arr = pdata.GetArray(a_name)\n",
        "#     n_components = cur_arr.GetNumberOfComponents()\n",
        "\n",
        "#     if n_components == 1:\n",
        "#         var_name.append(a_name)\n",
        "#         data_array.append(vtk_to_numpy(cur_arr))\n",
        "#     else:\n",
        "#         component_names = [f\"{a_name}_{c}\" for c in ['x', 'y', 'z'][:n_components]]\n",
        "#         var_name.extend(component_names)\n",
        "#         for c in range(n_components):\n",
        "#             c_data = [cur_arr.GetComponent(j, c) for j in range(n_pts)]\n",
        "#             data_array.append(np.array(c_data))\n",
        "\n",
        "# valid_pts = n_pts  # Assume all points are valid for simplicity\n",
        "# total_vars = len(var_name)\n",
        "# univariate = total_vars == 1\n",
        "\n",
        "# # Prepare numpy arrays for coordinates and variable values\n",
        "# cord = np.zeros((valid_pts, n_dim))\n",
        "# val = np.zeros((valid_pts, total_vars))\n",
        "\n",
        "# # Store data in numpy arrays\n",
        "# for i in range(n_pts):\n",
        "#     pt = scalar_data.GetPoint(i)\n",
        "#     cord[i, :] = pt\n",
        "#     val[i, :] = [arr[i] for arr in data_array]\n",
        "\n",
        "# # Display final information\n",
        "# print(\"Total Variables:\", total_vars)\n",
        "# print(\"Univariate:\", univariate)\n",
        "# print(\"Coordinates Shape:\", cord.shape)\n",
        "# print(\"Values Shape:\", val.shape)\n",
        "\n",
        "# Reading values from .vti files\n",
        "reader = vtk.vtkXMLImageDataReader()\n",
        "reader.SetFileName(datapath)\n",
        "reader.Update()\n",
        "\n",
        "data = reader.GetOutput()\n",
        "scalar_data = data\n",
        "pdata = data.GetPointData()\n",
        "n_pts = data.GetNumberOfPoints()\n",
        "dim = data.GetDimensions()\n",
        "n_dim = len(dim)\n",
        "total_arr = pdata.GetNumberOfArrays()\n",
        "\n",
        "print(\"n_pts:\", n_pts, \"dim:\", dim, \"n_dim:\", n_dim, \"total_arr:\", total_arr)\n",
        "\n",
        "var_name = []\n",
        "data_array = []\n",
        "\n",
        "# Extracting data from the .vti file\n",
        "for i in range(total_arr):\n",
        "    a_name = pdata.GetArrayName(i)\n",
        "\n",
        "    cur_arr = pdata.GetArray(a_name)\n",
        "    n_components = cur_arr.GetNumberOfComponents()\n",
        "\n",
        "    if n_components == 1:\n",
        "        var_name.append(a_name)\n",
        "        data_array.append(vtk_to_numpy(cur_arr))\n",
        "    else:\n",
        "        component_names = [f\"{a_name}_{c}\" for c in ['x', 'y', 'z'][:n_components]]\n",
        "        var_name.extend(component_names)\n",
        "        for c in range(n_components):\n",
        "            c_data = [cur_arr.GetComponent(j, c) for j in range(n_pts)]\n",
        "            data_array.append(np.array(c_data))\n",
        "\n",
        "total_vars = len(var_name)\n",
        "univariate = total_vars == 1\n",
        "\n",
        "# Prepare numpy arrays for coordinates and variable values\n",
        "cord = np.zeros((n_pts, n_dim))\n",
        "val = np.zeros((n_pts, total_vars))\n",
        "\n",
        "# Store data in numpy arrays\n",
        "for i in range(n_pts):\n",
        "    pt = scalar_data.GetPoint(i)\n",
        "    cord[i, :] = pt\n",
        "    val[i, :] = [arr[i] for arr in data_array]\n",
        "\n",
        "# Display final information\n",
        "print(\"Total Variables:\", total_vars)\n",
        "print(\"Univariate:\", univariate)\n",
        "print(\"Coordinates Shape:\", cord.shape)\n",
        "print(\"Values Shape:\", val.shape)"
      ],
      "metadata": {
        "_uuid": "01428998-749b-433d-8d00-0ad9ac906055",
        "_cell_guid": "2f13ab5d-71b7-4829-8d28-4a08f4f9a1cf",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.825827Z",
          "iopub.execute_input": "2025-05-26T20:25:19.826013Z",
          "iopub.status.idle": "2025-05-26T20:25:21.280626Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.825996Z",
          "shell.execute_reply": "2025-05-26T20:25:21.279633Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39aORhdJ5lmQ",
        "outputId": "0dff4678-1de6-4440-c963-1a2aa29f91f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_pts: 262144 dim: (64, 64, 64) n_dim: 3 total_arr: 2\n",
            "Total Variables: 2\n",
            "Univariate: False\n",
            "Coordinates Shape: (262144, 3)\n",
            "Values Shape: (262144, 2)\n"
          ]
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "# # Ensure modified data path exists\n",
        "# if not os.path.exists(modified_data_path):\n",
        "#     os.mkdir(modified_data_path)\n",
        "\n",
        "# Save raw coordinates and values\n",
        "# np.save(f'{modified_data_path}cord.npy', cord)\n",
        "# np.save(f'{modified_data_path}val.npy', val)\n",
        "\n",
        "# # Create copies of non-normalized data\n",
        "# nn_cord = cord.copy()\n",
        "# nn_val = val.copy()\n",
        "\n",
        "# === Separate Normalization for Values ===\n",
        "# We assume the variable order is:\n",
        "#   - Means: indices 0,1,2\n",
        "#   - Std Devs: indices 3,4,5\n",
        "#   - Weights: indices 6,7,8\n",
        "\n",
        "# # We'll store normalization parameters so that we can invert normalization later.\n",
        "# norm_params = {}\n",
        "# epsilon = 1e-8  # to avoid log(0)\n",
        "\n",
        "# # Normalize Means to [-1,1] using min–max normalization\n",
        "# for i in range(3):\n",
        "#     min_val = np.min(val[:, i])\n",
        "#     max_val = np.max(val[:, i])\n",
        "#     norm_params[var_name[i]] = (min_val, max_val)\n",
        "#     val[:, i] = 2.0 * ((val[:, i] - min_val) / (max_val - min_val) - 0.5)\n",
        "\n",
        "# # Normalize Std Devs: first take log, then min–max to [-1,1]\n",
        "# for i in range(3, 6):\n",
        "#     log_vals = np.log(val[:, i] + epsilon)\n",
        "#     min_val = np.min(log_vals)\n",
        "#     max_val = np.max(log_vals)\n",
        "#     norm_params[var_name[i]] = (min_val, max_val)\n",
        "#     val[:, i] = 2.0 * ((log_vals - min_val) / (max_val - min_val) - 0.5)\n",
        "\n",
        "# # Normalize Weights: take log, then min–max to [-1,1]\n",
        "# for i in range(6, 9):\n",
        "#     log_vals = np.log(val[:, i] + epsilon)\n",
        "#     min_val = np.min(log_vals)\n",
        "#     max_val = np.max(log_vals)\n",
        "#     norm_params[var_name[i]] = (min_val, max_val)\n",
        "#     val[:, i] = 2.0 * ((log_vals - min_val) / (max_val - min_val) - 0.5)\n",
        "\n",
        "# norm_params = {}\n",
        "real_data=val.copy()\n",
        "print(np.max(real_data))\n",
        "# Normalize values between -1 and 1\n",
        "for i in range(total_vars):\n",
        "    min_data = np.min(val[:, i])\n",
        "    max_data = np.max(val[:, i])\n",
        "    # norm_params[var_name[i]] = (min_data, max_data)\n",
        "    val[:, i] = 2.0 * ((val[:, i] - min_data) / (max_data - min_data) - 0.5)\n",
        "\n",
        "# Normalize Coordinates to [-1,1]\n",
        "for i in range(n_dim):\n",
        "    # Use (dim[i]-1] so that coordinates go from 0 to dim[i]-1.\n",
        "    cord[:, i] = 2.0 * (cord[:, i] / (dim[i] - 1) - 0.5)\n",
        "\n",
        "# # Normalize coordinates between 0 and 1\n",
        "# for i in range(n_dim):\n",
        "#     cord[:, i] = cord[:, i] / dim[i]\n",
        "\n",
        "\n",
        "# # Save normalized values and coordinates\n",
        "# np.save(f'{modified_data_path}n_cord.npy', cord)\n",
        "# np.save(f'{modified_data_path}n_val.npy', val)\n",
        "n_cord = cord.copy()\n",
        "n_val = val.copy()\n",
        "\n",
        "# # Reload data for verification\n",
        "# n_cord = np.load(f'{modified_data_path}n_cord.npy')\n",
        "# n_val = np.load(f'{modified_data_path}n_val.npy')\n",
        "# cord = np.load(f'{modified_data_path}cord.npy')\n",
        "# val = np.load(f'{modified_data_path}val.npy')\n",
        "means=n_val[:,0]\n",
        "stds=n_val[:,1]\n",
        "# Convert normalized data to PyTorch tensors\n",
        "torch_coords = torch.from_numpy(n_cord)\n",
        "torch_means = torch.from_numpy(means)\n",
        "torch_stds =torch.from_numpy(stds)\n",
        "# Display dataset details\n",
        "print('Dataset Name:', dataset_name)\n",
        "print('Total Variables:', total_vars)\n",
        "print('Variables Name:', var_name, end=\"\\n\\n\")\n",
        "print('Total Points in Data:', n_pts)\n",
        "print('Dimension of the Dataset:', dim)\n",
        "print('Number of Dimensions:', n_dim)\n",
        "print('Coordinate Tensor Shape:', torch_coords.shape)\n",
        "print('Scalar means Values Tensor Shape:', torch_means.shape)\n",
        "print('Scalar stds Values Tensor Shape:', torch_stds.shape)\n",
        "\n",
        "print('\\n###### Data setup is complete, now starting training ######\\n')"
      ],
      "metadata": {
        "_uuid": "521f7f9c-9a01-41f9-a149-1d15ff3fd1b8",
        "_cell_guid": "b0cbd8a2-2b80-4d5e-a135-f3c4b8b3c6c2",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:21.281683Z",
          "iopub.execute_input": "2025-05-26T20:25:21.282051Z",
          "iopub.status.idle": "2025-05-26T20:25:21.356747Z",
          "shell.execute_reply.started": "2025-05-26T20:25:21.282027Z",
          "shell.execute_reply": "2025-05-26T20:25:21.356094Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d4o9_RR5lmR",
        "outputId": "9d16626c-23ee-4fd0-ba5d-a31305895b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161.9956817626953\n",
            "Dataset Name: 3d_data\n",
            "Total Variables: 2\n",
            "Variables Name: ['Average', 'Standard_Deviation']\n",
            "\n",
            "Total Points in Data: 262144\n",
            "Dimension of the Dataset: (64, 64, 64)\n",
            "Number of Dimensions: 3\n",
            "Coordinate Tensor Shape: torch.Size([262144, 3])\n",
            "Scalar means Values Tensor Shape: torch.Size([262144])\n",
            "Scalar stds Values Tensor Shape: torch.Size([262144])\n",
            "\n",
            "###### Data setup is complete, now starting training ######\n",
            "\n"
          ]
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the DataLoader\n",
        "train_dataloader_mean = DataLoader(\n",
        "    TensorDataset(torch_coords, torch_means),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    pin_memory=True,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "# Model configuration\n",
        "obj = {\n",
        "    'total_vars': 1,\n",
        "    'dim': n_dim,\n",
        "    'n_neurons': n_neurons,\n",
        "    'n_layers': n_layers\n",
        "}\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model_mean = MyResidualSirenNet(obj).to(device)\n",
        "print(model_mean)\n",
        "\n",
        "optimizer = optim.Adam(model_mean.parameters(), lr=LR, betas=(0.9, 0.999))\n",
        "print(optimizer)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "print(criterion)\n",
        "\n",
        "# Training configuration summary\n",
        "print('\\nLearning Rate:', LR)\n",
        "print('Max Epochs:', MAX_EPOCH)\n",
        "print('Batch Size:', BATCH_SIZE)\n",
        "print('Number of Hidden Layers:', obj['n_layers'] - 2)\n",
        "print('Number of Neurons per Layer:', obj['n_neurons'])\n",
        "\n",
        "if decay:\n",
        "    print('Decay Rate:', decay_rate)\n",
        "    if decay_at_equal_interval:\n",
        "        print(f'Rate decays every {decay_interval} epochs.')\n",
        "    else:\n",
        "        print('Rate decays when the current epoch loss is greater than the previous epoch loss.')\n",
        "else:\n",
        "    print('No decay!')\n",
        "print()"
      ],
      "metadata": {
        "_uuid": "ec0c651a-5dad-486b-9fb7-1ccbaaf98cda",
        "_cell_guid": "adf3a3b0-29d8-4b33-ad38-babd78b228d1",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:21.357490Z",
          "iopub.execute_input": "2025-05-26T20:25:21.357712Z",
          "iopub.status.idle": "2025-05-26T20:25:23.403911Z",
          "shell.execute_reply.started": "2025-05-26T20:25:21.357694Z",
          "shell.execute_reply": "2025-05-26T20:25:23.403094Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnnT0LL_5lmS",
        "outputId": "70b737fd-40b3-43dd-b582-d49e7451c19e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyResidualSirenNet(\n",
            "  (net_layers): ModuleList(\n",
            "    (0): SineLayer(\n",
            "      (linear): Linear(in_features=3, out_features=150, bias=True)\n",
            "    )\n",
            "    (1-6): 6 x ResidualSineLayer(\n",
            "      (linear_1): Linear(in_features=150, out_features=150, bias=True)\n",
            "      (linear_2): Linear(in_features=150, out_features=150, bias=True)\n",
            "    )\n",
            "    (7): Linear(in_features=150, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 5e-05\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "MSELoss()\n",
            "\n",
            "Learning Rate: 5e-05\n",
            "Max Epochs: 200\n",
            "Batch Size: 512\n",
            "Number of Hidden Layers: 6\n",
            "Number of Neurons per Layer: 150\n",
            "Decay Rate: 0.8\n",
            "Rate decays every 15 epochs.\n",
            "\n"
          ]
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list = []\n",
        "best_epoch = -1\n",
        "best_loss = 1e8\n",
        "best_model=\"\"\n",
        "from tqdm import tqdm\n",
        "# Ensure the output path exists\n",
        "if not os.path.exists(outpath):\n",
        "    os.makedirs(outpath)\n",
        "\n",
        "# Training loop\n",
        "for epoch in tqdm(range(MAX_EPOCH)):\n",
        "    model_mean.train()\n",
        "    temp_loss_list = []\n",
        "    start = time.time()\n",
        "\n",
        "    # Batch-by-batch training\n",
        "    for X_train, y_train in train_dataloader_mean:\n",
        "        X_train = X_train.type(torch.float32).to(device)\n",
        "        y_train = y_train.type(torch.float32).to(device)\n",
        "\n",
        "        if univariate:\n",
        "            y_train = y_train.squeeze()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model_mean(X_train)\n",
        "        predictions = predictions.squeeze()\n",
        "        loss = criterion(predictions, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track batch loss\n",
        "        temp_loss_list.append(loss.detach().cpu().numpy())\n",
        "\n",
        "    # Calculate epoch loss\n",
        "    epoch_loss = np.average(temp_loss_list)\n",
        "\n",
        "    # Learning rate decay\n",
        "    if decay:\n",
        "        if decay_at_equal_interval:\n",
        "            if epoch >= decay_interval and epoch % decay_interval == 0:\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] *= decay_rate\n",
        "        # else:\n",
        "        #     if epoch > 0 and epoch_loss > train_loss_list[-1]:\n",
        "        #         for param_group in optimizer.param_groups:\n",
        "        #             param_group['lr'] *= decay_rate\n",
        "        if epoch > 0 and epoch_loss > train_loss_list[-1]:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] *= decay_rate\n",
        "\n",
        "    # Track losses and best model\n",
        "    train_loss_list.append(epoch_loss)\n",
        "    if epoch_loss < best_loss:\n",
        "        best_loss = epoch_loss\n",
        "        best_epoch = epoch+1\n",
        "        if(best_model==0):\n",
        "            best_model=model_mean.state_dict()\n",
        "        else:\n",
        "            best_model=model_mean.state_dict()\n",
        "\n",
        "    end = time.time()\n",
        "    print(\n",
        "        f\"Epoch: {epoch + 1}/{MAX_EPOCH} | Train Loss: {train_loss_list[-1]} | \"\n",
        "        f\"Time: {round(end - start, 2)}s ({device}) | LR: {optimizer.param_groups[0]['lr']}\"\n",
        "    )\n",
        "\n",
        "    # Save model at intervals\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        model_name = (\n",
        "            f'train_{dataset_name}_{epoch + 1}ep_{n_layers - 2}rb_{n_neurons}n_'\n",
        "            f'{BATCH_SIZE}bs_{LR}lr_{decay}decay_{decay_rate}dr_'\n",
        "            f'{\"decayingAtInterval\" + str(decay_interval)+\"mean\" if decay_at_equal_interval else \"decayingWhenLossIncr\"}'\n",
        "        )\n",
        "        torch.save(\n",
        "            {\"epoch\": epoch + 1, \"model_state_dict\": model_mean.state_dict()},\n",
        "            os.path.join(outpath, f'{model_name}_mean.pth')\n",
        "        )\n",
        "\n",
        "# Final summary\n",
        "print('\\nEpoch with Least Loss:', best_epoch, '| Loss:', best_loss, '\\n')\n",
        "\n",
        "# Save the final model\n",
        "model_name = f'siren_compressor'\n",
        "torch.save(\n",
        "    {\"epoch\": MAX_EPOCH, \"model_state_dict\": model_mean.state_dict()},\n",
        "    os.path.join(outpath, f'{model_name}_mean.pth')\n",
        ")\n",
        "torch.save(\n",
        "    {\"epoch\": best_epoch, \"model_state_dict\": best_model},\n",
        "    os.path.join(outpath, f'{best_epoch}_mean.pth')\n",
        ")\n"
      ],
      "metadata": {
        "_uuid": "16645d61-b423-4e5a-a7d2-5f692a4f6102",
        "_cell_guid": "1c6f398e-b851-4fad-b62e-4080114fa832",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:23.404654Z",
          "iopub.execute_input": "2025-05-26T20:25:23.405027Z",
          "iopub.status.idle": "2025-05-26T20:39:04.911778Z",
          "shell.execute_reply.started": "2025-05-26T20:25:23.405000Z",
          "shell.execute_reply": "2025-05-26T20:39:04.910700Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "dZt3Bxfu5lmS",
        "outputId": "4d398ffd-13ae-485f-a0a1-8194b6e301df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/200 [00:05<18:37,  5.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/200 | Train Loss: 0.007658324204385281 | Time: 5.61s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 2/200 [00:12<21:03,  6.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2/200 | Train Loss: 0.003164463210850954 | Time: 6.92s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 3/200 [00:18<20:03,  6.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3/200 | Train Loss: 0.0028839341830462217 | Time: 5.78s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 4/200 [00:25<21:20,  6.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4/200 | Train Loss: 0.00266069732606411 | Time: 7.19s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 4/200 [00:29<23:55,  7.32s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-48-4132908452.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Batch-by-batch training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RecordFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_as_effectful_op_temporarily\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_in_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fallthrough_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dispatch_in_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfallthrough_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 48
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize prediction lists\n",
        "prediction_list = [[] for _ in range(1)]\n",
        "total_vars=1\n",
        "# Inference loop\n",
        "model_mean = MyResidualSirenNet(obj).to(device)\n",
        "state_dict = torch.load(os.path.join(outpath, '200_mean.pth'))['model_state_dict']\n",
        "model_mean.load_state_dict(state_dict)\n",
        "with torch.no_grad():\n",
        "    for i in range(0, torch_coords.shape[0], group_size):\n",
        "        coords = torch_coords[i:min(i + group_size, torch_coords.shape[0])].type(torch.float32).to(device)\n",
        "        vals = model_mean(coords)\n",
        "        vals = vals.to('cpu')\n",
        "\n",
        "        for j in range(total_vars):\n",
        "            prediction_list[j].append(vals[:, j])\n",
        "\n",
        "# Extract and concatenate predictions\n",
        "extracted_list = [[] for _ in range(1)]\n",
        "for i in range(len(prediction_list[0])):\n",
        "    for j in range(1):\n",
        "        el = prediction_list[j][i].detach().numpy()\n",
        "        extracted_list[j].append(el)\n",
        "\n",
        "for j in range(1):\n",
        "    extracted_list[j] = np.concatenate(extracted_list[j], dtype='float32')\n",
        "\n",
        "# Final prediction (normalized)\n",
        "n_predictions_means = np.array(extracted_list).T\n",
        "\n",
        "# Compute PSNR\n",
        "#findMultiVariatePSNR(var_name[0], total_vars, n_val[:,0], n_predictions_means[:,0])\n",
        "print(\"mean\",compute_PSNR(n_val[:,0],n_predictions_means[:,0]))\n",
        "# Compute RMSE\n",
        "rmse = compute_rmse(n_val[:,0], n_predictions_means[:,0])\n",
        "print(\"RMSE:\", rmse)"
      ],
      "metadata": {
        "_uuid": "07a36d31-db47-4d2c-b11d-5339aa8cb204",
        "_cell_guid": "cc00efa1-e7a5-4a3a-aa44-d056d987dcb8",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:39:04.914949Z",
          "iopub.execute_input": "2025-05-26T20:39:04.915203Z",
          "iopub.status.idle": "2025-05-26T20:39:05.385328Z",
          "shell.execute_reply.started": "2025-05-26T20:39:04.915181Z",
          "shell.execute_reply": "2025-05-26T20:39:05.384428Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NW3xL0y5lmS",
        "outputId": "2127db5d-9d15-46b2-fdbf-1077175f4b9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean 72.7810994165529\n",
            "RMSE: 0.00045917160629419825\n"
          ]
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the DataLoader\n",
        "train_dataloader_std= DataLoader(\n",
        "    TensorDataset(torch_coords, torch_stds),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    pin_memory=True,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "# Model configuration\n",
        "obj = {\n",
        "    'total_vars': 1,\n",
        "    'dim': n_dim,\n",
        "    'n_neurons': n_neurons,\n",
        "    'n_layers': n_layers\n",
        "}\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model_std = MyResidualSirenNet(obj).to(device)\n",
        "print(model_mean)\n",
        "\n",
        "optimizer_std = optim.Adam(model_mean.parameters(), lr=LR, betas=(0.9, 0.999))\n",
        "print(optimizer)\n",
        "\n",
        "criterion_std = nn.MSELoss()\n",
        "print(criterion_std)\n",
        "\n",
        "# Training configuration summary\n",
        "print('\\nLearning Rate:', LR)\n",
        "print('Max Epochs:', MAX_EPOCH)\n",
        "print('Batch Size:', BATCH_SIZE)\n",
        "print('Number of Hidden Layers:', obj['n_layers'] - 2)\n",
        "print('Number of Neurons per Layer:', obj['n_neurons'])\n",
        "\n",
        "if decay:\n",
        "    print('Decay Rate:', decay_rate)\n",
        "    if decay_at_equal_interval:\n",
        "        print(f'Rate decays every {decay_interval} epochs.')\n",
        "    else:\n",
        "        print('Rate decays when the current epoch loss is greater than the previous epoch loss.')\n",
        "else:\n",
        "    print('No decay!')\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v8tpivej35Y",
        "outputId": "d67c1da5-09bb-48e6-c939-95e800dcf67d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyResidualSirenNet(\n",
            "  (net_layers): ModuleList(\n",
            "    (0): SineLayer(\n",
            "      (linear): Linear(in_features=3, out_features=150, bias=True)\n",
            "    )\n",
            "    (1-6): 6 x ResidualSineLayer(\n",
            "      (linear_1): Linear(in_features=150, out_features=150, bias=True)\n",
            "      (linear_2): Linear(in_features=150, out_features=150, bias=True)\n",
            "    )\n",
            "    (7): Linear(in_features=150, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 5e-05\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "MSELoss()\n",
            "\n",
            "Learning Rate: 5e-05\n",
            "Max Epochs: 200\n",
            "Batch Size: 512\n",
            "Number of Hidden Layers: 6\n",
            "Number of Neurons per Layer: 150\n",
            "Decay Rate: 0.8\n",
            "Rate decays every 15 epochs.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list = []\n",
        "best_epoch = -1\n",
        "best_loss = 1e8\n",
        "best_model=\"\"\n",
        "from tqdm import tqdm\n",
        "# Ensure the output path exists\n",
        "if not os.path.exists(outpath):\n",
        "    os.makedirs(outpath)\n",
        "\n",
        "# Training loop\n",
        "for epoch in tqdm(range(MAX_EPOCH)):\n",
        "    model_std.train()\n",
        "    temp_loss_list = []\n",
        "    start = time.time()\n",
        "\n",
        "    # Batch-by-batch training\n",
        "    for X_train, y_train in train_dataloader_std:\n",
        "        X_train = X_train.type(torch.float32).to(device)\n",
        "        y_train = y_train.type(torch.float32).to(device)\n",
        "\n",
        "        if univariate:\n",
        "            y_train = y_train.squeeze()\n",
        "\n",
        "        optimizer_std.zero_grad()\n",
        "        predictions = model_mean(X_train)\n",
        "        predictions = predictions.squeeze()\n",
        "        loss = criterion_std(predictions, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track batch loss\n",
        "        temp_loss_list.append(loss.detach().cpu().numpy())\n",
        "\n",
        "    # Calculate epoch loss\n",
        "    epoch_loss = np.average(temp_loss_list)\n",
        "\n",
        "    # Learning rate decay\n",
        "    if decay:\n",
        "        if decay_at_equal_interval:\n",
        "            if epoch >= decay_interval and epoch % decay_interval == 0:\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] *= decay_rate\n",
        "        # else:\n",
        "        #     if epoch > 0 and epoch_loss > train_loss_list[-1]:\n",
        "        #         for param_group in optimizer.param_groups:\n",
        "        #             param_group['lr'] *= decay_rate\n",
        "        if epoch > 0 and epoch_loss > train_loss_list[-1]:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] *= decay_rate\n",
        "\n",
        "    # Track losses and best model\n",
        "    train_loss_list.append(epoch_loss)\n",
        "    if epoch_loss < best_loss:\n",
        "        best_loss = epoch_loss\n",
        "        best_epoch = epoch+1\n",
        "        if(best_model==0):\n",
        "            best_model=model_mean.state_dict()\n",
        "        else:\n",
        "            best_model=model_mean.state_dict()\n",
        "\n",
        "    end = time.time()\n",
        "    print(\n",
        "        f\"Epoch: {epoch + 1}/{MAX_EPOCH} | Train Loss: {train_loss_list[-1]} | \"\n",
        "        f\"Time: {round(end - start, 2)}s ({device}) | LR: {optimizer.param_groups[0]['lr']}\"\n",
        "    )\n",
        "\n",
        "    # Save model at intervals\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        model_name = (\n",
        "            f'train_{dataset_name}_{epoch + 1}ep_{n_layers - 2}rb_{n_neurons}n_'\n",
        "            f'{BATCH_SIZE}bs_{LR}lr_{decay}decay_{decay_rate}dr_'\n",
        "            f'{\"decayingAtInterval\" + str(decay_interval)+\"std\" if decay_at_equal_interval else \"decayingWhenLossIncr\"}'\n",
        "        )\n",
        "        torch.save(\n",
        "            {\"epoch\": epoch + 1, \"model_state_dict\": model_mean.state_dict()},\n",
        "            os.path.join(outpath, f'{model_name}_std.pth')\n",
        "        )\n",
        "\n",
        "# Final summary\n",
        "print('\\nEpoch with Least Loss:', best_epoch, '| Loss:', best_loss, '\\n')\n",
        "\n",
        "# Save the final model\n",
        "model_name = f'siren_compressor'\n",
        "torch.save(\n",
        "    {\"epoch\": MAX_EPOCH, \"model_state_dict\": model_mean.state_dict()},\n",
        "    os.path.join(outpath, f'{model_name}_std.pth')\n",
        ")\n",
        "torch.save(\n",
        "    {\"epoch\": best_epoch, \"model_state_dict\": best_model},\n",
        "    os.path.join(outpath, f'{best_epoch}_std.pth')\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2rsfR4rkEIO",
        "outputId": "d9d827e2-0d86-4660-d6b7-11e12c021c11"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "  0%|          | 1/200 [00:07<24:17,  7.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/200 | Train Loss: 0.009194845333695412 | Time: 7.32s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 2/200 [00:13<22:01,  6.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2/200 | Train Loss: 0.0028720130212605 | Time: 6.22s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 3/200 [00:20<22:06,  6.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3/200 | Train Loss: 0.002567930379882455 | Time: 6.81s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 4/200 [00:26<20:48,  6.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4/200 | Train Loss: 0.0023847653064876795 | Time: 5.8s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▎         | 5/200 [00:32<21:11,  6.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5/200 | Train Loss: 0.002256781095638871 | Time: 6.8s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 6/200 [00:38<20:15,  6.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6/200 | Train Loss: 0.002154187997803092 | Time: 5.76s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 7/200 [00:45<20:40,  6.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7/200 | Train Loss: 0.002080448204651475 | Time: 6.76s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 8/200 [00:51<19:51,  6.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8/200 | Train Loss: 0.002045626752078533 | Time: 5.74s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 9/200 [00:59<22:09,  6.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9/200 | Train Loss: 0.001972614787518978 | Time: 8.61s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 10/200 [01:05<20:40,  6.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10/200 | Train Loss: 0.0019249295582994819 | Time: 5.56s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 11/200 [01:12<20:44,  6.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11/200 | Train Loss: 0.0018737944774329662 | Time: 6.71s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 12/200 [01:17<19:43,  6.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12/200 | Train Loss: 0.0018399524269625545 | Time: 5.63s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 13/200 [01:24<20:08,  6.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13/200 | Train Loss: 0.001806402113288641 | Time: 6.84s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 14/200 [01:30<19:17,  6.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 14/200 | Train Loss: 0.0017818710766732693 | Time: 5.68s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 15/200 [01:36<19:14,  6.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 15/200 | Train Loss: 0.0017433357425034046 | Time: 6.28s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 16/200 [01:42<18:51,  6.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 16/200 | Train Loss: 0.0016952555160969496 | Time: 5.93s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 17/200 [01:48<19:01,  6.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 17/200 | Train Loss: 0.0014271930558606982 | Time: 6.44s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 18/200 [01:56<19:50,  6.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 18/200 | Train Loss: 0.001263576908968389 | Time: 7.23s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 19/200 [02:02<19:27,  6.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 19/200 | Train Loss: 0.0012481918092817068 | Time: 6.24s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 20/200 [02:08<19:05,  6.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20/200 | Train Loss: 0.0012059148866683245 | Time: 6.16s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 21/200 [02:14<18:41,  6.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 21/200 | Train Loss: 0.0011958950199186802 | Time: 6.03s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 22/200 [02:20<18:38,  6.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 22/200 | Train Loss: 0.001171864802017808 | Time: 6.32s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 23/200 [02:27<18:26,  6.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 23/200 | Train Loss: 0.0011311592534184456 | Time: 6.18s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 24/200 [02:33<18:28,  6.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 24/200 | Train Loss: 0.001101246802136302 | Time: 6.41s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 25/200 [02:39<17:51,  6.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25/200 | Train Loss: 0.0010757476557046175 | Time: 5.71s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 26/200 [02:45<18:19,  6.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 26/200 | Train Loss: 0.0010798744624480605 | Time: 6.77s (cuda) | LR: 3.2000000000000005e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 27/200 [02:51<17:48,  6.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 27/200 | Train Loss: 0.0008635143749415874 | Time: 5.84s (cuda) | LR: 3.2000000000000005e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 28/200 [02:58<18:27,  6.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 28/200 | Train Loss: 0.0007373134139925241 | Time: 7.04s (cuda) | LR: 3.2000000000000005e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 29/200 [03:04<17:34,  6.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 29/200 | Train Loss: 0.0007226869929581881 | Time: 5.54s (cuda) | LR: 3.2000000000000005e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 30/200 [03:11<18:07,  6.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 30/200 | Train Loss: 0.0007169503951445222 | Time: 6.92s (cuda) | LR: 3.2000000000000005e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 31/200 [03:17<17:24,  6.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 31/200 | Train Loss: 0.0007171737961471081 | Time: 5.68s (cuda) | LR: 2.0480000000000007e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 32/200 [03:23<17:49,  6.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 32/200 | Train Loss: 0.0005033459165133536 | Time: 6.79s (cuda) | LR: 2.0480000000000007e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▋        | 33/200 [03:29<17:11,  6.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 33/200 | Train Loss: 0.00037924444768577814 | Time: 5.75s (cuda) | LR: 2.0480000000000007e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 34/200 [03:36<18:00,  6.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 34/200 | Train Loss: 0.0003605893871281296 | Time: 7.27s (cuda) | LR: 2.0480000000000007e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 35/200 [03:43<17:48,  6.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 35/200 | Train Loss: 0.0003632013394962996 | Time: 6.41s (cuda) | LR: 1.6384000000000008e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 36/200 [03:50<18:03,  6.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 36/200 | Train Loss: 0.0003051134408451617 | Time: 6.9s (cuda) | LR: 1.6384000000000008e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 37/200 [03:55<17:14,  6.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 37/200 | Train Loss: 0.00026360899209976196 | Time: 5.75s (cuda) | LR: 1.6384000000000008e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 38/200 [04:02<17:28,  6.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 38/200 | Train Loss: 0.00025372434174641967 | Time: 6.75s (cuda) | LR: 1.6384000000000008e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 39/200 [04:08<16:39,  6.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 39/200 | Train Loss: 0.0002518624532967806 | Time: 5.59s (cuda) | LR: 1.6384000000000008e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 40/200 [04:15<17:04,  6.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 40/200 | Train Loss: 0.0002549409109633416 | Time: 6.86s (cuda) | LR: 1.3107200000000007e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 41/200 [04:20<16:22,  6.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 41/200 | Train Loss: 0.0002009312156587839 | Time: 5.66s (cuda) | LR: 1.3107200000000007e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 42/200 [04:27<16:56,  6.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 42/200 | Train Loss: 0.00017993434448726475 | Time: 7.02s (cuda) | LR: 1.3107200000000007e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 43/200 [04:33<16:17,  6.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 43/200 | Train Loss: 0.00017502898117527366 | Time: 5.73s (cuda) | LR: 1.3107200000000007e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 44/200 [04:40<16:46,  6.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 44/200 | Train Loss: 0.00017678514996077865 | Time: 6.98s (cuda) | LR: 1.0485760000000006e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▎       | 45/200 [04:46<16:08,  6.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 45/200 | Train Loss: 0.00013968873827252537 | Time: 5.77s (cuda) | LR: 1.0485760000000006e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 46/200 [04:53<16:26,  6.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 46/200 | Train Loss: 0.00012119787425035611 | Time: 6.77s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 47/200 [04:58<15:51,  6.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 47/200 | Train Loss: 0.00010115245095221326 | Time: 5.78s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 48/200 [05:05<16:17,  6.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 48/200 | Train Loss: 9.331183537142351e-05 | Time: 6.93s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 49/200 [05:11<15:37,  6.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 49/200 | Train Loss: 9.314632916357368e-05 | Time: 5.69s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 50/200 [05:18<15:48,  6.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 50/200 | Train Loss: 9.266989945899695e-05 | Time: 6.58s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 51/200 [05:23<15:21,  6.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 51/200 | Train Loss: 9.248766582459211e-05 | Time: 5.85s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 52/200 [05:30<15:21,  6.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 52/200 | Train Loss: 9.111529652727768e-05 | Time: 6.33s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 53/200 [05:36<15:14,  6.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 53/200 | Train Loss: 8.882123074727133e-05 | Time: 6.2s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 54/200 [05:42<14:53,  6.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 54/200 | Train Loss: 8.706046355655417e-05 | Time: 5.88s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 55/200 [05:48<15:01,  6.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 55/200 | Train Loss: 8.519968832843006e-05 | Time: 6.45s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 56/200 [05:54<14:29,  6.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 56/200 | Train Loss: 8.34684178698808e-05 | Time: 5.63s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 57/200 [06:01<14:58,  6.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 57/200 | Train Loss: 8.186904597096145e-05 | Time: 6.84s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 58/200 [06:06<14:21,  6.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 58/200 | Train Loss: 8.040765533223748e-05 | Time: 5.55s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 59/200 [06:13<14:39,  6.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 59/200 | Train Loss: 7.892186113167554e-05 | Time: 6.65s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 60/200 [06:18<14:03,  6.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 60/200 | Train Loss: 7.838320743758231e-05 | Time: 5.51s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 61/200 [06:25<14:26,  6.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 61/200 | Train Loss: 7.728775381110609e-05 | Time: 6.73s (cuda) | LR: 6.7108864000000044e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 62/200 [06:31<13:59,  6.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 62/200 | Train Loss: 6.098553421907127e-05 | Time: 5.74s (cuda) | LR: 6.7108864000000044e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 63/200 [06:38<14:18,  6.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 63/200 | Train Loss: 5.2002393204020336e-05 | Time: 6.69s (cuda) | LR: 6.7108864000000044e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 64/200 [06:43<13:38,  6.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 64/200 | Train Loss: 5.253678682493046e-05 | Time: 5.44s (cuda) | LR: 5.368709120000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▎      | 65/200 [06:50<13:55,  6.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 65/200 | Train Loss: 4.456890019355342e-05 | Time: 6.58s (cuda) | LR: 5.368709120000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 66/200 [06:55<13:24,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 66/200 | Train Loss: 4.008863470517099e-05 | Time: 5.57s (cuda) | LR: 5.368709120000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▎      | 67/200 [07:02<13:54,  6.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 67/200 | Train Loss: 4.040004932903685e-05 | Time: 6.9s (cuda) | LR: 4.294967296000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 68/200 [07:08<13:16,  6.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 68/200 | Train Loss: 3.446186019573361e-05 | Time: 5.48s (cuda) | LR: 4.294967296000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 69/200 [07:14<13:19,  6.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 69/200 | Train Loss: 3.1503106583841145e-05 | Time: 6.27s (cuda) | LR: 4.294967296000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 70/200 [07:20<13:00,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 70/200 | Train Loss: 3.1692306947661564e-05 | Time: 5.76s (cuda) | LR: 3.4359738368000033e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 71/200 [07:26<12:51,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 71/200 | Train Loss: 2.7369529561838135e-05 | Time: 5.94s (cuda) | LR: 3.4359738368000033e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 72/200 [07:32<12:58,  6.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 72/200 | Train Loss: 2.5489687686786056e-05 | Time: 6.31s (cuda) | LR: 3.4359738368000033e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▋      | 73/200 [07:38<12:41,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 73/200 | Train Loss: 2.529530320316553e-05 | Time: 5.79s (cuda) | LR: 3.4359738368000033e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 74/200 [07:44<12:56,  6.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 74/200 | Train Loss: 2.5374876713613048e-05 | Time: 6.54s (cuda) | LR: 2.7487790694400027e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 75/200 [07:50<12:27,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 75/200 | Train Loss: 2.1933414245722815e-05 | Time: 5.54s (cuda) | LR: 2.7487790694400027e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 76/200 [07:56<12:48,  6.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 76/200 | Train Loss: 2.046031477220822e-05 | Time: 6.7s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 77/200 [08:02<12:22,  6.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 77/200 | Train Loss: 1.8081935195368715e-05 | Time: 5.66s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 78/200 [08:09<12:36,  6.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 78/200 | Train Loss: 1.74171946127899e-05 | Time: 6.6s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 79/200 [08:14<12:05,  5.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 79/200 | Train Loss: 1.7379083146806806e-05 | Time: 5.5s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 80/200 [08:21<12:23,  6.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 80/200 | Train Loss: 1.726246773614548e-05 | Time: 6.66s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 81/200 [08:26<11:53,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 81/200 | Train Loss: 1.7056248907465488e-05 | Time: 5.53s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 82/200 [08:33<12:11,  6.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 82/200 | Train Loss: 1.6797839634818956e-05 | Time: 6.67s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 83/200 [08:39<11:40,  5.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 83/200 | Train Loss: 1.6604648408247158e-05 | Time: 5.49s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 84/200 [08:45<11:56,  6.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 84/200 | Train Loss: 1.6378024156438187e-05 | Time: 6.61s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▎     | 85/200 [08:51<11:24,  5.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 85/200 | Train Loss: 1.6081434296211228e-05 | Time: 5.44s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 86/200 [08:57<11:26,  6.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 86/200 | Train Loss: 1.582074946782086e-05 | Time: 6.18s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▎     | 87/200 [09:03<11:16,  5.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 87/200 | Train Loss: 1.560833516123239e-05 | Time: 5.9s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 88/200 [09:08<10:54,  5.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 88/200 | Train Loss: 1.5363335478468798e-05 | Time: 5.51s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 89/200 [09:15<11:03,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 89/200 | Train Loss: 1.5172907296800986e-05 | Time: 6.29s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 90/200 [09:20<10:36,  5.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 90/200 | Train Loss: 1.4965848095016554e-05 | Time: 5.32s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 91/200 [09:26<10:52,  5.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 91/200 | Train Loss: 1.4686915164929815e-05 | Time: 6.47s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 92/200 [09:32<10:29,  5.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 92/200 | Train Loss: 1.2878527741122525e-05 | Time: 5.47s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▋     | 93/200 [09:38<10:40,  5.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 93/200 | Train Loss: 1.2308186342124827e-05 | Time: 6.35s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 94/200 [09:43<10:13,  5.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 94/200 | Train Loss: 1.2218693882459775e-05 | Time: 5.31s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 95/200 [09:50<10:28,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 95/200 | Train Loss: 1.2180093108327128e-05 | Time: 6.44s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 96/200 [09:55<10:01,  5.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 96/200 | Train Loss: 1.2073998732375912e-05 | Time: 5.32s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 97/200 [10:02<10:11,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 97/200 | Train Loss: 1.192901618196629e-05 | Time: 6.29s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 98/200 [10:07<09:54,  5.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 98/200 | Train Loss: 1.1789223208324984e-05 | Time: 5.57s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|████▉     | 99/200 [10:12<09:31,  5.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 99/200 | Train Loss: 1.164587683888385e-05 | Time: 5.25s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 100/200 [10:19<09:46,  5.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100/200 | Train Loss: 1.1499580068630166e-05 | Time: 6.36s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 101/200 [10:24<09:21,  5.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 101/200 | Train Loss: 1.1378539056750014e-05 | Time: 5.22s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 102/200 [10:31<09:42,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 102/200 | Train Loss: 1.1186569281562697e-05 | Time: 6.56s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 103/200 [10:36<09:19,  5.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 103/200 | Train Loss: 1.1100564734078944e-05 | Time: 5.35s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 104/200 [10:42<09:33,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 104/200 | Train Loss: 1.0982342246279586e-05 | Time: 6.48s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▎    | 105/200 [10:48<09:09,  5.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 105/200 | Train Loss: 1.0844923053809907e-05 | Time: 5.34s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 106/200 [10:54<09:26,  6.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 106/200 | Train Loss: 1.0717850273067597e-05 | Time: 6.58s (cuda) | LR: 1.4073748835532816e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▎    | 107/200 [11:00<09:02,  5.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 107/200 | Train Loss: 9.453588063479401e-06 | Time: 5.39s (cuda) | LR: 1.4073748835532816e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 108/200 [11:06<09:13,  6.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 108/200 | Train Loss: 9.031826266436838e-06 | Time: 6.43s (cuda) | LR: 1.4073748835532816e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 109/200 [11:12<08:57,  5.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 109/200 | Train Loss: 9.052893801708706e-06 | Time: 5.64s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 110/200 [11:17<08:44,  5.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 110/200 | Train Loss: 8.17463660496287e-06 | Time: 5.63s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 111/200 [11:24<08:46,  5.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 111/200 | Train Loss: 7.946956429805141e-06 | Time: 6.14s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 112/200 [11:29<08:26,  5.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 112/200 | Train Loss: 7.934586392366327e-06 | Time: 5.37s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▋    | 113/200 [11:35<08:42,  6.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 113/200 | Train Loss: 7.896715942479204e-06 | Time: 6.6s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 114/200 [11:41<08:18,  5.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 114/200 | Train Loss: 7.831221410015132e-06 | Time: 5.29s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▊    | 115/200 [11:47<08:28,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 115/200 | Train Loss: 7.776048732921481e-06 | Time: 6.42s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 116/200 [11:52<08:05,  5.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 116/200 | Train Loss: 7.713934792263899e-06 | Time: 5.3s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 117/200 [11:59<08:16,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 117/200 | Train Loss: 7.623189958394505e-06 | Time: 6.45s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 118/200 [12:04<07:56,  5.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 118/200 | Train Loss: 7.567256943730172e-06 | Time: 5.39s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 119/200 [12:11<08:00,  5.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 119/200 | Train Loss: 7.487641596526373e-06 | Time: 6.21s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 120/200 [12:16<07:44,  5.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 120/200 | Train Loss: 7.426900538121117e-06 | Time: 5.51s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 121/200 [12:22<07:35,  5.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 121/200 | Train Loss: 7.334077963605523e-06 | Time: 5.69s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 122/200 [12:28<07:33,  5.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 122/200 | Train Loss: 6.676857537968317e-06 | Time: 5.9s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 123/200 [12:33<07:18,  5.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 123/200 | Train Loss: 6.523503088828875e-06 | Time: 5.44s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 124/200 [12:39<07:28,  5.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 124/200 | Train Loss: 6.481851869466482e-06 | Time: 6.35s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▎   | 125/200 [12:45<07:12,  5.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 125/200 | Train Loss: 6.4576524891890585e-06 | Time: 5.47s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 126/200 [12:51<07:20,  5.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 126/200 | Train Loss: 6.410508831322659e-06 | Time: 6.4s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▎   | 127/200 [12:57<07:00,  5.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 127/200 | Train Loss: 6.364515229506651e-06 | Time: 5.3s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 128/200 [13:03<07:11,  5.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 128/200 | Train Loss: 6.3165371102513745e-06 | Time: 6.54s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 129/200 [13:09<06:52,  5.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 129/200 | Train Loss: 6.265262072702171e-06 | Time: 5.39s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 130/200 [13:15<07:01,  6.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 130/200 | Train Loss: 6.213703272806015e-06 | Time: 6.48s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 131/200 [13:20<06:41,  5.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 131/200 | Train Loss: 6.170053893583827e-06 | Time: 5.35s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 132/200 [13:26<06:30,  5.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 132/200 | Train Loss: 6.105942702561151e-06 | Time: 5.58s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▋   | 133/200 [13:32<06:29,  5.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 133/200 | Train Loss: 6.05967034061905e-06 | Time: 5.98s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 134/200 [13:37<06:17,  5.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 134/200 | Train Loss: 6.016886345605599e-06 | Time: 5.5s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 135/200 [13:44<06:29,  5.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 135/200 | Train Loss: 5.964640877209604e-06 | Time: 6.6s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 136/200 [13:49<06:10,  5.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 136/200 | Train Loss: 5.914996563660679e-06 | Time: 5.31s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 137/200 [13:56<06:13,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 137/200 | Train Loss: 5.435798811959103e-06 | Time: 6.28s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 138/200 [14:01<05:54,  5.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 138/200 | Train Loss: 5.33256343260291e-06 | Time: 5.23s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 139/200 [14:07<06:04,  5.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 139/200 | Train Loss: 5.308048457663972e-06 | Time: 6.54s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 140/200 [14:13<05:46,  5.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 140/200 | Train Loss: 5.2884201977576595e-06 | Time: 5.31s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 141/200 [14:19<05:51,  5.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 141/200 | Train Loss: 5.255395535641583e-06 | Time: 6.39s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 142/200 [14:24<05:33,  5.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 142/200 | Train Loss: 5.218447768129408e-06 | Time: 5.25s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 143/200 [14:30<05:23,  5.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 143/200 | Train Loss: 5.190965566725936e-06 | Time: 5.51s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 144/200 [14:36<05:27,  5.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 144/200 | Train Loss: 5.1592123782029375e-06 | Time: 6.27s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▎  | 145/200 [14:42<05:13,  5.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 145/200 | Train Loss: 5.115273779665586e-06 | Time: 5.32s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 146/200 [14:48<05:18,  5.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 146/200 | Train Loss: 5.0816015573218465e-06 | Time: 6.36s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 147/200 [14:53<05:03,  5.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 147/200 | Train Loss: 5.04785384691786e-06 | Time: 5.35s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 148/200 [15:00<05:11,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 148/200 | Train Loss: 5.012972906115465e-06 | Time: 6.62s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 149/200 [15:05<04:57,  5.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 149/200 | Train Loss: 4.97570181323681e-06 | Time: 5.45s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 150/200 [15:12<04:59,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 150/200 | Train Loss: 4.943174644722603e-06 | Time: 6.37s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 151/200 [15:17<04:43,  5.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 151/200 | Train Loss: 4.9192340156878345e-06 | Time: 5.32s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 152/200 [15:23<04:46,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 152/200 | Train Loss: 4.558860382530838e-06 | Time: 6.4s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 153/200 [15:29<04:30,  5.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 153/200 | Train Loss: 4.487210389925167e-06 | Time: 5.21s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 154/200 [15:34<04:25,  5.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 154/200 | Train Loss: 4.468001861823723e-06 | Time: 5.85s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 155/200 [15:40<04:21,  5.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 155/200 | Train Loss: 4.454514964891132e-06 | Time: 5.9s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 156/200 [15:46<04:07,  5.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 156/200 | Train Loss: 4.433964022609871e-06 | Time: 5.21s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 157/200 [15:52<04:12,  5.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 157/200 | Train Loss: 4.40819621871924e-06 | Time: 6.43s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 158/200 [15:57<03:58,  5.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 158/200 | Train Loss: 4.3815161916427314e-06 | Time: 5.23s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 159/200 [16:04<04:00,  5.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 159/200 | Train Loss: 4.356323643150972e-06 | Time: 6.31s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 160/200 [16:09<03:49,  5.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 160/200 | Train Loss: 4.336805432103574e-06 | Time: 5.45s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 161/200 [16:15<03:51,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 161/200 | Train Loss: 4.311411885282723e-06 | Time: 6.38s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 162/200 [16:21<03:38,  5.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 162/200 | Train Loss: 4.282331701688236e-06 | Time: 5.27s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 163/200 [16:27<03:33,  5.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 163/200 | Train Loss: 4.259857632860076e-06 | Time: 5.88s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 164/200 [16:32<03:27,  5.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 164/200 | Train Loss: 4.2304391172365285e-06 | Time: 5.7s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▎ | 165/200 [16:38<03:17,  5.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 165/200 | Train Loss: 4.2101564758922905e-06 | Time: 5.38s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 166/200 [16:44<03:18,  5.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 166/200 | Train Loss: 4.18280342273647e-06 | Time: 6.32s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 167/200 [16:49<03:07,  5.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 167/200 | Train Loss: 3.91786488762591e-06 | Time: 5.31s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 168/200 [16:56<03:09,  5.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 168/200 | Train Loss: 3.8706775740138255e-06 | Time: 6.47s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 169/200 [17:01<02:56,  5.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 169/200 | Train Loss: 3.86031251764507e-06 | Time: 5.2s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 170/200 [17:07<02:57,  5.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 170/200 | Train Loss: 3.844495950033888e-06 | Time: 6.45s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 171/200 [17:13<02:45,  5.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 171/200 | Train Loss: 3.834471954178298e-06 | Time: 5.21s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 172/200 [17:19<02:45,  5.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 172/200 | Train Loss: 3.8144112295412924e-06 | Time: 6.4s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 173/200 [17:24<02:33,  5.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 173/200 | Train Loss: 3.792488314502407e-06 | Time: 5.18s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 174/200 [17:30<02:27,  5.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 174/200 | Train Loss: 3.7766772038594354e-06 | Time: 5.62s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 175/200 [17:36<02:24,  5.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 175/200 | Train Loss: 3.755343868760974e-06 | Time: 5.99s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 176/200 [17:41<02:15,  5.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 176/200 | Train Loss: 3.743026354641188e-06 | Time: 5.4s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 177/200 [17:47<02:14,  5.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 177/200 | Train Loss: 3.7256208997860085e-06 | Time: 6.25s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 178/200 [17:53<02:05,  5.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 178/200 | Train Loss: 3.703330094140256e-06 | Time: 5.32s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 179/200 [17:59<02:03,  5.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 179/200 | Train Loss: 3.6845206068392145e-06 | Time: 6.35s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 180/200 [18:04<01:53,  5.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 180/200 | Train Loss: 3.6678052310890052e-06 | Time: 5.26s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 181/200 [18:11<01:52,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 181/200 | Train Loss: 3.6511689813778503e-06 | Time: 6.5s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 182/200 [18:16<01:43,  5.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 182/200 | Train Loss: 3.4483091440051794e-06 | Time: 5.24s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 183/200 [18:22<01:39,  5.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 183/200 | Train Loss: 3.4178287933173124e-06 | Time: 6.1s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 184/200 [18:28<01:33,  5.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 184/200 | Train Loss: 3.40724704983586e-06 | Time: 5.8s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▎| 185/200 [18:34<01:26,  5.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 185/200 | Train Loss: 3.394984560145531e-06 | Time: 5.59s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 186/200 [18:40<01:23,  5.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 186/200 | Train Loss: 3.3851774787763134e-06 | Time: 6.4s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 187/200 [18:45<01:14,  5.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 187/200 | Train Loss: 3.372001174284378e-06 | Time: 5.24s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 188/200 [18:52<01:11,  5.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 188/200 | Train Loss: 3.3582141441002022e-06 | Time: 6.39s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 189/200 [18:57<01:03,  5.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 189/200 | Train Loss: 3.345701088619535e-06 | Time: 5.35s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 190/200 [19:04<01:00,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 190/200 | Train Loss: 3.334504071972333e-06 | Time: 6.57s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 191/200 [19:09<00:53,  5.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 191/200 | Train Loss: 3.317104528832715e-06 | Time: 5.68s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 192/200 [19:16<00:48,  6.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 192/200 | Train Loss: 3.307384304207517e-06 | Time: 6.46s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▋| 193/200 [19:21<00:40,  5.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 193/200 | Train Loss: 3.29325303027872e-06 | Time: 5.32s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 194/200 [19:27<00:36,  6.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 194/200 | Train Loss: 3.279236580056022e-06 | Time: 6.39s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 195/200 [19:33<00:29,  5.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 195/200 | Train Loss: 3.2624909636069788e-06 | Time: 5.35s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 196/200 [19:39<00:23,  5.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 196/200 | Train Loss: 3.25239852827508e-06 | Time: 5.97s (cuda) | LR: 2.9514790517935326e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 197/200 [19:45<00:17,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 197/200 | Train Loss: 3.0981609597802162e-06 | Time: 6.14s (cuda) | LR: 2.9514790517935326e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 198/200 [19:50<00:11,  5.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 198/200 | Train Loss: 3.0763708309677895e-06 | Time: 5.32s (cuda) | LR: 2.9514790517935326e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 199/200 [19:57<00:05,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 199/200 | Train Loss: 3.0682040232932195e-06 | Time: 6.56s (cuda) | LR: 2.9514790517935326e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [20:02<00:00,  6.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 200/200 | Train Loss: 3.056057266803691e-06 | Time: 5.36s (cuda) | LR: 2.9514790517935326e-07\n",
            "\n",
            "Epoch with Least Loss: 200 | Loss: 3.0560573e-06 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize prediction lists\n",
        "# Initialize prediction lists\n",
        "prediction_list = [[] for _ in range(1)]\n",
        "total_vars=1\n",
        "# Inference loop\n",
        "model_mean = MyResidualSirenNet(obj).to(device)\n",
        "state_dict = torch.load(os.path.join(outpath, '200_std.pth'))['model_state_dict']\n",
        "model_mean.load_state_dict(state_dict)\n",
        "with torch.no_grad():\n",
        "    for i in range(0, torch_coords.shape[0], group_size):\n",
        "        coords = torch_coords[i:min(i + group_size, torch_coords.shape[0])].type(torch.float32).to(device)\n",
        "        vals = model_mean(coords)\n",
        "        vals = vals.to('cpu')\n",
        "\n",
        "        for j in range(total_vars):\n",
        "            prediction_list[j].append(vals[:, j])\n",
        "\n",
        "# Extract and concatenate predictions\n",
        "extracted_list = [[] for _ in range(1)]\n",
        "for i in range(len(prediction_list[0])):\n",
        "    for j in range(1):\n",
        "        el = prediction_list[j][i].detach().numpy()\n",
        "        extracted_list[j].append(el)\n",
        "\n",
        "for j in range(1):\n",
        "    extracted_list[j] = np.concatenate(extracted_list[j], dtype='float32')\n",
        "\n",
        "# Final prediction (normalized)\n",
        "n_predictions_stds = np.array(extracted_list).T\n",
        "print(n_predictions_stds.shape)\n",
        "# Compute PSNR\n",
        "#findMultiVariatePSNR(var_name[0], total_vars, n_val[:,0], n_predictions_means[:,0])\n",
        "print(\"std\",compute_PSNR(n_val[:,1],n_predictions_stds[:,0]))\n",
        "# Compute RMSE\n",
        "rmse = compute_rmse(n_val[:,1], n_predictions_stds[:,0])\n",
        "print(\"RMSE:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZbOQXB_kwk5",
        "outputId": "0033869e-7a16-460c-f375-be1ca074cf80"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(262144, 1)\n",
            "std 61.882343845798715\n",
            "RMSE: 0.001610322285992644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_predictions = np.concatenate([n_predictions_means, n_predictions_stds], axis=1)\n",
        "# !rm -rf /kaggle/working/*"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-26T20:39:05.386663Z",
          "iopub.execute_input": "2025-05-26T20:39:05.386998Z",
          "iopub.status.idle": "2025-05-26T20:39:05.390530Z",
          "shell.execute_reply.started": "2025-05-26T20:39:05.386966Z",
          "shell.execute_reply": "2025-05-26T20:39:05.389710Z"
        },
        "id": "_CEE5B8g5lmT"
      },
      "outputs": [],
      "execution_count": 24
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.path.getsize('/kaggle/working/models/train_3d_data_200ep_6rb_320n_512bs_5e-05lr_Truedecay_0.8dr_decayingAtInterval15.pth') / (1024 ** 2), 'MB')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-26T20:42:22.099537Z",
          "iopub.execute_input": "2025-05-26T20:42:22.099844Z",
          "iopub.status.idle": "2025-05-26T20:42:22.105129Z",
          "shell.execute_reply.started": "2025-05-26T20:42:22.099821Z",
          "shell.execute_reply": "2025-05-26T20:42:22.104165Z"
        },
        "id": "6UBTlK7L5lmT",
        "outputId": "69ceab23-5b68-44f6-bd71-ecdd8769add2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "4.731752395629883 MB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # vti saving path\n",
        "vti_path = args.vti_path\n",
        "if not os.path.exists(vti_path):\n",
        "    os.makedirs(vti_path)\n",
        "# vti name\n",
        "vti_name = args.vti_name\n",
        "isMaskPresent = False\n",
        "mask_arr = []\n",
        "total_vars=2\n",
        "makeVTI(data,real_data, n_predictions, n_pts, total_vars, var_name, dim, isMaskPresent, mask_arr, vti_path, vti_name)"
      ],
      "metadata": {
        "_uuid": "8987b9b8-de2f-448c-995c-28bee1a033eb",
        "_cell_guid": "6f9d6b16-aa9c-4808-81e8-a4d1e00459d2",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:39:05.443004Z",
          "iopub.status.idle": "2025-05-26T20:39:05.443267Z",
          "shell.execute_reply": "2025-05-26T20:39:05.443158Z"
        },
        "id": "htWe2iW35lmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc342256-30c6-4bed-fb73-3cd3cbc1d7a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vti File written successfully at ./data/predicted.vti\n"
          ]
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1tNS_Rattjqk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}