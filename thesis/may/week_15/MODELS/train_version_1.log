nohup: ignoring input
Using device: cuda
Training started
Epoch 0 | Loss: 0.013736 | LR: 0.000050
Epoch 1 | Loss: 0.011323 | LR: 0.000050
Epoch 2 | Loss: 0.011270 | LR: 0.000050
Epoch 3 | Loss: 0.011222 | LR: 0.000050
Epoch 4 | Loss: 0.011180 | LR: 0.000050
Epoch 5 | Loss: 0.011137 | LR: 0.000050
Epoch 6 | Loss: 0.011100 | LR: 0.000050
Epoch 7 | Loss: 0.011066 | LR: 0.000050
Epoch 8 | Loss: 0.011042 | LR: 0.000050
Epoch 9 | Loss: 0.011018 | LR: 0.000050
Epoch 10 | Loss: 0.011002 | LR: 0.000050
Epoch 11 | Loss: 0.010984 | LR: 0.000050
Epoch 12 | Loss: 0.010967 | LR: 0.000050
Epoch 13 | Loss: 0.010955 | LR: 0.000050
Epoch 14 | Loss: 0.010945 | LR: 0.000040
Epoch 15 | Loss: 0.010831 | LR: 0.000040
Epoch 16 | Loss: 0.010771 | LR: 0.000040
Epoch 17 | Loss: 0.010731 | LR: 0.000040
Epoch 18 | Loss: 0.010695 | LR: 0.000040
Epoch 19 | Loss: 0.010667 | LR: 0.000040
Epoch 20 | Loss: 0.010644 | LR: 0.000040
Epoch 21 | Loss: 0.010622 | LR: 0.000040
Epoch 22 | Loss: 0.010604 | LR: 0.000040
Epoch 23 | Loss: 0.010587 | LR: 0.000040
Epoch 24 | Loss: 0.010574 | LR: 0.000040
Epoch 25 | Loss: 0.010560 | LR: 0.000040
Epoch 26 | Loss: 0.010548 | LR: 0.000040
Epoch 27 | Loss: 0.010541 | LR: 0.000040
Epoch 28 | Loss: 0.010525 | LR: 0.000040
Epoch 29 | Loss: 0.010514 | LR: 0.000032
Epoch 30 | Loss: 0.010371 | LR: 0.000032
Epoch 31 | Loss: 0.010310 | LR: 0.000032
Epoch 32 | Loss: 0.010267 | LR: 0.000032
Epoch 33 | Loss: 0.010236 | LR: 0.000032
Epoch 34 | Loss: 0.010207 | LR: 0.000032
Epoch 35 | Loss: 0.010189 | LR: 0.000032
Epoch 36 | Loss: 0.010170 | LR: 0.000032
Epoch 37 | Loss: 0.010154 | LR: 0.000032
Epoch 38 | Loss: 0.010139 | LR: 0.000032
Epoch 39 | Loss: 0.010127 | LR: 0.000032
Epoch 40 | Loss: 0.010116 | LR: 0.000032
Epoch 41 | Loss: 0.010105 | LR: 0.000032
Epoch 42 | Loss: 0.010097 | LR: 0.000032
Epoch 43 | Loss: 0.010088 | LR: 0.000032
Epoch 44 | Loss: 0.010080 | LR: 0.000026
Epoch 45 | Loss: 0.009923 | LR: 0.000026
Epoch 46 | Loss: 0.009865 | LR: 0.000026
Epoch 47 | Loss: 0.009834 | LR: 0.000026
Epoch 48 | Loss: 0.009811 | LR: 0.000026
Epoch 49 | Loss: 0.009792 | LR: 0.000026
Epoch 50 | Loss: 0.009778 | LR: 0.000026
Epoch 51 | Loss: 0.009764 | LR: 0.000026
Epoch 52 | Loss: 0.009755 | LR: 0.000026
Epoch 53 | Loss: 0.009744 | LR: 0.000026
Epoch 54 | Loss: 0.009735 | LR: 0.000026
Epoch 55 | Loss: 0.009724 | LR: 0.000026
Epoch 56 | Loss: 0.009718 | LR: 0.000026
Epoch 57 | Loss: 0.009710 | LR: 0.000026
Epoch 58 | Loss: 0.009704 | LR: 0.000026
Epoch 59 | Loss: 0.009699 | LR: 0.000020
Epoch 60 | Loss: 0.009538 | LR: 0.000020
Epoch 61 | Loss: 0.009494 | LR: 0.000020
Epoch 62 | Loss: 0.009472 | LR: 0.000020
Epoch 63 | Loss: 0.009456 | LR: 0.000020
Epoch 64 | Loss: 0.009438 | LR: 0.000020
Epoch 65 | Loss: 0.009429 | LR: 0.000020
Epoch 66 | Loss: 0.009420 | LR: 0.000020
Epoch 67 | Loss: 0.009414 | LR: 0.000020
Epoch 68 | Loss: 0.009404 | LR: 0.000020
Epoch 69 | Loss: 0.009397 | LR: 0.000020
Epoch 70 | Loss: 0.009392 | LR: 0.000020
Epoch 71 | Loss: 0.009387 | LR: 0.000020
Epoch 72 | Loss: 0.009381 | LR: 0.000020
Epoch 73 | Loss: 0.009377 | LR: 0.000020
Epoch 74 | Loss: 0.009372 | LR: 0.000016
Epoch 75 | Loss: 0.009220 | LR: 0.000016
Epoch 76 | Loss: 0.009183 | LR: 0.000016
Epoch 77 | Loss: 0.009165 | LR: 0.000016
Epoch 78 | Loss: 0.009153 | LR: 0.000016
Epoch 79 | Loss: 0.009144 | LR: 0.000016
Epoch 80 | Loss: 0.009136 | LR: 0.000016
Epoch 81 | Loss: 0.009128 | LR: 0.000016
Epoch 82 | Loss: 0.009123 | LR: 0.000016
Epoch 83 | Loss: 0.009115 | LR: 0.000016
Epoch 84 | Loss: 0.009110 | LR: 0.000016
Epoch 85 | Loss: 0.009107 | LR: 0.000016
Epoch 86 | Loss: 0.009103 | LR: 0.000016
Epoch 87 | Loss: 0.009096 | LR: 0.000016
Epoch 88 | Loss: 0.009095 | LR: 0.000016
Epoch 89 | Loss: 0.009089 | LR: 0.000013
Epoch 90 | Loss: 0.008952 | LR: 0.000013
Epoch 91 | Loss: 0.008921 | LR: 0.000013
Epoch 92 | Loss: 0.008908 | LR: 0.000013
Epoch 93 | Loss: 0.008899 | LR: 0.000013
Epoch 94 | Loss: 0.008891 | LR: 0.000013
Epoch 95 | Loss: 0.008886 | LR: 0.000013
Epoch 96 | Loss: 0.008880 | LR: 0.000013
Epoch 97 | Loss: 0.008875 | LR: 0.000013
Epoch 98 | Loss: 0.008870 | LR: 0.000013
Epoch 99 | Loss: 0.008868 | LR: 0.000013
Epoch 100 | Loss: 0.008864 | LR: 0.000013
Epoch 101 | Loss: 0.008859 | LR: 0.000013
Epoch 102 | Loss: 0.008857 | LR: 0.000013
Epoch 103 | Loss: 0.008853 | LR: 0.000013
Epoch 104 | Loss: 0.008849 | LR: 0.000010
Epoch 105 | Loss: 0.008726 | LR: 0.000010
Epoch 106 | Loss: 0.008704 | LR: 0.000010
Epoch 107 | Loss: 0.008692 | LR: 0.000010
Epoch 108 | Loss: 0.008686 | LR: 0.000010
Epoch 109 | Loss: 0.008681 | LR: 0.000010
Epoch 110 | Loss: 0.008675 | LR: 0.000010
Epoch 111 | Loss: 0.008670 | LR: 0.000010
Epoch 112 | Loss: 0.008667 | LR: 0.000010
Epoch 113 | Loss: 0.008664 | LR: 0.000010
Epoch 114 | Loss: 0.008659 | LR: 0.000010
Epoch 115 | Loss: 0.008657 | LR: 0.000010
Epoch 116 | Loss: 0.008654 | LR: 0.000010
Epoch 117 | Loss: 0.008652 | LR: 0.000010
Epoch 118 | Loss: 0.008649 | LR: 0.000010
Epoch 119 | Loss: 0.008646 | LR: 0.000008
Epoch 120 | Loss: 0.008537 | LR: 0.000008
Epoch 121 | Loss: 0.008520 | LR: 0.000008
Epoch 122 | Loss: 0.008512 | LR: 0.000008
Epoch 123 | Loss: 0.008507 | LR: 0.000008
Epoch 124 | Loss: 0.008502 | LR: 0.000008
Epoch 125 | Loss: 0.008499 | LR: 0.000008
Epoch 126 | Loss: 0.008497 | LR: 0.000008
Epoch 127 | Loss: 0.008493 | LR: 0.000008
Epoch 128 | Loss: 0.008490 | LR: 0.000008
Epoch 129 | Loss: 0.008488 | LR: 0.000008
Epoch 130 | Loss: 0.008485 | LR: 0.000008
Epoch 131 | Loss: 0.008483 | LR: 0.000008
Epoch 132 | Loss: 0.008480 | LR: 0.000008
Epoch 133 | Loss: 0.008478 | LR: 0.000008
Epoch 134 | Loss: 0.008477 | LR: 0.000007
Epoch 135 | Loss: 0.008381 | LR: 0.000007
Epoch 136 | Loss: 0.008369 | LR: 0.000007
Epoch 137 | Loss: 0.008362 | LR: 0.000007
Epoch 138 | Loss: 0.008358 | LR: 0.000007
Epoch 139 | Loss: 0.008356 | LR: 0.000007
Epoch 140 | Loss: 0.008352 | LR: 0.000007
Epoch 141 | Loss: 0.008350 | LR: 0.000007
Epoch 142 | Loss: 0.008348 | LR: 0.000007
Epoch 143 | Loss: 0.008345 | LR: 0.000007
Epoch 144 | Loss: 0.008345 | LR: 0.000007
Epoch 145 | Loss: 0.008342 | LR: 0.000007
Epoch 146 | Loss: 0.008341 | LR: 0.000007
Epoch 147 | Loss: 0.008339 | LR: 0.000007
Epoch 148 | Loss: 0.008336 | LR: 0.000007
Epoch 149 | Loss: 0.008335 | LR: 0.000005
Epoch 150 | Loss: 0.008253 | LR: 0.000005
Epoch 151 | Loss: 0.008243 | LR: 0.000005
Epoch 152 | Loss: 0.008239 | LR: 0.000005
Epoch 153 | Loss: 0.008236 | LR: 0.000005
Epoch 154 | Loss: 0.008233 | LR: 0.000005
Epoch 155 | Loss: 0.008232 | LR: 0.000005
Epoch 156 | Loss: 0.008229 | LR: 0.000005
Epoch 157 | Loss: 0.008228 | LR: 0.000005
Epoch 158 | Loss: 0.008226 | LR: 0.000005
Epoch 159 | Loss: 0.008225 | LR: 0.000005
Epoch 160 | Loss: 0.008222 | LR: 0.000005
Epoch 161 | Loss: 0.008221 | LR: 0.000005
Epoch 162 | Loss: 0.008220 | LR: 0.000005
Epoch 163 | Loss: 0.008218 | LR: 0.000005
Epoch 164 | Loss: 0.008217 | LR: 0.000004
Epoch 165 | Loss: 0.008148 | LR: 0.000004
Epoch 166 | Loss: 0.008139 | LR: 0.000004
Epoch 167 | Loss: 0.008137 | LR: 0.000004
Epoch 168 | Loss: 0.008134 | LR: 0.000004
Epoch 169 | Loss: 0.008133 | LR: 0.000004
Epoch 170 | Loss: 0.008131 | LR: 0.000004
Epoch 171 | Loss: 0.008130 | LR: 0.000004
Epoch 172 | Loss: 0.008128 | LR: 0.000004
Epoch 173 | Loss: 0.008126 | LR: 0.000004
Epoch 174 | Loss: 0.008125 | LR: 0.000004
Epoch 175 | Loss: 0.008123 | LR: 0.000004
Epoch 176 | Loss: 0.008122 | LR: 0.000004
Epoch 177 | Loss: 0.008121 | LR: 0.000004
Epoch 178 | Loss: 0.008120 | LR: 0.000004
Epoch 179 | Loss: 0.008119 | LR: 0.000003
Epoch 180 | Loss: 0.008060 | LR: 0.000003
Epoch 181 | Loss: 0.008054 | LR: 0.000003
Epoch 182 | Loss: 0.008051 | LR: 0.000003
Epoch 183 | Loss: 0.008050 | LR: 0.000003
Epoch 184 | Loss: 0.008048 | LR: 0.000003
Epoch 185 | Loss: 0.008046 | LR: 0.000003
Epoch 186 | Loss: 0.008045 | LR: 0.000003
Epoch 187 | Loss: 0.008045 | LR: 0.000003
Epoch 188 | Loss: 0.008043 | LR: 0.000003
Epoch 189 | Loss: 0.008042 | LR: 0.000003
Epoch 190 | Loss: 0.008040 | LR: 0.000003
Epoch 191 | Loss: 0.008040 | LR: 0.000003
Epoch 192 | Loss: 0.008039 | LR: 0.000003
Epoch 193 | Loss: 0.008038 | LR: 0.000003
Epoch 194 | Loss: 0.008037 | LR: 0.000003
Epoch 195 | Loss: 0.007988 | LR: 0.000003
Epoch 196 | Loss: 0.007982 | LR: 0.000003
Epoch 197 | Loss: 0.007981 | LR: 0.000003
Epoch 198 | Loss: 0.007979 | LR: 0.000003
Epoch 199 | Loss: 0.007979 | LR: 0.000003
Epoch 200 | Loss: 0.007977 | LR: 0.000003
Epoch 201 | Loss: 0.007977 | LR: 0.000003
Epoch 202 | Loss: 0.007976 | LR: 0.000003
Epoch 203 | Loss: 0.007974 | LR: 0.000003
Epoch 204 | Loss: 0.007973 | LR: 0.000003
Epoch 205 | Loss: 0.007972 | LR: 0.000003
Epoch 206 | Loss: 0.007972 | LR: 0.000003
Epoch 207 | Loss: 0.007971 | LR: 0.000003
Epoch 208 | Loss: 0.007970 | LR: 0.000003
Epoch 209 | Loss: 0.007969 | LR: 0.000002
Epoch 210 | Loss: 0.007928 | LR: 0.000002
Epoch 211 | Loss: 0.007923 | LR: 0.000002
Epoch 212 | Loss: 0.007922 | LR: 0.000002
Epoch 213 | Loss: 0.007922 | LR: 0.000002
Epoch 214 | Loss: 0.007921 | LR: 0.000002
Epoch 215 | Loss: 0.007920 | LR: 0.000002
Epoch 216 | Loss: 0.007919 | LR: 0.000002
Epoch 217 | Loss: 0.007918 | LR: 0.000002
Epoch 218 | Loss: 0.007917 | LR: 0.000002
Epoch 219 | Loss: 0.007917 | LR: 0.000002
Epoch 220 | Loss: 0.007916 | LR: 0.000002
Epoch 221 | Loss: 0.007915 | LR: 0.000002
Epoch 222 | Loss: 0.007915 | LR: 0.000002
Epoch 223 | Loss: 0.007914 | LR: 0.000002
Epoch 224 | Loss: 0.007913 | LR: 0.000002
Epoch 225 | Loss: 0.007878 | LR: 0.000002
Epoch 226 | Loss: 0.007875 | LR: 0.000002
Epoch 227 | Loss: 0.007874 | LR: 0.000002
Epoch 228 | Loss: 0.007873 | LR: 0.000002
Epoch 229 | Loss: 0.007873 | LR: 0.000002
Epoch 230 | Loss: 0.007872 | LR: 0.000002
Epoch 231 | Loss: 0.007872 | LR: 0.000002
Epoch 232 | Loss: 0.007871 | LR: 0.000002
Epoch 233 | Loss: 0.007870 | LR: 0.000002
Epoch 234 | Loss: 0.007869 | LR: 0.000002
Epoch 235 | Loss: 0.007869 | LR: 0.000002
Epoch 236 | Loss: 0.007869 | LR: 0.000002
Epoch 237 | Loss: 0.007868 | LR: 0.000002
Epoch 238 | Loss: 0.007867 | LR: 0.000002
Epoch 239 | Loss: 0.007867 | LR: 0.000001
Epoch 240 | Loss: 0.007837 | LR: 0.000001
Epoch 241 | Loss: 0.007835 | LR: 0.000001
Epoch 242 | Loss: 0.007834 | LR: 0.000001
Epoch 243 | Loss: 0.007834 | LR: 0.000001
Epoch 244 | Loss: 0.007833 | LR: 0.000001
Epoch 245 | Loss: 0.007833 | LR: 0.000001
Epoch 246 | Loss: 0.007832 | LR: 0.000001
Epoch 247 | Loss: 0.007832 | LR: 0.000001
Epoch 248 | Loss: 0.007831 | LR: 0.000001
Epoch 249 | Loss: 0.007831 | LR: 0.000001
Epoch 250 | Loss: 0.007830 | LR: 0.000001
Epoch 251 | Loss: 0.007830 | LR: 0.000001
Epoch 252 | Loss: 0.007829 | LR: 0.000001
Epoch 253 | Loss: 0.007829 | LR: 0.000001
Epoch 254 | Loss: 0.007828 | LR: 0.000001
Epoch 255 | Loss: 0.007804 | LR: 0.000001
Epoch 256 | Loss: 0.007802 | LR: 0.000001
Epoch 257 | Loss: 0.007801 | LR: 0.000001
Epoch 258 | Loss: 0.007801 | LR: 0.000001
Epoch 259 | Loss: 0.007800 | LR: 0.000001
Epoch 260 | Loss: 0.007800 | LR: 0.000001
Epoch 261 | Loss: 0.007800 | LR: 0.000001
Epoch 262 | Loss: 0.007799 | LR: 0.000001
Epoch 263 | Loss: 0.007799 | LR: 0.000001
Epoch 264 | Loss: 0.007799 | LR: 0.000001
Epoch 265 | Loss: 0.007798 | LR: 0.000001
Epoch 266 | Loss: 0.007798 | LR: 0.000001
Epoch 267 | Loss: 0.007797 | LR: 0.000001
Epoch 268 | Loss: 0.007797 | LR: 0.000001
Epoch 269 | Loss: 0.007797 | LR: 0.000001
Epoch 270 | Loss: 0.007776 | LR: 0.000001
Epoch 271 | Loss: 0.007775 | LR: 0.000001
Epoch 272 | Loss: 0.007774 | LR: 0.000001
Epoch 273 | Loss: 0.007774 | LR: 0.000001
Epoch 274 | Loss: 0.007773 | LR: 0.000001
Epoch 275 | Loss: 0.007773 | LR: 0.000001
Epoch 276 | Loss: 0.007773 | LR: 0.000001
Epoch 277 | Loss: 0.007773 | LR: 0.000001
Epoch 278 | Loss: 0.007773 | LR: 0.000001
Epoch 279 | Loss: 0.007772 | LR: 0.000001
Epoch 280 | Loss: 0.007771 | LR: 0.000001
Epoch 281 | Loss: 0.007771 | LR: 0.000001
Epoch 282 | Loss: 0.007771 | LR: 0.000001
Epoch 283 | Loss: 0.007771 | LR: 0.000001
Epoch 284 | Loss: 0.007770 | LR: 0.000001
Epoch 285 | Loss: 0.007753 | LR: 0.000001
Epoch 286 | Loss: 0.007752 | LR: 0.000001
Epoch 287 | Loss: 0.007752 | LR: 0.000001
Epoch 288 | Loss: 0.007751 | LR: 0.000001
Epoch 289 | Loss: 0.007751 | LR: 0.000001
Epoch 290 | Loss: 0.007751 | LR: 0.000001
Epoch 291 | Loss: 0.007751 | LR: 0.000001
Epoch 292 | Loss: 0.007750 | LR: 0.000001
Epoch 293 | Loss: 0.007750 | LR: 0.000001
Epoch 294 | Loss: 0.007750 | LR: 0.000001
Epoch 295 | Loss: 0.007750 | LR: 0.000001
Epoch 296 | Loss: 0.007750 | LR: 0.000001
Epoch 297 | Loss: 0.007749 | LR: 0.000001
Epoch 298 | Loss: 0.007749 | LR: 0.000001
Epoch 299 | Loss: 0.007749 | LR: 0.000001
Epoch 300 | Loss: 0.007735 | LR: 0.000001
Training complete in 251m 45s
PSNR: 27.17, RMSE: 0.0876
PSNR vs Original File: 23.76, RMSE: 0.1297
Loading combined VTI...
Loading model...
Traceback (most recent call last):
  File "/home/tsudhakar/isabel/Knowledge_Distillation_v1.py", line 305, in <module>
    state = torch.load(args.model_path, map_location=device)
                       ^^^^^^^^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'model_path'
