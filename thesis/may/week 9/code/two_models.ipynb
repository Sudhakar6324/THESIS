{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10578389,
          "sourceType": "datasetVersion",
          "datasetId": 6546447
        },
        {
          "sourceId": 11041818,
          "sourceType": "datasetVersion",
          "datasetId": 6878023
        },
        {
          "sourceId": 11251078,
          "sourceType": "datasetVersion",
          "datasetId": 7030699
        },
        {
          "sourceId": 11389139,
          "sourceType": "datasetVersion",
          "datasetId": 7132144
        },
        {
          "sourceId": 11421576,
          "sourceType": "datasetVersion",
          "datasetId": 7153051
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install vtk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5RN3QEr9B8B",
        "outputId": "5cd863cf-afff-48d6-802a-ac8a9e73e171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vtk in /usr/local/lib/python3.11/dist-packages (9.5.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from vtk) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->vtk) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import vtk\n",
        "from vtk import *\n",
        "from vtk.util.numpy_support import vtk_to_numpy\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "import time"
      ],
      "metadata": {
        "_uuid": "d33f75d4-5445-4e48-8179-f0c5dd333f79",
        "_cell_guid": "240889c7-74eb-4fd4-a5b1-ec2aead81dac",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:13.755511Z",
          "iopub.execute_input": "2025-05-26T20:25:13.755738Z",
          "iopub.status.idle": "2025-05-26T20:25:19.575599Z",
          "shell.execute_reply.started": "2025-05-26T20:25:13.755716Z",
          "shell.execute_reply": "2025-05-26T20:25:19.574610Z"
        },
        "id": "2_BwBIYQ5lmI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print('Device running:', device)"
      ],
      "metadata": {
        "_uuid": "43d958cf-562d-4fb8-9670-43075fd82174",
        "_cell_guid": "bda30f3b-5c85-404f-8cdc-861e65b7ae69",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.576562Z",
          "iopub.execute_input": "2025-05-26T20:25:19.576994Z",
          "iopub.status.idle": "2025-05-26T20:25:19.654026Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.576972Z",
          "shell.execute_reply": "2025-05-26T20:25:19.653204Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_OdVX9C5lmL",
        "outputId": "6cc2e3c1-c779-4566-c11d-0ec6f5ba87e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device running: cuda\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class SineLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, bias=True, is_first=False, omega_0=30):\n",
        "        super().__init__()\n",
        "        self.omega_0 = omega_0\n",
        "        self.is_first = is_first\n",
        "        # self.enable_dropout = enable_dropout\n",
        "        # self.dropout_prob = dropout_prob\n",
        "        self.in_features = in_features\n",
        "        # if enable_dropout:\n",
        "        #     if not self.is_first:\n",
        "        #         self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        with torch.no_grad():\n",
        "            if self.is_first:\n",
        "                self.linear.weight.uniform_(-1 / self.in_features,\n",
        "                                             1 / self.in_features)\n",
        "            else:\n",
        "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0,\n",
        "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        # if self.enable_dropout:\n",
        "        #     if not self.is_first:\n",
        "        #         x = self.dropout(x)\n",
        "        return torch.sin(self.omega_0 * x)"
      ],
      "metadata": {
        "_uuid": "c6d00f8a-3e62-40d1-81e8-b30fd44e994f",
        "_cell_guid": "47639dbe-7c29-4716-ad12-c245edbd4925",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.654942Z",
          "iopub.execute_input": "2025-05-26T20:25:19.655223Z",
          "iopub.status.idle": "2025-05-26T20:25:19.667030Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.655199Z",
          "shell.execute_reply": "2025-05-26T20:25:19.666295Z"
        },
        "id": "3u8dXB2i5lmL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualSineLayer(nn.Module):\n",
        "    def __init__(self, features, bias=True, ave_first=False, ave_second=False, omega_0=30):\n",
        "        super().__init__()\n",
        "        self.omega_0 = omega_0\n",
        "        # self.enable_dropout = enable_dropout\n",
        "        # self.dropout_prob = dropout_prob\n",
        "        self.features = features\n",
        "        # if enable_dropout:\n",
        "        #     self.dropout_1 = nn.Dropout(dropout_prob)\n",
        "        self.linear_1 = nn.Linear(features, features, bias=bias)\n",
        "        self.linear_2 = nn.Linear(features, features, bias=bias)\n",
        "        self.weight_1 = .5 if ave_first else 1\n",
        "        self.weight_2 = .5 if ave_second else 1\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "\n",
        "    def init_weights(self):\n",
        "        with torch.no_grad():\n",
        "            self.linear_1.weight.uniform_(-np.sqrt(6 / self.features) / self.omega_0,\n",
        "                                           np.sqrt(6 / self.features) / self.omega_0)\n",
        "            self.linear_2.weight.uniform_(-np.sqrt(6 / self.features) / self.omega_0,\n",
        "                                           np.sqrt(6 / self.features) / self.omega_0)\n",
        "\n",
        "    def forward(self, input):\n",
        "        linear_1 = self.linear_1(self.weight_1*input)\n",
        "        # if self.enable_dropout:\n",
        "        #     linear_1 = self.dropout_1(linear_1)\n",
        "        sine_1 = torch.sin(self.omega_0 * linear_1)\n",
        "        sine_2 = torch.sin(self.omega_0 * self.linear_2(sine_1))\n",
        "        return self.weight_2*(input+sine_2)"
      ],
      "metadata": {
        "_uuid": "286fbfd2-ba2c-4fbe-8ac6-cfebd4a21e55",
        "_cell_guid": "ef7cdfa6-ccb1-405d-a306-c83170e479b4",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.667767Z",
          "iopub.execute_input": "2025-05-26T20:25:19.668045Z",
          "iopub.status.idle": "2025-05-26T20:25:19.679335Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.668025Z",
          "shell.execute_reply": "2025-05-26T20:25:19.678679Z"
        },
        "id": "vOXwLGmJ5lmM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class MyResidualSirenNet(nn.Module):\n",
        "    def __init__(self, obj):\n",
        "        super(MyResidualSirenNet, self).__init__()\n",
        "        # self.enable_dropout = obj['enable_dropout']\n",
        "        # self.dropout_prob = obj['dropout_prob']\n",
        "        self.Omega_0=30\n",
        "        self.n_layers = obj['n_layers']\n",
        "        self.input_dim = obj['dim']\n",
        "        self.output_dim = obj['total_vars']\n",
        "        self.neurons_per_layer = obj['n_neurons']\n",
        "        self.layers = [self.input_dim]\n",
        "        for i in range(self.n_layers-1):\n",
        "            self.layers.append(self.neurons_per_layer)\n",
        "        self.layers.append(self.output_dim)\n",
        "        self.net_layers = nn.ModuleList()\n",
        "        for idx in np.arange(self.n_layers):\n",
        "            layer_in = self.layers[idx]\n",
        "            layer_out = self.layers[idx+1]\n",
        "            ## if not the final layer\n",
        "            if idx != self.n_layers-1:\n",
        "                ## if first layer\n",
        "                if idx==0:\n",
        "                    self.net_layers.append(SineLayer(layer_in,layer_out,bias=True,is_first=idx==0))\n",
        "                ## if an intermdeiate layer\n",
        "                else:\n",
        "                    self.net_layers.append(ResidualSineLayer(layer_in,bias=True,ave_first=idx>1,ave_second=idx==(self.n_layers-2)))\n",
        "            ## if final layer\n",
        "            else:\n",
        "                final_linear = nn.Linear(layer_in,layer_out)\n",
        "                ## initialize weights for the final layer\n",
        "                with torch.no_grad():\n",
        "                    final_linear.weight.uniform_(-np.sqrt(6 / (layer_in)) / self.Omega_0, np.sqrt(6 / (layer_in)) / self.Omega_0)\n",
        "                self.net_layers.append(final_linear)\n",
        "\n",
        "    def forward(self,x):\n",
        "        for net_layer in self.net_layers:\n",
        "            x = net_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "_uuid": "e1400ad9-b3ed-49fc-81e0-929816a0aaf2",
        "_cell_guid": "807361ca-2c71-4799-83d0-2da9ccf9fac0",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.680067Z",
          "iopub.execute_input": "2025-05-26T20:25:19.680289Z",
          "iopub.status.idle": "2025-05-26T20:25:19.693684Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.680270Z",
          "shell.execute_reply": "2025-05-26T20:25:19.693049Z"
        },
        "id": "Cae86SYg5lmM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def size_of_network(n_layers, n_neurons, d_in, d_out, is_residual = True):\n",
        "    # Adding input layer\n",
        "    layers = [d_in]\n",
        "    # layers = [3]\n",
        "\n",
        "    # Adding hidden layers\n",
        "    layers.extend([n_neurons]*n_layers)\n",
        "    # layers = [3, 5, 5, 5]\n",
        "\n",
        "    # Adding output layer\n",
        "    layers.append(d_out)\n",
        "    # layers = [3, 5, 5, 5, 1]\n",
        "\n",
        "    # Number of steps\n",
        "    n_layers = len(layers)-1\n",
        "    # n_layers = 5 - 1 = 4\n",
        "\n",
        "    n_params = 0\n",
        "\n",
        "    # np.arange(4) = [0, 1, 2, 3]\n",
        "    for ndx in np.arange(n_layers):\n",
        "\n",
        "        # number of neurons in below layer\n",
        "        layer_in = layers[ndx]\n",
        "\n",
        "        # number of neurons in above layer\n",
        "        layer_out = layers[ndx+1]\n",
        "\n",
        "        # max number of neurons in both the layer\n",
        "        og_layer_in = max(layer_in,layer_out)\n",
        "\n",
        "        # if lower layer is the input layer\n",
        "        # or the upper layer is the output layer\n",
        "        if ndx==0 or ndx==(n_layers-1):\n",
        "            # Adding weight corresponding to every neuron for every input neuron\n",
        "            # Adding bias for every neuron in the upper layer\n",
        "            n_params += ((layer_in+1)*layer_out)\n",
        "\n",
        "        else:\n",
        "\n",
        "            # If the layer is residual then proceed as follows as there will be more weights if residual layer is included\n",
        "            if is_residual:\n",
        "                # doubt in the following two lines\n",
        "                n_params += (layer_in*og_layer_in)+og_layer_in\n",
        "                n_params += (og_layer_in*layer_out)+layer_out\n",
        "\n",
        "            # if the layer is non residual then simply add number of weights and biases as follows\n",
        "            else:\n",
        "                n_params += ((layer_in+1)*layer_out)\n",
        "            #\n",
        "        #\n",
        "    #\n",
        "\n",
        "    return n_params"
      ],
      "metadata": {
        "_uuid": "49e23bf9-3de6-417b-8de1-53aaf02fd323",
        "_cell_guid": "7342b7cd-612f-4c56-ad94-ecd81203519a",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.695847Z",
          "iopub.execute_input": "2025-05-26T20:25:19.696059Z",
          "iopub.status.idle": "2025-05-26T20:25:19.707241Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.696041Z",
          "shell.execute_reply": "2025-05-26T20:25:19.706562Z"
        },
        "id": "Gmzb8rVy5lmN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_PSNR(arrgt,arr_recon):\n",
        "    diff = arrgt - arr_recon\n",
        "    sqd_max_diff = (np.max(arrgt)-np.min(arrgt))**2\n",
        "    snr = 10*np.log10(sqd_max_diff/np.mean(diff**2))\n",
        "    return snr"
      ],
      "metadata": {
        "_uuid": "4bee2b5f-d501-4d1c-b226-410b2624c2d5",
        "_cell_guid": "c8d04a55-6de3-4520-9cf7-45a568420b31",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.708470Z",
          "iopub.execute_input": "2025-05-26T20:25:19.708697Z",
          "iopub.status.idle": "2025-05-26T20:25:19.720894Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.708678Z",
          "shell.execute_reply": "2025-05-26T20:25:19.720185Z"
        },
        "id": "Tr_FvTLA5lmN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def srs(numOfPoints, valid_pts, percentage, isMaskPresent, mask_array):\n",
        "\n",
        "    # getting total number of sampled points\n",
        "    numberOfSampledPoints = int((valid_pts/100) * percentage)\n",
        "\n",
        "    # storing corner indices in indices variable\n",
        "    indices = set()\n",
        "\n",
        "    # As long as we don't get the required amount of sample points keep finding the random numbers\n",
        "    while(len(indices) < numberOfSampledPoints):\n",
        "        rp = random.randint(0, numOfPoints-1)\n",
        "        if isMaskPresent and mask_array[rp] == 0:\n",
        "            continue\n",
        "        indices.add(rp)\n",
        "\n",
        "    # return indices\n",
        "    return indices"
      ],
      "metadata": {
        "_uuid": "9b219fbe-1596-4e3b-a0a7-6eb88db2f52d",
        "_cell_guid": "415f4118-71de-4504-b39f-a7bd40cdcc02",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.721825Z",
          "iopub.execute_input": "2025-05-26T20:25:19.722096Z",
          "iopub.status.idle": "2025-05-26T20:25:19.732038Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.722064Z",
          "shell.execute_reply": "2025-05-26T20:25:19.731249Z"
        },
        "id": "F1W8L5oG5lmO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def findMultiVariatePSNR(var_name, total_vars, actual, pred):\n",
        "    # print('Printing PSNR')\n",
        "    tot = 0\n",
        "    psnr_list = []\n",
        "    for j in range(total_vars):\n",
        "        psnr = compute_PSNR(actual[:,j], pred[:,j])\n",
        "        psnr_list.append(psnr)\n",
        "        tot += psnr\n",
        "        print(var_name, ' PSNR:', psnr)\n",
        "    avg_psnr = tot/total_vars\n",
        "    print('\\nAverage psnr : ', avg_psnr)\n",
        "     #this function is calculating the psnr of final epoch (or whenever it is called) of each variable and then averaging it\n",
        "     #Thus individual epochs psnr is not calculated\n",
        "\n",
        "    return psnr_list, avg_psnr"
      ],
      "metadata": {
        "_uuid": "964befc2-020d-46d4-bd1b-ef061a65b9e8",
        "_cell_guid": "c20e48d5-ebad-408b-b564-627ba81d02f9",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.732800Z",
          "iopub.execute_input": "2025-05-26T20:25:19.733052Z",
          "iopub.status.idle": "2025-05-26T20:25:19.745670Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.733032Z",
          "shell.execute_reply": "2025-05-26T20:25:19.744868Z"
        },
        "id": "4pFO0AYF5lmO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_rmse(actual, predicted):\n",
        "    mse = np.mean((actual - predicted) ** 2)\n",
        "    return np.sqrt(mse)\n",
        "\n",
        "def denormalizeValue(total_vars, to, ref):\n",
        "    to_arr = np.array(to)\n",
        "    for i in range(total_vars):\n",
        "        min_data = np.min(ref[:, i])\n",
        "        max_data = np.max(ref[:, i])\n",
        "        to_arr[:, i] = (((to[:, i] * 0.5) + 0.5) * (max_data - min_data)) + min_data\n",
        "    return to_arr"
      ],
      "metadata": {
        "_uuid": "2face64a-1559-415e-9527-5a581fab1db5",
        "_cell_guid": "716ccaed-b6c8-4cc4-83a6-643495093c02",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.746505Z",
          "iopub.execute_input": "2025-05-26T20:25:19.746788Z",
          "iopub.status.idle": "2025-05-26T20:25:19.755298Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.746760Z",
          "shell.execute_reply": "2025-05-26T20:25:19.754436Z"
        },
        "id": "8InIQVwb5lmP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def makeVTI(data, val, n_predictions, n_pts, total_vars, var_name, dim, isMaskPresent, mask_arr, vti_path, vti_name, normalizedVersion = False):\n",
        "    nn_predictions = denormalizeValue(total_vars, n_predictions, val) if not normalizedVersion else n_predictions\n",
        "    writer = vtkXMLImageDataWriter()\n",
        "    writer.SetFileName(vti_path + vti_name)\n",
        "    img = vtkImageData()\n",
        "    img.CopyStructure(data)\n",
        "    if not isMaskPresent:\n",
        "        for i in range(total_vars):\n",
        "            f = var_name[i]\n",
        "            temp = nn_predictions[:, i]\n",
        "            arr = vtkFloatArray()\n",
        "            for j in range(n_pts):\n",
        "                arr.InsertNextValue(temp[j])\n",
        "            arr.SetName(f)\n",
        "            img.GetPointData().AddArray(arr)\n",
        "        # print(img)\n",
        "        writer.SetInputData(img)\n",
        "        writer.Write()\n",
        "        print(f'Vti File written successfully at {vti_path}{vti_name}')\n",
        "    else:\n",
        "        for i in range(total_vars):\n",
        "            f = var_name[i]\n",
        "            temp = nn_predictions[:, i]\n",
        "            idx = 0\n",
        "            arr = vtkFloatArray()\n",
        "            for j in range(n_pts):\n",
        "                if(mask_arr[j] == 1):\n",
        "                    arr.InsertNextValue(temp[idx])\n",
        "                    idx += 1\n",
        "                else:\n",
        "                    arr.InsertNextValue(0.0)\n",
        "            arr.SetName('p_' + f)\n",
        "            data.GetPointData().AddArray(arr)\n",
        "        # print(data)\n",
        "        writer.SetInputData(data)\n",
        "        writer.Write()\n",
        "        print(f'Vti File written successfully at {vti_path}{vti_name}')"
      ],
      "metadata": {
        "_uuid": "88d4128a-9484-48bb-b8cd-21abe4801eb1",
        "_cell_guid": "4d173df2-a1ab-442d-8eeb-bd0f1e71b9ee",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.756183Z",
          "iopub.execute_input": "2025-05-26T20:25:19.756430Z",
          "iopub.status.idle": "2025-05-26T20:25:19.768524Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.756410Z",
          "shell.execute_reply": "2025-05-26T20:25:19.767693Z"
        },
        "id": "Vl1XdT_T5lmP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def getImageData(actual_img, val, n_pts, var_name, isMaskPresent, mask_arr):\n",
        "    img = vtkImageData()\n",
        "    img.CopyStructure(actual_img)\n",
        "    # if isMaskPresent:\n",
        "    #     img.DeepCopy(actual_img)\n",
        "    # img.SetDimensions(dim)\n",
        "    # img.SetOrigin(actual_img.GetOrigin())\n",
        "    # img.SetSpacing(actual_img.GetSpacing())\n",
        "    if not isMaskPresent:\n",
        "        f = var_name\n",
        "        data = val\n",
        "        arr = vtkFloatArray()\n",
        "        for j in range(n_pts):\n",
        "            arr.InsertNextValue(data[j])\n",
        "        arr.SetName(f)\n",
        "        img.GetPointData().SetScalars(arr)\n",
        "    else:\n",
        "        f = var_name\n",
        "        data = val\n",
        "        idx = 0\n",
        "        arr = vtkFloatArray()\n",
        "        for j in range(n_pts):\n",
        "            if(mask_arr[j] == 1):\n",
        "                arr.InsertNextValue(data[idx])\n",
        "                idx += 1\n",
        "            else:\n",
        "                arr.InsertNextValue(0.0)\n",
        "        arr.SetName(f)\n",
        "        img.GetPointData().SetScalars(arr)\n",
        "    return img"
      ],
      "metadata": {
        "_uuid": "99a2cbb5-4737-4a6d-b398-c37e117de5a7",
        "_cell_guid": "7042e60f-eafc-446d-87ab-ec4298dd9276",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.769381Z",
          "iopub.execute_input": "2025-05-26T20:25:19.769639Z",
          "iopub.status.idle": "2025-05-26T20:25:19.780625Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.769609Z",
          "shell.execute_reply": "2025-05-26T20:25:19.779903Z"
        },
        "id": "XsWI84C-5lmP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import Namespace\n",
        "\n",
        "# Parameters (simulating argparse in a Jupyter Notebook)\n",
        "args = Namespace(\n",
        "    n_neurons=150,\n",
        "    n_layers=6,\n",
        "    epochs=200,  # Required argument: Set the number of epochs\n",
        "    batchsize=2048,\n",
        "    lr=0.00005,\n",
        "    no_decay=False,\n",
        "    decay_rate=0.8,\n",
        "    decay_at_interval=True,\n",
        "    decay_interval=15,\n",
        "    datapath='/content/Teardrop_Gaussian.vti',  # Required: Set the path to your data\n",
        "    outpath='./models/',\n",
        "    exp_path='../logs/',\n",
        "    modified_data_path='./data/',\n",
        "    dataset_name='3d_data',  # Required: Set the dataset name\n",
        "    vti_name='predicted.vti',  # Required: Name of the dataset\n",
        "    vti_path='./data/'\n",
        ")\n",
        "\n",
        "print(args, end='\\n\\n')\n",
        "\n",
        "# Assigning parameters to variables\n",
        "LR = args.lr\n",
        "BATCH_SIZE = args.batchsize\n",
        "decay_rate = args.decay_rate\n",
        "decay_at_equal_interval = args.decay_at_interval\n",
        "\n",
        "decay = not args.no_decay\n",
        "MAX_EPOCH = args.epochs\n",
        "\n",
        "n_neurons = args.n_neurons\n",
        "n_layers = args.n_layers + 2\n",
        "decay_interval = args.decay_interval\n",
        "outpath = args.outpath\n",
        "exp_path = args.exp_path\n",
        "datapath = args.datapath\n",
        "modified_data_path = args.modified_data_path\n",
        "dataset_name = args.dataset_name\n",
        "vti_name = args.vti_name\n",
        "vti_path = args.vti_path\n",
        "\n",
        "# Displaying the final configuration\n",
        "print(f\"Learning Rate: {LR}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Decay Rate: {decay_rate}\")\n",
        "print(f\"Max Epochs: {MAX_EPOCH}\")\n",
        "print(f\"Number of Neurons per Layer: {n_neurons}\")\n",
        "print(f\"Number of Layers (including input/output): {n_layers}\")\n",
        "print(f\"Data Path: {datapath}\")\n",
        "print(f\"Output Path: {outpath}\")\n",
        "print(f\"Dataset Name: {dataset_name}\")\n",
        "print(f\"Vti Name: {vti_name}\")"
      ],
      "metadata": {
        "_uuid": "07692dd4-4d61-4352-8b23-bff56509856c",
        "_cell_guid": "4204ef20-76e1-416f-b261-20a979ca06e6",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.781711Z",
          "iopub.execute_input": "2025-05-26T20:25:19.782004Z",
          "iopub.status.idle": "2025-05-26T20:25:19.797158Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.781976Z",
          "shell.execute_reply": "2025-05-26T20:25:19.796521Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN1Tmd7t5lmP",
        "outputId": "62022fc5-27fb-4395-b24c-d8bb38c9074f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(n_neurons=150, n_layers=6, epochs=200, batchsize=2048, lr=5e-05, no_decay=False, decay_rate=0.8, decay_at_interval=True, decay_interval=15, datapath='/content/Teardrop_Gaussian.vti', outpath='./models/', exp_path='../logs/', modified_data_path='./data/', dataset_name='3d_data', vti_name='predicted.vti', vti_path='./data/')\n",
            "\n",
            "Learning Rate: 5e-05\n",
            "Batch Size: 2048\n",
            "Decay Rate: 0.8\n",
            "Max Epochs: 200\n",
            "Number of Neurons per Layer: 150\n",
            "Number of Layers (including input/output): 8\n",
            "Data Path: /content/Teardrop_Gaussian.vti\n",
            "Output Path: ./models/\n",
            "Dataset Name: 3d_data\n",
            "Vti Name: predicted.vti\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable Initialization\n",
        "var_name = []\n",
        "total_vars = None  # Number of variables\n",
        "univariate = None  # True if dataset has one variable, else False\n",
        "group_size = 5000  # Group size during testing\n",
        "\n",
        "\n",
        "# Constructing the log file name\n",
        "log_file = (\n",
        "    f'train_{dataset_name}_{n_layers-2}rb_{n_neurons}n_{BATCH_SIZE}bs_'\n",
        "    f'{LR}lr_{decay}decay_{decay_rate}dr_'\n",
        "    f'{\"decayingAtInterval\" + str(decay_interval) if decay_at_equal_interval else \"decayingWhenLossIncr\"}'\n",
        ")\n",
        "\n",
        "print(log_file)"
      ],
      "metadata": {
        "_uuid": "844184e9-6479-45d0-8d31-b1d3a9a4a116",
        "_cell_guid": "cd516584-ec76-4358-888f-79e1116c82d2",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.797890Z",
          "iopub.execute_input": "2025-05-26T20:25:19.798155Z",
          "iopub.status.idle": "2025-05-26T20:25:19.810981Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.798129Z",
          "shell.execute_reply": "2025-05-26T20:25:19.810268Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cu5ZJmn5lmQ",
        "outputId": "686c337c-218f-432f-f1b5-4ba20e7b189e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_3d_data_6rb_150n_2048bs_5e-05lr_Truedecay_0.8dr_decayingAtInterval15\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "n_pts = None  # Number of points in the dataset\n",
        "n_dim = None  # Dimensionality of the data\n",
        "dim = None  # Other dimension-specific information\n",
        "\n",
        "print(\"Decay:\", decay)\n",
        "print(f'Extracting variables from path: {datapath}', end=\"\\n\\n\")\n",
        "\n",
        "# Placeholder for data\n",
        "data_array = []\n",
        "scalar_data = None"
      ],
      "metadata": {
        "_uuid": "bc8c0631-eaaf-4af9-acb9-35bd7467277a",
        "_cell_guid": "c45f69dd-0524-4855-a64e-801e6bfb5765",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.811760Z",
          "iopub.execute_input": "2025-05-26T20:25:19.812043Z",
          "iopub.status.idle": "2025-05-26T20:25:19.825096Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.812017Z",
          "shell.execute_reply": "2025-05-26T20:25:19.824332Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hIB3Y5i5lmQ",
        "outputId": "f7ed6812-8f5b-4411-d3bd-a280a10f1851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decay: True\n",
            "Extracting variables from path: /content/Teardrop_Gaussian.vti\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # Reading values from .vti files\n",
        "# reader = vtk.vtkXMLImageDataReader()\n",
        "# reader.SetFileName(datapath)\n",
        "# reader.Update()\n",
        "\n",
        "# data = reader.GetOutput()\n",
        "# scalar_data = data\n",
        "# pdata = data.GetPointData()\n",
        "# n_pts = data.GetNumberOfPoints()\n",
        "# dim = data.GetDimensions()\n",
        "# n_dim = len(dim)\n",
        "# total_arr = pdata.GetNumberOfArrays()\n",
        "\n",
        "# print(\"n_pts:\", n_pts, \"dim:\", dim, \"n_dim:\", n_dim, \"total_arr:\", total_arr)\n",
        "\n",
        "# mask_arr = []\n",
        "# valid_pts = 0\n",
        "# var_name = []\n",
        "# data_array = []\n",
        "\n",
        "# # Extracting data from the .vti file\n",
        "# for i in range(total_arr):\n",
        "#     a_name = pdata.GetArrayName(i)\n",
        "#     if a_name in ['vtkValidPointMask', 'Swirl']:\n",
        "#         continue\n",
        "\n",
        "#     cur_arr = pdata.GetArray(a_name)\n",
        "#     n_components = cur_arr.GetNumberOfComponents()\n",
        "\n",
        "#     if n_components == 1:\n",
        "#         var_name.append(a_name)\n",
        "#         data_array.append(vtk_to_numpy(cur_arr))\n",
        "#     else:\n",
        "#         component_names = [f\"{a_name}_{c}\" for c in ['x', 'y', 'z'][:n_components]]\n",
        "#         var_name.extend(component_names)\n",
        "#         for c in range(n_components):\n",
        "#             c_data = [cur_arr.GetComponent(j, c) for j in range(n_pts)]\n",
        "#             data_array.append(np.array(c_data))\n",
        "\n",
        "# valid_pts = n_pts  # Assume all points are valid for simplicity\n",
        "# total_vars = len(var_name)\n",
        "# univariate = total_vars == 1\n",
        "\n",
        "# # Prepare numpy arrays for coordinates and variable values\n",
        "# cord = np.zeros((valid_pts, n_dim))\n",
        "# val = np.zeros((valid_pts, total_vars))\n",
        "\n",
        "# # Store data in numpy arrays\n",
        "# for i in range(n_pts):\n",
        "#     pt = scalar_data.GetPoint(i)\n",
        "#     cord[i, :] = pt\n",
        "#     val[i, :] = [arr[i] for arr in data_array]\n",
        "\n",
        "# # Display final information\n",
        "# print(\"Total Variables:\", total_vars)\n",
        "# print(\"Univariate:\", univariate)\n",
        "# print(\"Coordinates Shape:\", cord.shape)\n",
        "# print(\"Values Shape:\", val.shape)\n",
        "\n",
        "# Reading values from .vti files\n",
        "reader = vtk.vtkXMLImageDataReader()\n",
        "reader.SetFileName(datapath)\n",
        "reader.Update()\n",
        "\n",
        "data = reader.GetOutput()\n",
        "scalar_data = data\n",
        "pdata = data.GetPointData()\n",
        "n_pts = data.GetNumberOfPoints()\n",
        "dim = data.GetDimensions()\n",
        "n_dim = len(dim)\n",
        "total_arr = pdata.GetNumberOfArrays()\n",
        "\n",
        "print(\"n_pts:\", n_pts, \"dim:\", dim, \"n_dim:\", n_dim, \"total_arr:\", total_arr)\n",
        "\n",
        "var_name = []\n",
        "data_array = []\n",
        "\n",
        "# Extracting data from the .vti file\n",
        "for i in range(total_arr):\n",
        "    a_name = pdata.GetArrayName(i)\n",
        "\n",
        "    cur_arr = pdata.GetArray(a_name)\n",
        "    n_components = cur_arr.GetNumberOfComponents()\n",
        "\n",
        "    if n_components == 1:\n",
        "        var_name.append(a_name)\n",
        "        data_array.append(vtk_to_numpy(cur_arr))\n",
        "    else:\n",
        "        component_names = [f\"{a_name}_{c}\" for c in ['x', 'y', 'z'][:n_components]]\n",
        "        var_name.extend(component_names)\n",
        "        for c in range(n_components):\n",
        "            c_data = [cur_arr.GetComponent(j, c) for j in range(n_pts)]\n",
        "            data_array.append(np.array(c_data))\n",
        "\n",
        "total_vars = len(var_name)\n",
        "univariate = total_vars == 1\n",
        "\n",
        "# Prepare numpy arrays for coordinates and variable values\n",
        "cord = np.zeros((n_pts, n_dim))\n",
        "val = np.zeros((n_pts, total_vars))\n",
        "\n",
        "# Store data in numpy arrays\n",
        "for i in range(n_pts):\n",
        "    pt = scalar_data.GetPoint(i)\n",
        "    cord[i, :] = pt\n",
        "    val[i, :] = [arr[i] for arr in data_array]\n",
        "\n",
        "# Display final information\n",
        "print(\"Total Variables:\", total_vars)\n",
        "print(\"Univariate:\", univariate)\n",
        "print(\"Coordinates Shape:\", cord.shape)\n",
        "print(\"Values Shape:\", val.shape)"
      ],
      "metadata": {
        "_uuid": "01428998-749b-433d-8d00-0ad9ac906055",
        "_cell_guid": "2f13ab5d-71b7-4829-8d28-4a08f4f9a1cf",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:19.825827Z",
          "iopub.execute_input": "2025-05-26T20:25:19.826013Z",
          "iopub.status.idle": "2025-05-26T20:25:21.280626Z",
          "shell.execute_reply.started": "2025-05-26T20:25:19.825996Z",
          "shell.execute_reply": "2025-05-26T20:25:21.279633Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39aORhdJ5lmQ",
        "outputId": "3d81bf7a-4df0-47a8-a505-6d3acdb47a89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_pts: 262144 dim: (64, 64, 64) n_dim: 3 total_arr: 2\n",
            "Total Variables: 2\n",
            "Univariate: False\n",
            "Coordinates Shape: (262144, 3)\n",
            "Values Shape: (262144, 2)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # Ensure modified data path exists\n",
        "# if not os.path.exists(modified_data_path):\n",
        "#     os.mkdir(modified_data_path)\n",
        "\n",
        "# Save raw coordinates and values\n",
        "# np.save(f'{modified_data_path}cord.npy', cord)\n",
        "# np.save(f'{modified_data_path}val.npy', val)\n",
        "\n",
        "# # Create copies of non-normalized data\n",
        "# nn_cord = cord.copy()\n",
        "# nn_val = val.copy()\n",
        "\n",
        "# === Separate Normalization for Values ===\n",
        "# We assume the variable order is:\n",
        "#   - Means: indices 0,1,2\n",
        "#   - Std Devs: indices 3,4,5\n",
        "#   - Weights: indices 6,7,8\n",
        "\n",
        "# # We'll store normalization parameters so that we can invert normalization later.\n",
        "# norm_params = {}\n",
        "# epsilon = 1e-8  # to avoid log(0)\n",
        "\n",
        "# # Normalize Means to [-1,1] using min–max normalization\n",
        "# for i in range(3):\n",
        "#     min_val = np.min(val[:, i])\n",
        "#     max_val = np.max(val[:, i])\n",
        "#     norm_params[var_name[i]] = (min_val, max_val)\n",
        "#     val[:, i] = 2.0 * ((val[:, i] - min_val) / (max_val - min_val) - 0.5)\n",
        "\n",
        "# # Normalize Std Devs: first take log, then min–max to [-1,1]\n",
        "# for i in range(3, 6):\n",
        "#     log_vals = np.log(val[:, i] + epsilon)\n",
        "#     min_val = np.min(log_vals)\n",
        "#     max_val = np.max(log_vals)\n",
        "#     norm_params[var_name[i]] = (min_val, max_val)\n",
        "#     val[:, i] = 2.0 * ((log_vals - min_val) / (max_val - min_val) - 0.5)\n",
        "\n",
        "# # Normalize Weights: take log, then min–max to [-1,1]\n",
        "# for i in range(6, 9):\n",
        "#     log_vals = np.log(val[:, i] + epsilon)\n",
        "#     min_val = np.min(log_vals)\n",
        "#     max_val = np.max(log_vals)\n",
        "#     norm_params[var_name[i]] = (min_val, max_val)\n",
        "#     val[:, i] = 2.0 * ((log_vals - min_val) / (max_val - min_val) - 0.5)\n",
        "\n",
        "# norm_params = {}\n",
        "real_data=val.copy()\n",
        "print(np.max(real_data))\n",
        "# Normalize values between -1 and 1\n",
        "for i in range(total_vars):\n",
        "    min_data = np.min(val[:, i])\n",
        "    max_data = np.max(val[:, i])\n",
        "    # norm_params[var_name[i]] = (min_data, max_data)\n",
        "    val[:, i] = 2.0 * ((val[:, i] - min_data) / (max_data - min_data) - 0.5)\n",
        "\n",
        "# Normalize Coordinates to [-1,1]\n",
        "for i in range(n_dim):\n",
        "    # Use (dim[i]-1] so that coordinates go from 0 to dim[i]-1.\n",
        "    cord[:, i] = 2.0 * (cord[:, i] / (dim[i] - 1) - 0.5)\n",
        "\n",
        "# # Normalize coordinates between 0 and 1\n",
        "# for i in range(n_dim):\n",
        "#     cord[:, i] = cord[:, i] / dim[i]\n",
        "\n",
        "\n",
        "# # Save normalized values and coordinates\n",
        "# np.save(f'{modified_data_path}n_cord.npy', cord)\n",
        "# np.save(f'{modified_data_path}n_val.npy', val)\n",
        "n_cord = cord.copy()\n",
        "n_val = val.copy()\n",
        "\n",
        "# # Reload data for verification\n",
        "# n_cord = np.load(f'{modified_data_path}n_cord.npy')\n",
        "# n_val = np.load(f'{modified_data_path}n_val.npy')\n",
        "# cord = np.load(f'{modified_data_path}cord.npy')\n",
        "# val = np.load(f'{modified_data_path}val.npy')\n",
        "means=n_val[:,0]\n",
        "stds=n_val[:,1]\n",
        "# Convert normalized data to PyTorch tensors\n",
        "torch_coords = torch.from_numpy(n_cord)\n",
        "torch_means = torch.from_numpy(means)\n",
        "torch_stds =torch.from_numpy(stds)\n",
        "# Display dataset details\n",
        "print('Dataset Name:', dataset_name)\n",
        "print('Total Variables:', total_vars)\n",
        "print('Variables Name:', var_name, end=\"\\n\\n\")\n",
        "print('Total Points in Data:', n_pts)\n",
        "print('Dimension of the Dataset:', dim)\n",
        "print('Number of Dimensions:', n_dim)\n",
        "print('Coordinate Tensor Shape:', torch_coords.shape)\n",
        "print('Scalar means Values Tensor Shape:', torch_means.shape)\n",
        "print('Scalar stds Values Tensor Shape:', torch_stds.shape)\n",
        "\n",
        "print('\\n###### Data setup is complete, now starting training ######\\n')"
      ],
      "metadata": {
        "_uuid": "521f7f9c-9a01-41f9-a149-1d15ff3fd1b8",
        "_cell_guid": "b0cbd8a2-2b80-4d5e-a135-f3c4b8b3c6c2",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:21.281683Z",
          "iopub.execute_input": "2025-05-26T20:25:21.282051Z",
          "iopub.status.idle": "2025-05-26T20:25:21.356747Z",
          "shell.execute_reply.started": "2025-05-26T20:25:21.282027Z",
          "shell.execute_reply": "2025-05-26T20:25:21.356094Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d4o9_RR5lmR",
        "outputId": "8224b472-44ec-45f5-c15f-37a1c3a99b94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161.9956817626953\n",
            "Dataset Name: 3d_data\n",
            "Total Variables: 2\n",
            "Variables Name: ['Average', 'Standard_Deviation']\n",
            "\n",
            "Total Points in Data: 262144\n",
            "Dimension of the Dataset: (64, 64, 64)\n",
            "Number of Dimensions: 3\n",
            "Coordinate Tensor Shape: torch.Size([262144, 3])\n",
            "Scalar means Values Tensor Shape: torch.Size([262144])\n",
            "Scalar stds Values Tensor Shape: torch.Size([262144])\n",
            "\n",
            "###### Data setup is complete, now starting training ######\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the DataLoader\n",
        "train_dataloader_mean = DataLoader(\n",
        "    TensorDataset(torch_coords, torch_means),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    pin_memory=True,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "# Model configuration\n",
        "obj = {\n",
        "    'total_vars': 1,\n",
        "    'dim': n_dim,\n",
        "    'n_neurons': n_neurons,\n",
        "    'n_layers': n_layers\n",
        "}\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model_mean = MyResidualSirenNet(obj).to(device)\n",
        "print(model_mean)\n",
        "\n",
        "optimizer = optim.Adam(model_mean.parameters(), lr=LR, betas=(0.9, 0.999))\n",
        "print(optimizer)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "print(criterion)\n",
        "\n",
        "# Training configuration summary\n",
        "print('\\nLearning Rate:', LR)\n",
        "print('Max Epochs:', MAX_EPOCH)\n",
        "print('Batch Size:', BATCH_SIZE)\n",
        "print('Number of Hidden Layers:', obj['n_layers'] - 2)\n",
        "print('Number of Neurons per Layer:', obj['n_neurons'])\n",
        "\n",
        "if decay:\n",
        "    print('Decay Rate:', decay_rate)\n",
        "    if decay_at_equal_interval:\n",
        "        print(f'Rate decays every {decay_interval} epochs.')\n",
        "    else:\n",
        "        print('Rate decays when the current epoch loss is greater than the previous epoch loss.')\n",
        "else:\n",
        "    print('No decay!')\n",
        "print()"
      ],
      "metadata": {
        "_uuid": "ec0c651a-5dad-486b-9fb7-1ccbaaf98cda",
        "_cell_guid": "adf3a3b0-29d8-4b33-ad38-babd78b228d1",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:21.357490Z",
          "iopub.execute_input": "2025-05-26T20:25:21.357712Z",
          "iopub.status.idle": "2025-05-26T20:25:23.403911Z",
          "shell.execute_reply.started": "2025-05-26T20:25:21.357694Z",
          "shell.execute_reply": "2025-05-26T20:25:23.403094Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnnT0LL_5lmS",
        "outputId": "a125a3e8-0442-47f6-9ebc-00249d90911a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyResidualSirenNet(\n",
            "  (net_layers): ModuleList(\n",
            "    (0): SineLayer(\n",
            "      (linear): Linear(in_features=3, out_features=150, bias=True)\n",
            "    )\n",
            "    (1-6): 6 x ResidualSineLayer(\n",
            "      (linear_1): Linear(in_features=150, out_features=150, bias=True)\n",
            "      (linear_2): Linear(in_features=150, out_features=150, bias=True)\n",
            "    )\n",
            "    (7): Linear(in_features=150, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 5e-05\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "MSELoss()\n",
            "\n",
            "Learning Rate: 5e-05\n",
            "Max Epochs: 200\n",
            "Batch Size: 2048\n",
            "Number of Hidden Layers: 6\n",
            "Number of Neurons per Layer: 150\n",
            "Decay Rate: 0.8\n",
            "Rate decays every 15 epochs.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list = []\n",
        "best_epoch = -1\n",
        "best_loss = 1e8\n",
        "best_model=\"\"\n",
        "from tqdm import tqdm\n",
        "# Ensure the output path exists\n",
        "if not os.path.exists(outpath):\n",
        "    os.makedirs(outpath)\n",
        "\n",
        "# Training loop\n",
        "for epoch in tqdm(range(MAX_EPOCH)):\n",
        "    model_mean.train()\n",
        "    temp_loss_list = []\n",
        "    start = time.time()\n",
        "\n",
        "    # Batch-by-batch training\n",
        "    for X_train, y_train in train_dataloader_mean:\n",
        "        X_train = X_train.type(torch.float32).to(device)\n",
        "        y_train = y_train.type(torch.float32).to(device)\n",
        "\n",
        "        if univariate:\n",
        "            y_train = y_train.squeeze()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model_mean(X_train)\n",
        "        predictions = predictions.squeeze()\n",
        "        loss = criterion(predictions, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track batch loss\n",
        "        temp_loss_list.append(loss.detach().cpu().numpy())\n",
        "\n",
        "    # Calculate epoch loss\n",
        "    epoch_loss = np.average(temp_loss_list)\n",
        "\n",
        "    # Learning rate decay\n",
        "    if decay:\n",
        "        if decay_at_equal_interval:\n",
        "            if epoch >= decay_interval and epoch % decay_interval == 0:\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] *= decay_rate\n",
        "        # else:\n",
        "        #     if epoch > 0 and epoch_loss > train_loss_list[-1]:\n",
        "        #         for param_group in optimizer.param_groups:\n",
        "        #             param_group['lr'] *= decay_rate\n",
        "        if epoch > 0 and epoch_loss > train_loss_list[-1]:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] *= decay_rate\n",
        "\n",
        "    # Track losses and best model\n",
        "    train_loss_list.append(epoch_loss)\n",
        "    if epoch_loss < best_loss:\n",
        "        best_loss = epoch_loss\n",
        "        best_epoch = epoch+1\n",
        "        if(best_model==0):\n",
        "            best_model=model_mean.state_dict()\n",
        "        else:\n",
        "            best_model=model_mean.state_dict()\n",
        "\n",
        "    end = time.time()\n",
        "    print(\n",
        "        f\"Epoch: {epoch + 1}/{MAX_EPOCH} | Train Loss: {train_loss_list[-1]} | \"\n",
        "        f\"Time: {round(end - start, 2)}s ({device}) | LR: {optimizer.param_groups[0]['lr']}\"\n",
        "    )\n",
        "\n",
        "    # Save model at intervals\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        model_name = (\n",
        "            f'train_{dataset_name}_{epoch + 1}ep_{n_layers - 2}rb_{n_neurons}n_'\n",
        "            f'{BATCH_SIZE}bs_{LR}lr_{decay}decay_{decay_rate}dr_'\n",
        "            f'{\"decayingAtInterval\" + str(decay_interval)+\"mean\" if decay_at_equal_interval else \"decayingWhenLossIncr\"}'\n",
        "        )\n",
        "        torch.save(\n",
        "            {\"epoch\": epoch + 1, \"model_state_dict\": model_mean.state_dict()},\n",
        "            os.path.join(outpath, f'{model_name}_mean.pth')\n",
        "        )\n",
        "\n",
        "# Final summary\n",
        "print('\\nEpoch with Least Loss:', best_epoch, '| Loss:', best_loss, '\\n')\n",
        "\n",
        "# Save the final model\n",
        "model_name = f'siren_compressor'\n",
        "torch.save(\n",
        "    {\"epoch\": MAX_EPOCH, \"model_state_dict\": model_mean.state_dict()},\n",
        "    os.path.join(outpath, f'{model_name}_mean.pth')\n",
        ")\n",
        "torch.save(\n",
        "    {\"epoch\": best_epoch, \"model_state_dict\": best_model},\n",
        "    os.path.join(outpath, f'{best_epoch}_mean.pth')\n",
        ")\n"
      ],
      "metadata": {
        "_uuid": "16645d61-b423-4e5a-a7d2-5f692a4f6102",
        "_cell_guid": "1c6f398e-b851-4fad-b62e-4080114fa832",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:25:23.404654Z",
          "iopub.execute_input": "2025-05-26T20:25:23.405027Z",
          "iopub.status.idle": "2025-05-26T20:39:04.911778Z",
          "shell.execute_reply.started": "2025-05-26T20:25:23.405000Z",
          "shell.execute_reply": "2025-05-26T20:39:04.910700Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "dZt3Bxfu5lmS",
        "outputId": "de1c2f28-3836-4968-c58f-fad33295c96d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "  0%|          | 0/200 [00:02<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-21-4132908452.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    218\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                     new_grads.append(\n\u001b[0;32m--> 220\u001b[0;31m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     )\n\u001b[1;32m    222\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize prediction lists\n",
        "prediction_list = [[] for _ in range(1)]\n",
        "total_vars=1\n",
        "# Inference loop\n",
        "model_mean = MyResidualSirenNet(obj).to(device)\n",
        "state_dict = torch.load('/content/150_neurons_mean.pth')['model_state_dict']\n",
        "model_mean.load_state_dict(state_dict)\n",
        "with torch.no_grad():\n",
        "    for i in range(0, torch_coords.shape[0], group_size):\n",
        "        coords = torch_coords[i:min(i + group_size, torch_coords.shape[0])].type(torch.float32).to(device)\n",
        "        vals = model_mean(coords)\n",
        "        vals = vals.to('cpu')\n",
        "\n",
        "        for j in range(total_vars):\n",
        "            prediction_list[j].append(vals[:, j])\n",
        "\n",
        "# Extract and concatenate predictions\n",
        "extracted_list = [[] for _ in range(1)]\n",
        "for i in range(len(prediction_list[0])):\n",
        "    for j in range(1):\n",
        "        el = prediction_list[j][i].detach().numpy()\n",
        "        extracted_list[j].append(el)\n",
        "\n",
        "for j in range(1):\n",
        "    extracted_list[j] = np.concatenate(extracted_list[j], dtype='float32')\n",
        "\n",
        "# Final prediction (normalized)\n",
        "n_predictions_means = np.array(extracted_list).T\n",
        "\n",
        "# Compute PSNR\n",
        "#findMultiVariatePSNR(var_name[0], total_vars, n_val[:,0], n_predictions_means[:,0])\n",
        "print(\"mean\",compute_PSNR(n_val[:,0],n_predictions_means[:,0]))\n",
        "# Compute RMSE\n",
        "rmse = compute_rmse(n_val[:,0], n_predictions_means[:,0])\n",
        "print(\"RMSE:\", rmse)"
      ],
      "metadata": {
        "_uuid": "07a36d31-db47-4d2c-b11d-5339aa8cb204",
        "_cell_guid": "cc00efa1-e7a5-4a3a-aa44-d056d987dcb8",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:39:04.914949Z",
          "iopub.execute_input": "2025-05-26T20:39:04.915203Z",
          "iopub.status.idle": "2025-05-26T20:39:05.385328Z",
          "shell.execute_reply.started": "2025-05-26T20:39:04.915181Z",
          "shell.execute_reply": "2025-05-26T20:39:05.384428Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NW3xL0y5lmS",
        "outputId": "52fe443d-de4d-4ddd-b15b-ae92c48a62f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean 72.7810994165529\n",
            "RMSE: 0.00045917160629419825\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#finetunning model"
      ],
      "metadata": {
        "id": "Oyt9w2KKR9yR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm # For progress bar\n",
        "\n",
        "# Re-define your model classes (SineLayer, ResidualSineLayer, MyResidualSirenNet)\n",
        "# These are essential for re-building the pruned model.\n",
        "# (Copy and paste them from your notebook)\n",
        "\n",
        "class SineLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, bias=True, is_first=False, omega_0=30):\n",
        "        super().__init__()\n",
        "        self.omega_0 = omega_0\n",
        "        self.is_first = is_first\n",
        "        self.in_features = in_features\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        with torch.no_grad():\n",
        "            if self.is_first:\n",
        "                self.linear.weight.uniform_(-1 / self.in_features,\n",
        "                                             1 / self.in_features)\n",
        "            else:\n",
        "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0,\n",
        "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        return torch.sin(self.omega_0 * x)\n",
        "\n",
        "class ResidualSineLayer(nn.Module):\n",
        "    def __init__(self, features, bias=True, ave_first=False, ave_second=False, omega_0=30):\n",
        "        super().__init__()\n",
        "        self.omega_0 = omega_0\n",
        "        self.features = features\n",
        "        self.linear_1 = nn.Linear(features, features, bias=bias)\n",
        "        self.linear_2 = nn.Linear(features, features, bias=bias)\n",
        "        self.weight_1 = .5 if ave_first else 1\n",
        "        self.weight_2 = .5 if ave_second else 1\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        with torch.no_grad():\n",
        "            self.linear_1.weight.uniform_(-np.sqrt(6 / self.features) / self.omega_0,\n",
        "                                           np.sqrt(6 / self.features) / self.omega_0)\n",
        "            self.linear_2.weight.uniform_(-np.sqrt(6 / self.features) / self.omega_0,\n",
        "                                           np.sqrt(6 / self.features) / self.omega_0)\n",
        "\n",
        "    def forward(self, input):\n",
        "        linear_1_out = self.linear_1(self.weight_1*input)\n",
        "        sine_1_out = torch.sin(self.omega_0 * linear_1_out)\n",
        "        sine_2_out = torch.sin(self.omega_0 * self.linear_2(sine_1_out))\n",
        "        return self.weight_2*(input+sine_2_out)\n",
        "\n",
        "class MyResidualSirenNet(nn.Module):\n",
        "    def __init__(self, obj):\n",
        "        super(MyResidualSirenNet, self).__init__()\n",
        "        self.Omega_0 = 30\n",
        "        self.n_layers = obj['n_layers']\n",
        "        self.input_dim = obj['dim']\n",
        "        self.output_dim = obj['total_vars']\n",
        "        self.neurons_per_layer = obj['n_neurons']\n",
        "\n",
        "        self.layers_dim_list = [self.input_dim]\n",
        "        for i in range(self.n_layers - 1):\n",
        "            self.layers_dim_list.append(self.neurons_per_layer)\n",
        "        self.layers_dim_list.append(self.output_dim)\n",
        "\n",
        "        self.net_layers = nn.ModuleList()\n",
        "        for idx in np.arange(self.n_layers):\n",
        "            layer_in = self.layers_dim_list[idx]\n",
        "            layer_out = self.layers_dim_list[idx + 1]\n",
        "\n",
        "            if idx == 0:\n",
        "                self.net_layers.append(SineLayer(layer_in, layer_out, bias=True, is_first=True))\n",
        "            elif idx != self.n_layers - 1:\n",
        "                self.net_layers.append(ResidualSineLayer(layer_in, bias=True, ave_first=idx > 1, ave_second=idx == (self.n_layers - 2)))\n",
        "            else:\n",
        "                final_linear = nn.Linear(layer_in, layer_out)\n",
        "                with torch.no_grad():\n",
        "                    final_linear.weight.uniform_(-np.sqrt(6 / (layer_in)) / self.Omega_0, np.sqrt(6 / (layer_in)) / self.Omega_0)\n",
        "                self.net_layers.append(final_linear)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for net_layer in self.net_layers:\n",
        "            x = net_layer(x)\n",
        "        return x\n",
        "\n",
        "# Your utility functions (compute_PSNR, denormalizeValue, etc.)\n",
        "def compute_PSNR(arrgt,arr_recon):\n",
        "    diff = arrgt - arr_recon\n",
        "    sqd_max_diff = (np.max(arrgt)-np.min(arrgt))**2\n",
        "    # Ensure MSE is not zero for log calculation\n",
        "    mse = np.mean(diff**2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    psnr = 10*np.log10(sqd_max_diff/mse)\n",
        "    return psnr\n",
        "\n",
        "def compute_rmse(actual, predicted):\n",
        "    mse = np.mean((actual - predicted) ** 2)\n",
        "    return np.sqrt(mse)\n",
        "\n",
        "def denormalizeValue(total_vars, to, ref):\n",
        "    to_arr = np.array(to)\n",
        "    for i in range(total_vars):\n",
        "        min_data = np.min(ref[:, i])\n",
        "        max_data = np.max(ref[:, i])\n",
        "        # Invert the normalization: val[:, i] = 2.0 * ((val[:, i] - min_data) / (max_data - min_data) - 0.5);\n",
        "        # val_norm = 2 * (val_orig - min_data) / (max_data - min_data) - 1\n",
        "        # (val_norm + 1) / 2 = (val_orig - min_data) / (max_data - min_data)\n",
        "        # val_orig = ((val_norm + 1) / 2) * (max_data - min_data) + min_data\n",
        "        to_arr[:, i] = (((to[:, i] * 0.5) + 0.5) * (max_data - min_data)) + min_data\n",
        "    return to_arr\n",
        "\n",
        "# Assume args, n_dim, total_vars, var_name, dim, n_pts, real_data, n_val, torch_coords, torch_means, torch_stds are loaded as in your notebook\n",
        "# You will need to load your data and initial models first.\n",
        "# This part is critical for loading the actual data and original model states for pruning and evaluation.\n",
        "# Given your notebook, the PSNR for mean model is `72.7810994165529`\n",
        "# PSNR for std model is `61.882343845798715`\n",
        "# You want to prune the model while maintaining a PSNR of at least 70.0.\n",
        "\n",
        "# Mocking your data loading and setup based on your notebook\n",
        "from argparse import Namespace\n",
        "args = Namespace(\n",
        "    n_neurons=150,\n",
        "    n_layers=6, # This means 6 residual blocks + input + output = 8 layers in total\n",
        "    epochs=200,\n",
        "    batchsize=512,\n",
        "    lr=0.00005,\n",
        "    no_decay=False,\n",
        "    decay_rate=0.8,\n",
        "    decay_at_interval=True,\n",
        "    decay_interval=15,\n",
        "    datapath='/content/Teardrop_Gaussian.vti',\n",
        "    outpath='./models/',\n",
        "    exp_path='../logs/',\n",
        "    modified_data_path='./data/',\n",
        "    dataset_name='3d_data',\n",
        "    vti_name='predicted.vti',\n",
        "    vti_path='./data/'\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# --- Dummy data loading for demonstration. Replace with your actual VTK loading ---\n",
        "# For actual execution, you'd run the VTK loading cells from your notebook.\n",
        "# This is to make the pruning code runnable independently if you don't have VTK setup directly.\n",
        "n_pts = 262144\n",
        "n_dim = 3\n",
        "dim = (64, 64, 64)\n",
        "total_vars = 2\n",
        "var_name = ['Average', 'Standard_Deviation']\n",
        "\n",
        "# Create dummy coordinate and value arrays for demonstration # Unnormalized original data\n",
        "\n",
        "# Normalize values between -1 and 1\n",
        "n_val = real_data.copy()\n",
        "for i in range(total_vars):\n",
        "    min_data = np.min(n_val[:, i])\n",
        "    max_data = np.max(n_val[:, i])\n",
        "    n_val[:, i] = 2.0 * ((n_val[:, i] - min_data) / (max_data - min_data) - 0.5)\n",
        "\n",
        "# Normalize Coordinates to [-1,1]\n",
        "# n_cord = cord.copy()\n",
        "# for i in range(n_dim):\n",
        "#     n_cord[:, i] = 2.0 * (n_cord[:, i] / (dim[i] - 1) - 0.5)\n",
        "# n_cord=\n",
        "torch_coords = torch.from_numpy(n_cord).float()\n",
        "torch_means = torch.from_numpy(n_val[:, 0]).float()\n",
        "torch_stds = torch.from_numpy(n_val[:, 1]).float()\n",
        "\n",
        "# --- End of dummy data loading ---\n",
        "\n",
        "# Model configuration from args\n",
        "obj_original = {\n",
        "    'total_vars': 1,\n",
        "    'dim': n_dim,\n",
        "    'n_neurons': args.n_neurons,\n",
        "    'n_layers': args.n_layers + 2 # Includes input and output as per your notebook's definition\n",
        "}\n",
        "\n",
        "# Load the trained mean model\n",
        "original_mean_model = MyResidualSirenNet(obj_original).to(device)\n",
        "model_path = os.path.join(args.outpath, '/content/150_neurons_mean.pth') # Assuming you saved your best mean model as 200_mean.pth or similar\n",
        "if os.path.exists(model_path):\n",
        "    print(f\"Loading original model from {model_path}\")\n",
        "    original_state_dict = torch.load(model_path, map_location=device)['model_state_dict']\n",
        "    original_mean_model.load_state_dict(original_state_dict)\n",
        "else:\n",
        "    print(f\"Warning: Model file not found at {model_path}. Please ensure your trained model is saved correctly.\")\n",
        "    # As a fallback for demonstration, initialize random weights if model is not found\n",
        "    print(\"Initializing a new model for demonstration purposes.\")\n",
        "    # You would typically train it here or load a different existing one.\n",
        "\n",
        "original_mean_model.eval()\n",
        "\n",
        "# Calculate initial PSNR for verification\n",
        "with torch.no_grad():\n",
        "    test_coords = torch_coords.to(device)\n",
        "    original_predictions = original_mean_model(test_coords).squeeze().cpu().numpy()\n",
        "initial_psnr = compute_PSNR(n_val[:, 0], original_predictions)\n",
        "print(f\"Initial PSNR (Mean Model): {initial_psnr:.4f}\")\n",
        "print(f\"Original model parameters: {sum(p.numel() for p in original_mean_model.parameters())}\")\n",
        "\n",
        "# --- PRUNING FUNCTION ---\n",
        "def prune_siren_model(original_model, original_obj, prune_ratio, train_dataloader, original_n_val_target, fine_tune_epochs=50, fine_tune_lr=0.00001, target_psnr=70.0):\n",
        "    \"\"\"\n",
        "    Performs structured pruning on the SIREN model by removing neurons.\n",
        "\n",
        "    Args:\n",
        "        original_model (nn.Module): The already trained MyResidualSirenNet model.\n",
        "        original_obj (dict): The original configuration object for MyResidualSirenNet.\n",
        "        prune_ratio (float): The fraction of neurons to prune (e.g., 0.1 for 10%).\n",
        "        train_dataloader (DataLoader): DataLoader for fine-tuning.\n",
        "        original_n_val_target (np.ndarray): The normalized ground truth values for PSNR calculation.\n",
        "        fine_tune_epochs (int): Number of epochs for fine-tuning after pruning.\n",
        "        fine_tune_lr (float): Learning rate for fine-tuning.\n",
        "        target_psnr (float): The minimum acceptable PSNR after pruning.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (pruned_model, new_n_neurons, final_psnr) if successful, else (None, None, None)\n",
        "    \"\"\"\n",
        "    device = next(original_model.parameters()).device # Get current device\n",
        "\n",
        "    # Identify prune-able layers and collect their weights/biases\n",
        "    layers_to_prune = [] # Stores (layer_idx, module_name, linear_module, is_residual_input, current_in_features)\n",
        "\n",
        "    # First layer (SineLayer)\n",
        "    # Prune its 'out_features'\n",
        "    first_layer_module = original_model.net_layers[0].linear\n",
        "    layers_to_prune.append((0, 'input_sine_layer', first_layer_module, False, first_layer_module.in_features))\n",
        "\n",
        "    # ResidualSineLayers (each has linear_1 and linear_2)\n",
        "    # Prune 'features' (which is both in_features and out_features for linear_1 and linear_2)\n",
        "    for i in range(1, original_obj['n_layers'] - 1): # Iterate through ResidualSineLayers\n",
        "        res_block_module = original_model.net_layers[i]\n",
        "        # linear_1's output neurons are candidates\n",
        "        layers_to_prune.append((i, f'residual_block_{i}_linear_1', res_block_module.linear_1, False, res_block_module.linear_1.in_features))\n",
        "        # linear_2's output neurons are candidates\n",
        "        layers_to_prune.append((i, f'residual_block_{i}_linear_2', res_block_module.linear_2, False, res_block_module.linear_2.in_features))\n",
        "\n",
        "    # Last layer (Linear) - its 'in_features' are the 'out_features' of the last residual block\n",
        "    # We don't prune the output layer's *output* (total_vars), only its *input* which comes from the previous layer\n",
        "    # So, the effective pruning is done on the last ResidualSineLayer's output\n",
        "    # This is handled implicitly by adjusting `new_n_neurons`.\n",
        "\n",
        "    # Calculate L1 norms for all potential neurons to prune (output features)\n",
        "    neuron_l1_norms = []\n",
        "    # Store (l1_norm, layer_index_in_net_layers, internal_linear_idx_in_block, neuron_index)\n",
        "    # We collect all neurons from intermediate layers to prune\n",
        "    for layer_idx, _, linear_module, _, _ in layers_to_prune:\n",
        "        # L1 norm for each *output neuron* (column of the weight matrix)\n",
        "        # weight.data shape is (out_features, in_features)\n",
        "        # We want to prune out_features (rows), so compute norm along dim=1 (input features)\n",
        "        l1_norms = torch.norm(linear_module.weight.data, p=1, dim=1) # L1 norm per output feature\n",
        "        for neuron_idx, norm_val in enumerate(l1_norms):\n",
        "            neuron_l1_norms.append((norm_val.item(), layer_idx, neuron_idx))\n",
        "\n",
        "    # Sort neurons by L1 norm (ascending)\n",
        "    neuron_l1_norms.sort(key=lambda x: x[0])\n",
        "\n",
        "    # Determine how many neurons to prune from the hidden layers (neurons_per_layer)\n",
        "    # We apply the prune_ratio to the 'neurons_per_layer'\n",
        "    original_hidden_neurons = original_obj['n_neurons']\n",
        "    num_neurons_to_prune = int(original_hidden_neurons * prune_ratio)\n",
        "    if num_neurons_to_prune < 1 and prune_ratio > 0: # Ensure at least one neuron is pruned if ratio is positive\n",
        "        num_neurons_to_prune = 1\n",
        "    if num_neurons_to_prune >= original_hidden_neurons: # Don't prune all\n",
        "        print(f\"Warning: Prune ratio {prune_ratio} is too high. Cannot prune all neurons. Adjusting to prune {original_hidden_neurons - 1} neurons.\")\n",
        "        num_neurons_to_prune = original_hidden_neurons - 1\n",
        "    if num_neurons_to_prune < 0: # No negative pruning\n",
        "        num_neurons_to_prune = 0\n",
        "\n",
        "\n",
        "    # Create a set of indices of neurons to keep for each relevant layer\n",
        "    # We will identify the lowest L1 norm neurons to prune.\n",
        "    neurons_to_prune_per_layer_map = {} # {layer_idx: set(neuron_indices_to_prune)}\n",
        "\n",
        "    # Collect the indices of neurons to prune based on the sorted L1 norms\n",
        "    # We prune from the most \"dense\" layers, which are the main hidden layers (residual blocks)\n",
        "    # This assumes uniform pruning across all hidden layers to maintain the residual structure's dimensions\n",
        "    # For a simple uniform prune across all hidden layers:\n",
        "    pruned_neurons_indices = set()\n",
        "    for _, layer_idx, neuron_idx in neuron_l1_norms:\n",
        "        # Apply pruning primarily to the hidden layers (layers with n_neurons)\n",
        "        # The input layer's output (layer 0) and residual layers (1 to n_layers-2) all have 'n_neurons' as output features\n",
        "        if original_obj['n_layers'] > 2 and layer_idx > 0 and layer_idx < original_obj['n_layers'] - 1 : # All hidden layers\n",
        "            if len(pruned_neurons_indices) < num_neurons_to_prune:\n",
        "                pruned_neurons_indices.add(neuron_idx) # Neuron index within its layer\n",
        "            else:\n",
        "                break\n",
        "\n",
        "    # If we collected enough neurons from a variety of layers, convert set to list and sort\n",
        "    if len(pruned_neurons_indices) > 0:\n",
        "        pruned_neurons_indices = sorted(list(pruned_neurons_indices))\n",
        "        kept_neurons_indices = sorted([i for i in range(original_hidden_neurons) if i not in pruned_neurons_indices])\n",
        "    else: # No neurons pruned\n",
        "        kept_neurons_indices = list(range(original_hidden_neurons))\n",
        "\n",
        "    new_n_neurons = len(kept_neurons_indices)\n",
        "    if new_n_neurons == 0:\n",
        "        print(\"Error: Cannot prune all neurons. Resulting model would have 0 neurons.\")\n",
        "        return None, None, None\n",
        "\n",
        "    print(f\"Original hidden neurons: {original_hidden_neurons}, New hidden neurons: {new_n_neurons} (Pruning {num_neurons_to_prune} neurons)\")\n",
        "\n",
        "\n",
        "    # Construct the new, pruned model architecture\n",
        "    new_obj = original_obj.copy()\n",
        "    new_obj['n_neurons'] = new_n_neurons\n",
        "\n",
        "    pruned_model = MyResidualSirenNet(new_obj).to(device)\n",
        "    print(f\"New pruned model architecture:\\n{pruned_model}\")\n",
        "    print(f\"New pruned model parameters: {sum(p.numel() for p in pruned_model.parameters())}\")\n",
        "    print(f\"Parameter reduction: {1 - sum(p.numel() for p in pruned_model.parameters()) / sum(p.numel() for p in original_model.parameters()):.2%}\")\n",
        "\n",
        "\n",
        "    # Copy weights from original model to pruned model\n",
        "    with torch.no_grad():\n",
        "        # First SineLayer: Only its 'out_features' are affected\n",
        "        # original_model.net_layers[0].linear.weight shape: (out_features, in_features)\n",
        "        # kept_neurons_indices are for its out_features\n",
        "        pruned_model.net_layers[0].linear.weight.data = original_model.net_layers[0].linear.weight.data[kept_neurons_indices, :]\n",
        "        pruned_model.net_layers[0].linear.bias.data = original_model.net_layers[0].linear.bias.data[kept_neurons_indices]\n",
        "\n",
        "        # ResidualSineLayers: These are tricky because of the skip connection and two linear layers\n",
        "        # Each ResidualSineLayer(features) means both linear_1 and linear_2 have (features, features)\n",
        "        # When you prune 'features', it affects both in and out dimensions of these internal layers\n",
        "        # The skip connection also remains of size 'features'\n",
        "        for i in range(1, original_obj['n_layers'] - 1):\n",
        "            original_res_block = original_model.net_layers[i]\n",
        "            pruned_res_block = pruned_model.net_layers[i]\n",
        "\n",
        "            # linear_1: its in_features is new_n_neurons (from previous layer), its out_features is also new_n_neurons\n",
        "            # original_res_block.linear_1.weight shape: (old_out_features, old_in_features)\n",
        "            # You want to select rows (output features) by `kept_neurons_indices`\n",
        "            # and columns (input features) by `kept_neurons_indices`\n",
        "            pruned_res_block.linear_1.weight.data = original_res_block.linear_1.weight.data[kept_neurons_indices, :]\n",
        "            pruned_res_block.linear_1.weight.data = pruned_res_block.linear_1.weight.data[:, kept_neurons_indices]\n",
        "            pruned_res_block.linear_1.bias.data = original_res_block.linear_1.bias.data[kept_neurons_indices]\n",
        "\n",
        "            # linear_2: same as linear_1\n",
        "            pruned_res_block.linear_2.weight.data = original_res_block.linear_2.weight.data[kept_neurons_indices, :]\n",
        "            pruned_res_block.linear_2.weight.data = pruned_res_block.linear_2.weight.data[:, kept_neurons_indices]\n",
        "            pruned_res_block.linear_2.bias.data = original_res_block.linear_2.bias.data[kept_neurons_indices]\n",
        "\n",
        "        # Final Linear Layer: Its 'in_features' are from the last residual block's output\n",
        "        # So its columns (input features) need to be subsetted by kept_neurons_indices\n",
        "        pruned_model.net_layers[-1].weight.data = original_model.net_layers[-1].weight.data[:, kept_neurons_indices]\n",
        "        pruned_model.net_layers[-1].bias.data = original_model.net_layers[-1].bias.data\n",
        "\n",
        "\n",
        "    # Fine-tuning\n",
        "    print(f\"\\n--- Fine-tuning pruned model for {fine_tune_epochs} epochs ---\")\n",
        "    pruned_model.train()\n",
        "    optimizer_pruned = optim.Adam(pruned_model.parameters(), lr=fine_tune_lr, betas=(0.9, 0.999))\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    best_pruned_loss = float('inf')\n",
        "    best_pruned_state = None\n",
        "\n",
        "    for epoch in tqdm(range(fine_tune_epochs)):\n",
        "        epoch_loss_list = []\n",
        "        for X_train, y_train in train_dataloader:\n",
        "            X_train = X_train.type(torch.float32).to(device)\n",
        "            y_train = y_train.type(torch.float32).to(device)\n",
        "            y_train = y_train.squeeze() # Assuming your target is 1D\n",
        "\n",
        "            optimizer_pruned.zero_grad()\n",
        "            predictions = pruned_model(X_train).squeeze()\n",
        "            loss = criterion(predictions, y_train)\n",
        "            loss.backward()\n",
        "            optimizer_pruned.step()\n",
        "            epoch_loss_list.append(loss.detach().cpu().numpy())\n",
        "\n",
        "        current_epoch_loss = np.mean(epoch_loss_list)\n",
        "        if current_epoch_loss < best_pruned_loss:\n",
        "            best_pruned_loss = current_epoch_loss\n",
        "            best_pruned_state = pruned_model.state_dict()\n",
        "\n",
        "        print(f\"Fine-tune Epoch {epoch+1}/{fine_tune_epochs}, Loss: {current_epoch_loss:.6e}, LR: {optimizer_pruned.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "    if best_pruned_state:\n",
        "        pruned_model.load_state_dict(best_pruned_state)\n",
        "    pruned_model.eval()\n",
        "\n",
        "    # Evaluate PSNR after fine-tuning\n",
        "    with torch.no_grad():\n",
        "        test_coords = torch_coords.to(device)\n",
        "        final_predictions = pruned_model(test_coords).squeeze().cpu().numpy()\n",
        "    final_psnr = compute_PSNR(original_n_val_target, final_predictions)\n",
        "    print(f\"\\nFinal PSNR after pruning and fine-tuning: {final_psnr:.4f}\")\n",
        "\n",
        "    if final_psnr >= target_psnr:\n",
        "        print(f\"Pruning successful! Achieved {final_psnr:.2f} PSNR with {new_n_neurons} hidden neurons.\")\n",
        "        return pruned_model, new_n_neurons, final_psnr\n",
        "    else:\n",
        "        print(f\"Pruning resulted in PSNR {final_psnr:.2f} which is below target {target_psnr:.2f}. Consider less aggressive pruning.\")\n",
        "        return None, None, None\n",
        "\n",
        "# --- Main Pruning Execution ---\n",
        "\n",
        "# Set up DataLoader for the mean model's data\n",
        "# You need to make sure torch_coords and torch_means are loaded from your actual data.\n",
        "train_dataloader_mean = DataLoader(\n",
        "    TensorDataset(torch_coords, torch_means),\n",
        "    batch_size=args.batchsize,\n",
        "    pin_memory=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0 # Set to 0 for simpler debugging in notebooks, adjust as needed\n",
        ")\n",
        "\n",
        "# Iterative pruning loop\n",
        "prune_ratios = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30] # Try different pruning percentages\n",
        "current_best_pruned_model = None\n",
        "current_best_psnr = initial_psnr\n",
        "current_n_neurons = obj_original['n_neurons']\n",
        "\n",
        "print(\"\\n--- Starting Iterative Pruning ---\")\n",
        "\n",
        "for p_ratio in prune_ratios:\n",
        "    print(f\"\\nAttempting to prune with ratio: {p_ratio * 100:.0f}%\")\n",
        "\n",
        "    # Pass the *original* obj for architecture definition, but the pruning function will modify it\n",
        "    pruned_model, new_neurons, final_psnr = prune_siren_model(\n",
        "        original_mean_model, # The full model from previous iteration or initial model\n",
        "        obj_original,   # Use the original model's parameters for structure definition\n",
        "        prune_ratio=p_ratio,\n",
        "        train_dataloader=train_dataloader_mean,\n",
        "        original_n_val_target=n_val[:, 0], # Target for PSNR\n",
        "        fine_tune_epochs=50,\n",
        "        fine_tune_lr=args.lr * 0.1, # Typically lower learning rate for fine-tuning\n",
        "        target_psnr=70.0\n",
        "    )\n",
        "\n",
        "    if pruned_model is not None:\n",
        "        if final_psnr > current_best_psnr: # Prioritize PSNR\n",
        "             # If this pruning yields a better PSNR (though we want <=70), or is first good result\n",
        "            current_best_pruned_model = pruned_model\n",
        "            current_best_psnr = final_psnr\n",
        "            current_n_neurons = new_neurons\n",
        "            print(f\"Updated best model with {new_neurons} neurons and PSNR: {final_psnr:.2f}\")\n",
        "            # Save this best model\n",
        "            model_save_name = f'pruned_siren_mean_{new_neurons}n.pth'\n",
        "            torch.save(current_best_pruned_model.state_dict(), os.path.join(args.outpath, model_save_name))\n",
        "            print(f\"Saved best pruned model to {os.path.join(args.outpath, model_save_name)}\")\n",
        "        elif final_psnr >= 70.0 and sum(p.numel() for p in pruned_model.parameters()) < sum(p.numel() for p in (current_best_pruned_model if current_best_pruned_model else original_model).parameters()):\n",
        "            # If PSNR is acceptable AND model is smaller than current best acceptable model\n",
        "            current_best_pruned_model = pruned_model\n",
        "            current_best_psnr = final_psnr\n",
        "            current_n_neurons = new_neurons\n",
        "            print(f\"Updated best model with {new_neurons} neurons and PSNR: {final_psnr:.2f}\")\n",
        "            # Save this best model\n",
        "            model_save_name = f'pruned_siren_mean_{new_neurons}n.pth'\n",
        "            torch.save(current_best_pruned_model.state_dict(), os.path.join(args.outpath, model_save_name))\n",
        "            print(f\"Saved best pruned model to {os.path.join(args.outpath, model_save_name)}\")\n",
        "    else:\n",
        "        print(f\"Pruning with ratio {p_ratio * 100:.0f}% failed to meet PSNR target.\")\n",
        "        # If a pruning ratio fails, you might want to stop increasing the ratio or try smaller increments.\n",
        "        # break # Option to stop if performance drops significantly.\n",
        "\n",
        "print(\"\\n--- Pruning Process Complete ---\")\n",
        "if current_best_pruned_model:\n",
        "    print(f\"Best pruned model found with {current_n_neurons} neurons and PSNR: {current_best_psnr:.2f}\")\n",
        "    print(f\"Original model parameters: {sum(p.numel() for p in original_mean_model.parameters())}\")\n",
        "    print(f\"Final pruned model parameters: {sum(p.numel() for p in current_best_pruned_model.parameters())}\")\n",
        "    print(f\"Total parameter reduction: {1 - sum(p.numel() for p in current_best_pruned_model.parameters()) / sum(p.numel() for p in original_mean_model.parameters()):.2%}\")\n",
        "else:\n",
        "    print(\"No pruned model found that met the PSNR target.\")"
      ],
      "metadata": {
        "id": "8QVGULB2Wg1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c79bbffe-bf3e-4ce3-fb23-dd817aedb79b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading original model from /content/150_neurons_mean.pth\n",
            "Initial PSNR (Mean Model): 72.7811\n",
            "Original model parameters: 272551\n",
            "\n",
            "--- Starting Iterative Pruning ---\n",
            "\n",
            "Attempting to prune with ratio: 5%\n",
            "Original hidden neurons: 150, New hidden neurons: 143 (Pruning 7 neurons)\n",
            "New pruned model architecture:\n",
            "MyResidualSirenNet(\n",
            "  (net_layers): ModuleList(\n",
            "    (0): SineLayer(\n",
            "      (linear): Linear(in_features=3, out_features=143, bias=True)\n",
            "    )\n",
            "    (1-6): 6 x ResidualSineLayer(\n",
            "      (linear_1): Linear(in_features=143, out_features=143, bias=True)\n",
            "      (linear_2): Linear(in_features=143, out_features=143, bias=True)\n",
            "    )\n",
            "    (7): Linear(in_features=143, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "New pruned model parameters: 247820\n",
            "Parameter reduction: 9.07%\n",
            "\n",
            "--- Fine-tuning pruned model for 50 epochs ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/50 [00:04<03:18,  4.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 1/50, Loss: 3.497561e-04, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [00:08<03:37,  4.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 2/50, Loss: 3.140939e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [00:13<03:27,  4.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 3/50, Loss: 1.610739e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [00:17<03:26,  4.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 4/50, Loss: 1.052519e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [00:22<03:20,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 5/50, Loss: 7.700598e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [00:26<03:12,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 6/50, Loss: 6.179420e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [00:31<03:12,  4.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 7/50, Loss: 5.300114e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [00:35<03:04,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 8/50, Loss: 4.721413e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [00:39<02:58,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 9/50, Loss: 4.266458e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [00:44<03:00,  4.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 10/50, Loss: 4.168041e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [00:48<02:50,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 11/50, Loss: 3.895726e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [00:52<02:42,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 12/50, Loss: 3.449366e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [00:57<02:44,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 13/50, Loss: 3.607361e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [01:01<02:37,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 14/50, Loss: 3.206359e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [01:05<02:32,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 15/50, Loss: 3.305714e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [01:10<02:30,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 16/50, Loss: 3.138003e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [01:14<02:24,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 17/50, Loss: 2.755678e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [01:19<02:23,  4.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 18/50, Loss: 2.931521e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [01:23<02:16,  4.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 19/50, Loss: 2.539128e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [01:27<02:10,  4.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 20/50, Loss: 2.719243e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [01:32<02:10,  4.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 21/50, Loss: 2.611569e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [01:36<02:02,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 22/50, Loss: 2.526925e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [01:41<01:57,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 23/50, Loss: 2.700911e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [01:45<01:55,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 24/50, Loss: 2.319525e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [01:50<01:49,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 25/50, Loss: 2.311766e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [01:54<01:44,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 26/50, Loss: 2.457607e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [01:58<01:41,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 27/50, Loss: 2.271584e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [02:03<01:34,  4.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 28/50, Loss: 2.065020e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [02:07<01:33,  4.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 29/50, Loss: 2.380247e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [02:12<01:28,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 30/50, Loss: 2.306196e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [02:16<01:21,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 31/50, Loss: 2.065462e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [02:20<01:20,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 32/50, Loss: 2.446923e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [02:25<01:14,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 33/50, Loss: 1.871632e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [02:29<01:08,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 34/50, Loss: 2.010579e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [02:34<01:06,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 35/50, Loss: 2.234357e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [02:38<01:01,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 36/50, Loss: 2.042022e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [02:43<00:58,  4.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 37/50, Loss: 1.961893e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [02:47<00:53,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 38/50, Loss: 2.075104e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [02:51<00:48,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 39/50, Loss: 2.066099e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [02:56<00:44,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 40/50, Loss: 1.844949e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [03:00<00:39,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 41/50, Loss: 1.953053e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [03:04<00:34,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 42/50, Loss: 2.052371e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [03:09<00:31,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 43/50, Loss: 1.881572e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [03:13<00:26,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 44/50, Loss: 1.977908e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [03:17<00:21,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 45/50, Loss: 1.883589e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [03:22<00:18,  4.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 46/50, Loss: 1.966740e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [03:26<00:13,  4.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 47/50, Loss: 1.740340e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [03:31<00:09,  4.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 48/50, Loss: 1.578012e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [03:35<00:04,  4.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 49/50, Loss: 2.131614e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:40<00:00,  4.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 50/50, Loss: 1.662974e-06, LR: 5.00e-06\n",
            "\n",
            "Final PSNR after pruning and fine-tuning: 64.7710\n",
            "Pruning resulted in PSNR 64.77 which is below target 70.00. Consider less aggressive pruning.\n",
            "Pruning with ratio 5% failed to meet PSNR target.\n",
            "\n",
            "Attempting to prune with ratio: 10%\n",
            "Original hidden neurons: 150, New hidden neurons: 135 (Pruning 15 neurons)\n",
            "New pruned model architecture:\n",
            "MyResidualSirenNet(\n",
            "  (net_layers): ModuleList(\n",
            "    (0): SineLayer(\n",
            "      (linear): Linear(in_features=3, out_features=135, bias=True)\n",
            "    )\n",
            "    (1-6): 6 x ResidualSineLayer(\n",
            "      (linear_1): Linear(in_features=135, out_features=135, bias=True)\n",
            "      (linear_2): Linear(in_features=135, out_features=135, bias=True)\n",
            "    )\n",
            "    (7): Linear(in_features=135, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "New pruned model parameters: 220996\n",
            "Parameter reduction: 18.92%\n",
            "\n",
            "--- Fine-tuning pruned model for 50 epochs ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/50 [00:04<03:49,  4.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 1/50, Loss: 2.129900e-03, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [00:08<03:32,  4.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 2/50, Loss: 1.433895e-04, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [00:12<03:19,  4.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 3/50, Loss: 6.866154e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [00:17<03:26,  4.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 4/50, Loss: 4.140246e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [00:21<03:17,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 5/50, Loss: 2.773339e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [00:26<03:07,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 6/50, Loss: 2.018537e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [00:30<03:12,  4.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 7/50, Loss: 1.537724e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [00:35<03:04,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 8/50, Loss: 1.239394e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [00:39<03:04,  4.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 9/50, Loss: 1.009844e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [00:44<02:55,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 10/50, Loss: 8.657114e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [00:48<02:46,  4.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 11/50, Loss: 7.458139e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [00:52<02:49,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 12/50, Loss: 7.122513e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [00:57<02:45,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 13/50, Loss: 6.087495e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [01:01<02:36,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 14/50, Loss: 5.810588e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [01:06<02:37,  4.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 15/50, Loss: 5.524375e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [01:10<02:28,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 16/50, Loss: 4.883150e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [01:14<02:24,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 17/50, Loss: 4.620194e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [01:19<02:23,  4.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 18/50, Loss: 4.448478e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [01:23<02:14,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 19/50, Loss: 4.106239e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [01:28<02:14,  4.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 20/50, Loss: 3.926535e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [01:32<02:07,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 21/50, Loss: 3.933116e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [01:36<02:01,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 22/50, Loss: 3.607954e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [01:41<02:01,  4.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 23/50, Loss: 3.371732e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [01:45<01:53,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 24/50, Loss: 3.300040e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [01:49<01:48,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 25/50, Loss: 3.426941e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [01:54<01:47,  4.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 26/50, Loss: 2.977622e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [01:58<01:40,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 27/50, Loss: 3.172591e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [02:03<01:36,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 28/50, Loss: 3.000057e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [02:07<01:33,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 29/50, Loss: 2.913674e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [02:12<01:27,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 30/50, Loss: 2.728144e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [02:16<01:25,  4.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 31/50, Loss: 3.010952e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [02:21<01:19,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 32/50, Loss: 2.700357e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [02:25<01:14,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 33/50, Loss: 2.662144e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [02:30<01:12,  4.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 34/50, Loss: 2.516997e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [02:34<01:06,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 35/50, Loss: 2.693982e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [02:38<01:00,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 36/50, Loss: 2.386119e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [02:43<00:58,  4.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 37/50, Loss: 2.658730e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [02:47<00:52,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 38/50, Loss: 2.520844e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [02:51<00:48,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 39/50, Loss: 2.593648e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [02:56<00:44,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 40/50, Loss: 2.095046e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [03:00<00:39,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 41/50, Loss: 2.455504e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [03:05<00:36,  4.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 42/50, Loss: 2.184788e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [03:09<00:30,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 43/50, Loss: 2.492927e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [03:14<00:26,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 44/50, Loss: 2.092695e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [03:18<00:22,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 45/50, Loss: 2.061685e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [03:22<00:17,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 46/50, Loss: 2.465066e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [03:27<00:12,  4.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 47/50, Loss: 1.844718e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [03:31<00:08,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 48/50, Loss: 2.062380e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [03:36<00:04,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 49/50, Loss: 2.150764e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:40<00:00,  4.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 50/50, Loss: 2.500575e-06, LR: 5.00e-06\n",
            "\n",
            "Final PSNR after pruning and fine-tuning: 64.2106\n",
            "Pruning resulted in PSNR 64.21 which is below target 70.00. Consider less aggressive pruning.\n",
            "Pruning with ratio 10% failed to meet PSNR target.\n",
            "\n",
            "Attempting to prune with ratio: 15%\n",
            "Original hidden neurons: 150, New hidden neurons: 128 (Pruning 22 neurons)\n",
            "New pruned model architecture:\n",
            "MyResidualSirenNet(\n",
            "  (net_layers): ModuleList(\n",
            "    (0): SineLayer(\n",
            "      (linear): Linear(in_features=3, out_features=128, bias=True)\n",
            "    )\n",
            "    (1-6): 6 x ResidualSineLayer(\n",
            "      (linear_1): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (linear_2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "    (7): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "New pruned model parameters: 198785\n",
            "Parameter reduction: 27.07%\n",
            "\n",
            "--- Fine-tuning pruned model for 50 epochs ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/50 [00:04<03:41,  4.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 1/50, Loss: 4.743458e-03, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [00:08<03:27,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 2/50, Loss: 2.972625e-04, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [00:13<03:31,  4.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 3/50, Loss: 1.348434e-04, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [00:17<03:20,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 4/50, Loss: 7.973118e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [00:21<03:14,  4.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 5/50, Loss: 5.260392e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [00:26<03:17,  4.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 6/50, Loss: 3.736731e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [00:30<03:07,  4.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 7/50, Loss: 2.780311e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [00:34<03:00,  4.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 8/50, Loss: 2.178840e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [00:39<03:03,  4.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 9/50, Loss: 1.758127e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [00:43<02:55,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 10/50, Loss: 1.453634e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [00:48<02:48,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 11/50, Loss: 1.250884e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [00:52<02:47,  4.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 12/50, Loss: 1.035362e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [00:56<02:38,  4.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 13/50, Loss: 9.573666e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [01:01<02:40,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 14/50, Loss: 8.473706e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [01:05<02:31,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 15/50, Loss: 7.588687e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [01:09<02:25,  4.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 16/50, Loss: 7.060492e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [01:14<02:24,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 17/50, Loss: 6.241232e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [01:18<02:16,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 18/50, Loss: 6.486605e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [01:22<02:11,  4.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 19/50, Loss: 5.453515e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [01:27<02:11,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 20/50, Loss: 5.332092e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [01:31<02:04,  4.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 21/50, Loss: 5.372430e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [01:35<01:58,  4.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 22/50, Loss: 4.540098e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [01:40<01:58,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 23/50, Loss: 4.620773e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [01:44<01:52,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 24/50, Loss: 4.226239e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [01:48<01:49,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 25/50, Loss: 4.051928e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [01:53<01:45,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 26/50, Loss: 4.277215e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [01:57<01:39,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 27/50, Loss: 3.695886e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [02:02<01:37,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 28/50, Loss: 3.865583e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [02:06<01:31,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 29/50, Loss: 3.666703e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [02:10<01:25,  4.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 30/50, Loss: 3.528795e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [02:15<01:24,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 31/50, Loss: 3.456940e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [02:19<01:18,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 32/50, Loss: 3.392956e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [02:23<01:13,  4.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 33/50, Loss: 3.205894e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [02:28<01:11,  4.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 34/50, Loss: 3.235185e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [02:32<01:04,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 35/50, Loss: 2.945706e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [02:36<01:01,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 36/50, Loss: 3.084108e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [02:41<00:57,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 37/50, Loss: 2.873545e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [02:45<00:52,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 38/50, Loss: 2.930316e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [02:50<00:49,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 39/50, Loss: 2.992334e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [02:54<00:44,  4.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 40/50, Loss: 2.824383e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [02:58<00:38,  4.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 41/50, Loss: 2.854398e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [03:03<00:35,  4.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 42/50, Loss: 2.463279e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [03:07<00:30,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 43/50, Loss: 2.944102e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [03:11<00:25,  4.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 44/50, Loss: 2.481153e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [03:16<00:22,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 45/50, Loss: 3.037924e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [03:20<00:17,  4.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 46/50, Loss: 2.333297e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [03:24<00:12,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 47/50, Loss: 2.340960e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [03:29<00:08,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 48/50, Loss: 2.517670e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [03:33<00:04,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 49/50, Loss: 2.268764e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:38<00:00,  4.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 50/50, Loss: 2.694685e-06, LR: 5.00e-06\n",
            "\n",
            "Final PSNR after pruning and fine-tuning: 63.2862\n",
            "Pruning resulted in PSNR 63.29 which is below target 70.00. Consider less aggressive pruning.\n",
            "Pruning with ratio 15% failed to meet PSNR target.\n",
            "\n",
            "Attempting to prune with ratio: 20%\n",
            "Original hidden neurons: 150, New hidden neurons: 120 (Pruning 30 neurons)\n",
            "New pruned model architecture:\n",
            "MyResidualSirenNet(\n",
            "  (net_layers): ModuleList(\n",
            "    (0): SineLayer(\n",
            "      (linear): Linear(in_features=3, out_features=120, bias=True)\n",
            "    )\n",
            "    (1-6): 6 x ResidualSineLayer(\n",
            "      (linear_1): Linear(in_features=120, out_features=120, bias=True)\n",
            "      (linear_2): Linear(in_features=120, out_features=120, bias=True)\n",
            "    )\n",
            "    (7): Linear(in_features=120, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "New pruned model parameters: 174841\n",
            "Parameter reduction: 35.85%\n",
            "\n",
            "--- Fine-tuning pruned model for 50 epochs ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/50 [00:04<03:38,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 1/50, Loss: 8.322123e-03, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [00:08<03:25,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 2/50, Loss: 5.541313e-04, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [00:13<03:29,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 3/50, Loss: 2.377366e-04, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [00:17<03:20,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 4/50, Loss: 1.370012e-04, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [00:21<03:10,  4.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 5/50, Loss: 8.900292e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [00:26<03:15,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 6/50, Loss: 6.246155e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [00:30<03:06,  4.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 7/50, Loss: 4.543712e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [00:34<02:57,  4.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 8/50, Loss: 3.514095e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [00:39<03:01,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 9/50, Loss: 2.791060e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [00:43<02:52,  4.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 10/50, Loss: 2.215433e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [00:47<02:47,  4.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 11/50, Loss: 1.830717e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [00:52<02:48,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 12/50, Loss: 1.576872e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [00:56<02:38,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 13/50, Loss: 1.359127e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [01:01<02:38,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 14/50, Loss: 1.213231e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [01:05<02:31,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 15/50, Loss: 1.083625e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [01:09<02:25,  4.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 16/50, Loss: 9.590687e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [01:14<02:26,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 17/50, Loss: 8.770665e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [01:18<02:17,  4.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 18/50, Loss: 8.099377e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [01:22<02:12,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 19/50, Loss: 7.626635e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [01:27<02:11,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 20/50, Loss: 7.197834e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [01:31<02:05,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 21/50, Loss: 6.469912e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [01:35<02:00,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 22/50, Loss: 5.938494e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [01:40<01:59,  4.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 23/50, Loss: 6.076214e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [01:44<01:51,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 24/50, Loss: 5.236338e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [01:48<01:48,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 25/50, Loss: 5.123618e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [01:53<01:46,  4.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 26/50, Loss: 5.250713e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [01:57<01:40,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 27/50, Loss: 4.552949e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [02:02<01:38,  4.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 28/50, Loss: 4.977564e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [02:06<01:32,  4.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 29/50, Loss: 4.194860e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [02:10<01:25,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 30/50, Loss: 3.892825e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [02:15<01:24,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 31/50, Loss: 4.112635e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [02:19<01:17,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 32/50, Loss: 4.277000e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [02:23<01:12,  4.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 33/50, Loss: 4.290713e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [02:28<01:11,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 34/50, Loss: 3.235033e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [02:32<01:04,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 35/50, Loss: 3.978602e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [02:36<01:00,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 36/50, Loss: 3.541448e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [02:41<00:57,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 37/50, Loss: 3.491353e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [02:45<00:51,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 38/50, Loss: 3.360698e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [02:49<00:48,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 39/50, Loss: 4.111211e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [02:54<00:43,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 40/50, Loss: 2.641154e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [02:58<00:38,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 41/50, Loss: 3.400831e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [03:03<00:35,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 42/50, Loss: 3.077840e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [03:07<00:30,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 43/50, Loss: 3.091249e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [03:11<00:25,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 44/50, Loss: 2.873210e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [03:16<00:22,  4.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 45/50, Loss: 2.839386e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [03:20<00:17,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 46/50, Loss: 2.930335e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [03:24<00:12,  4.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 47/50, Loss: 2.803921e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [03:29<00:08,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 48/50, Loss: 2.884320e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [03:33<00:04,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 49/50, Loss: 2.839782e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:37<00:00,  4.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 50/50, Loss: 2.510746e-06, LR: 5.00e-06\n",
            "\n",
            "Final PSNR after pruning and fine-tuning: 58.9026\n",
            "Pruning resulted in PSNR 58.90 which is below target 70.00. Consider less aggressive pruning.\n",
            "Pruning with ratio 20% failed to meet PSNR target.\n",
            "\n",
            "Attempting to prune with ratio: 25%\n",
            "Original hidden neurons: 150, New hidden neurons: 113 (Pruning 37 neurons)\n",
            "New pruned model architecture:\n",
            "MyResidualSirenNet(\n",
            "  (net_layers): ModuleList(\n",
            "    (0): SineLayer(\n",
            "      (linear): Linear(in_features=3, out_features=113, bias=True)\n",
            "    )\n",
            "    (1-6): 6 x ResidualSineLayer(\n",
            "      (linear_1): Linear(in_features=113, out_features=113, bias=True)\n",
            "      (linear_2): Linear(in_features=113, out_features=113, bias=True)\n",
            "    )\n",
            "    (7): Linear(in_features=113, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "New pruned model parameters: 155150\n",
            "Parameter reduction: 43.07%\n",
            "\n",
            "--- Fine-tuning pruned model for 50 epochs ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/50 [00:04<03:32,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 1/50, Loss: 1.374205e-02, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [00:08<03:23,  4.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 2/50, Loss: 9.010652e-04, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [00:13<03:27,  4.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 3/50, Loss: 3.742845e-04, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [00:17<03:18,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 4/50, Loss: 2.114252e-04, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [00:21<03:12,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 5/50, Loss: 1.365724e-04, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [00:26<03:16,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 6/50, Loss: 9.487096e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [00:30<03:07,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 7/50, Loss: 6.958646e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [00:34<03:00,  4.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 8/50, Loss: 5.285817e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [00:39<03:00,  4.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 9/50, Loss: 4.097822e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [00:43<02:53,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 10/50, Loss: 3.317684e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [00:47<02:49,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 11/50, Loss: 2.721959e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [00:52<02:49,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 12/50, Loss: 2.238441e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [00:56<02:39,  4.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 13/50, Loss: 1.913084e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [01:01<02:39,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 14/50, Loss: 1.650533e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [01:05<02:33,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 15/50, Loss: 1.475793e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [01:09<02:27,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 16/50, Loss: 1.292081e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [01:14<02:26,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 17/50, Loss: 1.164258e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [01:18<02:19,  4.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 18/50, Loss: 1.067324e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [01:22<02:11,  4.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 19/50, Loss: 9.961605e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [01:27<02:12,  4.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 20/50, Loss: 8.823583e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [01:31<02:06,  4.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 21/50, Loss: 8.100748e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [01:35<01:58,  4.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 22/50, Loss: 7.437170e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [01:40<01:59,  4.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 23/50, Loss: 7.427678e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [01:44<01:51,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 24/50, Loss: 7.185525e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [01:48<01:46,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 25/50, Loss: 6.217794e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [01:53<01:44,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 26/50, Loss: 6.377112e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [01:57<01:39,  4.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 27/50, Loss: 5.844263e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [02:01<01:36,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 28/50, Loss: 5.574440e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [02:06<01:31,  4.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 29/50, Loss: 5.167820e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [02:10<01:25,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 30/50, Loss: 5.302164e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [02:15<01:23,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 31/50, Loss: 5.275141e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [02:19<01:17,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 32/50, Loss: 4.332902e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [02:23<01:12,  4.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 33/50, Loss: 4.842717e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [02:27<01:09,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 34/50, Loss: 4.458826e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [02:32<01:04,  4.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 35/50, Loss: 4.406321e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [02:36<00:59,  4.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 36/50, Loss: 4.093950e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [02:41<00:57,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 37/50, Loss: 3.908816e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [02:45<00:51,  4.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 38/50, Loss: 3.838024e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [02:49<00:47,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 39/50, Loss: 4.181295e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [02:53<00:43,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 40/50, Loss: 3.516885e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [02:58<00:38,  4.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 41/50, Loss: 3.726863e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [03:02<00:35,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 42/50, Loss: 3.588116e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [03:07<00:30,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 43/50, Loss: 3.744768e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [03:11<00:25,  4.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 44/50, Loss: 3.253625e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [03:15<00:22,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 45/50, Loss: 3.799793e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [03:20<00:17,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 46/50, Loss: 3.379867e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [03:24<00:12,  4.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 47/50, Loss: 3.072940e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [03:28<00:08,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 48/50, Loss: 3.318409e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [03:33<00:04,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 49/50, Loss: 3.523133e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:37<00:00,  4.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 50/50, Loss: 2.761052e-06, LR: 5.00e-06\n",
            "\n",
            "Final PSNR after pruning and fine-tuning: 60.2095\n",
            "Pruning resulted in PSNR 60.21 which is below target 70.00. Consider less aggressive pruning.\n",
            "Pruning with ratio 25% failed to meet PSNR target.\n",
            "\n",
            "Attempting to prune with ratio: 30%\n",
            "Original hidden neurons: 150, New hidden neurons: 105 (Pruning 45 neurons)\n",
            "New pruned model architecture:\n",
            "MyResidualSirenNet(\n",
            "  (net_layers): ModuleList(\n",
            "    (0): SineLayer(\n",
            "      (linear): Linear(in_features=3, out_features=105, bias=True)\n",
            "    )\n",
            "    (1-6): 6 x ResidualSineLayer(\n",
            "      (linear_1): Linear(in_features=105, out_features=105, bias=True)\n",
            "      (linear_2): Linear(in_features=105, out_features=105, bias=True)\n",
            "    )\n",
            "    (7): Linear(in_features=105, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "New pruned model parameters: 134086\n",
            "Parameter reduction: 50.80%\n",
            "\n",
            "--- Fine-tuning pruned model for 50 epochs ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/50 [00:04<03:45,  4.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 1/50, Loss: 1.731919e-02, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [00:08<03:24,  4.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 2/50, Loss: 1.292639e-03, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [00:13<03:32,  4.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 3/50, Loss: 5.190694e-04, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [00:17<03:21,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 4/50, Loss: 2.834779e-04, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [00:21<03:11,  4.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 5/50, Loss: 1.790214e-04, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [00:26<03:15,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 6/50, Loss: 1.235366e-04, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [00:30<03:07,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 7/50, Loss: 8.973952e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [00:34<02:58,  4.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 8/50, Loss: 6.838622e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [00:39<03:01,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 9/50, Loss: 5.357636e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [00:43<02:54,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 10/50, Loss: 4.260109e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [00:47<02:46,  4.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 11/50, Loss: 3.461635e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [00:52<02:46,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 12/50, Loss: 2.872712e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [00:56<02:39,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 13/50, Loss: 2.417988e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [01:01<02:38,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 14/50, Loss: 2.093781e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [01:05<02:32,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 15/50, Loss: 1.815920e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [01:09<02:26,  4.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 16/50, Loss: 1.596159e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [01:14<02:27,  4.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 17/50, Loss: 1.428013e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [01:18<02:18,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 18/50, Loss: 1.300670e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [01:22<02:12,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 19/50, Loss: 1.138115e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [01:27<02:13,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 20/50, Loss: 1.065321e-05, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [01:31<02:06,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 21/50, Loss: 9.630976e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [01:35<01:59,  4.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 22/50, Loss: 9.260865e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [01:40<01:57,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 23/50, Loss: 8.094246e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [01:44<01:51,  4.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 24/50, Loss: 7.569561e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [01:48<01:46,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 25/50, Loss: 7.416805e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [01:53<01:45,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 26/50, Loss: 6.764941e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [01:57<01:38,  4.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 27/50, Loss: 6.718358e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [02:01<01:36,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 28/50, Loss: 6.304962e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [02:06<01:30,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 29/50, Loss: 5.973587e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [02:10<01:25,  4.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 30/50, Loss: 5.968398e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [02:15<01:24,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 31/50, Loss: 5.237240e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [02:19<01:18,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 32/50, Loss: 4.996921e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [02:23<01:13,  4.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 33/50, Loss: 5.659419e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [02:28<01:11,  4.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 34/50, Loss: 4.892933e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [02:32<01:05,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 35/50, Loss: 4.439219e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [02:36<01:00,  4.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 36/50, Loss: 4.536618e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [02:41<00:57,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 37/50, Loss: 4.349060e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [02:45<00:52,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 38/50, Loss: 4.071860e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [02:49<00:48,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 39/50, Loss: 4.162077e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [02:54<00:43,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 40/50, Loss: 4.229992e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [02:58<00:38,  4.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 41/50, Loss: 3.703080e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [03:03<00:35,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 42/50, Loss: 3.983577e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [03:07<00:30,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 43/50, Loss: 3.547116e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [03:11<00:26,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 44/50, Loss: 3.669023e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [03:16<00:22,  4.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 45/50, Loss: 3.526390e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [03:20<00:17,  4.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 46/50, Loss: 3.517273e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [03:24<00:12,  4.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 47/50, Loss: 3.502218e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [03:29<00:08,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 48/50, Loss: 3.425987e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [03:33<00:04,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 49/50, Loss: 3.119778e-06, LR: 5.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [03:38<00:00,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune Epoch 50/50, Loss: 3.597569e-06, LR: 5.00e-06\n",
            "\n",
            "Final PSNR after pruning and fine-tuning: 62.0631\n",
            "Pruning resulted in PSNR 62.06 which is below target 70.00. Consider less aggressive pruning.\n",
            "Pruning with ratio 30% failed to meet PSNR target.\n",
            "\n",
            "--- Pruning Process Complete ---\n",
            "No pruned model found that met the PSNR target.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#stds predction and trainingn"
      ],
      "metadata": {
        "id": "9WCxaBAVSA5J"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f2yaZStMR9Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the DataLoader\n",
        "train_dataloader_std= DataLoader(\n",
        "    TensorDataset(torch_coords, torch_stds),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    pin_memory=True,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "# Model configuration\n",
        "obj = {\n",
        "    'total_vars': 1,\n",
        "    'dim': n_dim,\n",
        "    'n_neurons': n_neurons,\n",
        "    'n_layers': n_layers\n",
        "}\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model_std = MyResidualSirenNet(obj).to(device)\n",
        "print(model_mean)\n",
        "\n",
        "optimizer_std = optim.Adam(model_mean.parameters(), lr=LR, betas=(0.9, 0.999))\n",
        "print(optimizer)\n",
        "\n",
        "criterion_std = nn.MSELoss()\n",
        "print(criterion_std)\n",
        "\n",
        "# Training configuration summary\n",
        "print('\\nLearning Rate:', LR)\n",
        "print('Max Epochs:', MAX_EPOCH)\n",
        "print('Batch Size:', BATCH_SIZE)\n",
        "print('Number of Hidden Layers:', obj['n_layers'] - 2)\n",
        "print('Number of Neurons per Layer:', obj['n_neurons'])\n",
        "\n",
        "if decay:\n",
        "    print('Decay Rate:', decay_rate)\n",
        "    if decay_at_equal_interval:\n",
        "        print(f'Rate decays every {decay_interval} epochs.')\n",
        "    else:\n",
        "        print('Rate decays when the current epoch loss is greater than the previous epoch loss.')\n",
        "else:\n",
        "    print('No decay!')\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v8tpivej35Y",
        "outputId": "d67c1da5-09bb-48e6-c939-95e800dcf67d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyResidualSirenNet(\n",
            "  (net_layers): ModuleList(\n",
            "    (0): SineLayer(\n",
            "      (linear): Linear(in_features=3, out_features=150, bias=True)\n",
            "    )\n",
            "    (1-6): 6 x ResidualSineLayer(\n",
            "      (linear_1): Linear(in_features=150, out_features=150, bias=True)\n",
            "      (linear_2): Linear(in_features=150, out_features=150, bias=True)\n",
            "    )\n",
            "    (7): Linear(in_features=150, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 5e-05\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "MSELoss()\n",
            "\n",
            "Learning Rate: 5e-05\n",
            "Max Epochs: 200\n",
            "Batch Size: 512\n",
            "Number of Hidden Layers: 6\n",
            "Number of Neurons per Layer: 150\n",
            "Decay Rate: 0.8\n",
            "Rate decays every 15 epochs.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list = []\n",
        "best_epoch = -1\n",
        "best_loss = 1e8\n",
        "best_model=\"\"\n",
        "from tqdm import tqdm\n",
        "# Ensure the output path exists\n",
        "if not os.path.exists(outpath):\n",
        "    os.makedirs(outpath)\n",
        "\n",
        "# Training loop\n",
        "for epoch in tqdm(range(MAX_EPOCH)):\n",
        "    model_std.train()\n",
        "    temp_loss_list = []\n",
        "    start = time.time()\n",
        "\n",
        "    # Batch-by-batch training\n",
        "    for X_train, y_train in train_dataloader_std:\n",
        "        X_train = X_train.type(torch.float32).to(device)\n",
        "        y_train = y_train.type(torch.float32).to(device)\n",
        "\n",
        "        if univariate:\n",
        "            y_train = y_train.squeeze()\n",
        "\n",
        "        optimizer_std.zero_grad()\n",
        "        predictions = model_mean(X_train)\n",
        "        predictions = predictions.squeeze()\n",
        "        loss = criterion_std(predictions, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track batch loss\n",
        "        temp_loss_list.append(loss.detach().cpu().numpy())\n",
        "\n",
        "    # Calculate epoch loss\n",
        "    epoch_loss = np.average(temp_loss_list)\n",
        "\n",
        "    # Learning rate decay\n",
        "    if decay:\n",
        "        if decay_at_equal_interval:\n",
        "            if epoch >= decay_interval and epoch % decay_interval == 0:\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] *= decay_rate\n",
        "        # else:\n",
        "        #     if epoch > 0 and epoch_loss > train_loss_list[-1]:\n",
        "        #         for param_group in optimizer.param_groups:\n",
        "        #             param_group['lr'] *= decay_rate\n",
        "        if epoch > 0 and epoch_loss > train_loss_list[-1]:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] *= decay_rate\n",
        "\n",
        "    # Track losses and best model\n",
        "    train_loss_list.append(epoch_loss)\n",
        "    if epoch_loss < best_loss:\n",
        "        best_loss = epoch_loss\n",
        "        best_epoch = epoch+1\n",
        "        if(best_model==0):\n",
        "            best_model=model_mean.state_dict()\n",
        "        else:\n",
        "            best_model=model_mean.state_dict()\n",
        "\n",
        "    end = time.time()\n",
        "    print(\n",
        "        f\"Epoch: {epoch + 1}/{MAX_EPOCH} | Train Loss: {train_loss_list[-1]} | \"\n",
        "        f\"Time: {round(end - start, 2)}s ({device}) | LR: {optimizer.param_groups[0]['lr']}\"\n",
        "    )\n",
        "\n",
        "    # Save model at intervals\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        model_name = (\n",
        "            f'train_{dataset_name}_{epoch + 1}ep_{n_layers - 2}rb_{n_neurons}n_'\n",
        "            f'{BATCH_SIZE}bs_{LR}lr_{decay}decay_{decay_rate}dr_'\n",
        "            f'{\"decayingAtInterval\" + str(decay_interval)+\"std\" if decay_at_equal_interval else \"decayingWhenLossIncr\"}'\n",
        "        )\n",
        "        torch.save(\n",
        "            {\"epoch\": epoch + 1, \"model_state_dict\": model_mean.state_dict()},\n",
        "            os.path.join(outpath, f'{model_name}_std.pth')\n",
        "        )\n",
        "\n",
        "# Final summary\n",
        "print('\\nEpoch with Least Loss:', best_epoch, '| Loss:', best_loss, '\\n')\n",
        "\n",
        "# Save the final model\n",
        "model_name = f'siren_compressor'\n",
        "torch.save(\n",
        "    {\"epoch\": MAX_EPOCH, \"model_state_dict\": model_mean.state_dict()},\n",
        "    os.path.join(outpath, f'{model_name}_std.pth')\n",
        ")\n",
        "torch.save(\n",
        "    {\"epoch\": best_epoch, \"model_state_dict\": best_model},\n",
        "    os.path.join(outpath, f'{best_epoch}_std.pth')\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2rsfR4rkEIO",
        "outputId": "d9d827e2-0d86-4660-d6b7-11e12c021c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "  0%|          | 1/200 [00:07<24:17,  7.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/200 | Train Loss: 0.009194845333695412 | Time: 7.32s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 2/200 [00:13<22:01,  6.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2/200 | Train Loss: 0.0028720130212605 | Time: 6.22s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 3/200 [00:20<22:06,  6.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3/200 | Train Loss: 0.002567930379882455 | Time: 6.81s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 4/200 [00:26<20:48,  6.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4/200 | Train Loss: 0.0023847653064876795 | Time: 5.8s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▎         | 5/200 [00:32<21:11,  6.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5/200 | Train Loss: 0.002256781095638871 | Time: 6.8s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 6/200 [00:38<20:15,  6.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6/200 | Train Loss: 0.002154187997803092 | Time: 5.76s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 7/200 [00:45<20:40,  6.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7/200 | Train Loss: 0.002080448204651475 | Time: 6.76s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 8/200 [00:51<19:51,  6.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8/200 | Train Loss: 0.002045626752078533 | Time: 5.74s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 9/200 [00:59<22:09,  6.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9/200 | Train Loss: 0.001972614787518978 | Time: 8.61s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 10/200 [01:05<20:40,  6.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10/200 | Train Loss: 0.0019249295582994819 | Time: 5.56s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 11/200 [01:12<20:44,  6.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11/200 | Train Loss: 0.0018737944774329662 | Time: 6.71s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 12/200 [01:17<19:43,  6.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12/200 | Train Loss: 0.0018399524269625545 | Time: 5.63s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 13/200 [01:24<20:08,  6.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13/200 | Train Loss: 0.001806402113288641 | Time: 6.84s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 14/200 [01:30<19:17,  6.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 14/200 | Train Loss: 0.0017818710766732693 | Time: 5.68s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 15/200 [01:36<19:14,  6.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 15/200 | Train Loss: 0.0017433357425034046 | Time: 6.28s (cuda) | LR: 5e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 16/200 [01:42<18:51,  6.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 16/200 | Train Loss: 0.0016952555160969496 | Time: 5.93s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 17/200 [01:48<19:01,  6.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 17/200 | Train Loss: 0.0014271930558606982 | Time: 6.44s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 18/200 [01:56<19:50,  6.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 18/200 | Train Loss: 0.001263576908968389 | Time: 7.23s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 19/200 [02:02<19:27,  6.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 19/200 | Train Loss: 0.0012481918092817068 | Time: 6.24s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 20/200 [02:08<19:05,  6.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20/200 | Train Loss: 0.0012059148866683245 | Time: 6.16s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 21/200 [02:14<18:41,  6.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 21/200 | Train Loss: 0.0011958950199186802 | Time: 6.03s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 22/200 [02:20<18:38,  6.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 22/200 | Train Loss: 0.001171864802017808 | Time: 6.32s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 23/200 [02:27<18:26,  6.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 23/200 | Train Loss: 0.0011311592534184456 | Time: 6.18s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 24/200 [02:33<18:28,  6.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 24/200 | Train Loss: 0.001101246802136302 | Time: 6.41s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 25/200 [02:39<17:51,  6.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25/200 | Train Loss: 0.0010757476557046175 | Time: 5.71s (cuda) | LR: 4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 26/200 [02:45<18:19,  6.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 26/200 | Train Loss: 0.0010798744624480605 | Time: 6.77s (cuda) | LR: 3.2000000000000005e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 27/200 [02:51<17:48,  6.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 27/200 | Train Loss: 0.0008635143749415874 | Time: 5.84s (cuda) | LR: 3.2000000000000005e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 28/200 [02:58<18:27,  6.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 28/200 | Train Loss: 0.0007373134139925241 | Time: 7.04s (cuda) | LR: 3.2000000000000005e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 29/200 [03:04<17:34,  6.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 29/200 | Train Loss: 0.0007226869929581881 | Time: 5.54s (cuda) | LR: 3.2000000000000005e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 30/200 [03:11<18:07,  6.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 30/200 | Train Loss: 0.0007169503951445222 | Time: 6.92s (cuda) | LR: 3.2000000000000005e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 31/200 [03:17<17:24,  6.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 31/200 | Train Loss: 0.0007171737961471081 | Time: 5.68s (cuda) | LR: 2.0480000000000007e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 32/200 [03:23<17:49,  6.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 32/200 | Train Loss: 0.0005033459165133536 | Time: 6.79s (cuda) | LR: 2.0480000000000007e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▋        | 33/200 [03:29<17:11,  6.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 33/200 | Train Loss: 0.00037924444768577814 | Time: 5.75s (cuda) | LR: 2.0480000000000007e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 34/200 [03:36<18:00,  6.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 34/200 | Train Loss: 0.0003605893871281296 | Time: 7.27s (cuda) | LR: 2.0480000000000007e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 35/200 [03:43<17:48,  6.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 35/200 | Train Loss: 0.0003632013394962996 | Time: 6.41s (cuda) | LR: 1.6384000000000008e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 36/200 [03:50<18:03,  6.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 36/200 | Train Loss: 0.0003051134408451617 | Time: 6.9s (cuda) | LR: 1.6384000000000008e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 37/200 [03:55<17:14,  6.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 37/200 | Train Loss: 0.00026360899209976196 | Time: 5.75s (cuda) | LR: 1.6384000000000008e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 38/200 [04:02<17:28,  6.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 38/200 | Train Loss: 0.00025372434174641967 | Time: 6.75s (cuda) | LR: 1.6384000000000008e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 39/200 [04:08<16:39,  6.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 39/200 | Train Loss: 0.0002518624532967806 | Time: 5.59s (cuda) | LR: 1.6384000000000008e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 40/200 [04:15<17:04,  6.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 40/200 | Train Loss: 0.0002549409109633416 | Time: 6.86s (cuda) | LR: 1.3107200000000007e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 41/200 [04:20<16:22,  6.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 41/200 | Train Loss: 0.0002009312156587839 | Time: 5.66s (cuda) | LR: 1.3107200000000007e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 42/200 [04:27<16:56,  6.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 42/200 | Train Loss: 0.00017993434448726475 | Time: 7.02s (cuda) | LR: 1.3107200000000007e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 43/200 [04:33<16:17,  6.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 43/200 | Train Loss: 0.00017502898117527366 | Time: 5.73s (cuda) | LR: 1.3107200000000007e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 44/200 [04:40<16:46,  6.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 44/200 | Train Loss: 0.00017678514996077865 | Time: 6.98s (cuda) | LR: 1.0485760000000006e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▎       | 45/200 [04:46<16:08,  6.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 45/200 | Train Loss: 0.00013968873827252537 | Time: 5.77s (cuda) | LR: 1.0485760000000006e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 46/200 [04:53<16:26,  6.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 46/200 | Train Loss: 0.00012119787425035611 | Time: 6.77s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 47/200 [04:58<15:51,  6.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 47/200 | Train Loss: 0.00010115245095221326 | Time: 5.78s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 48/200 [05:05<16:17,  6.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 48/200 | Train Loss: 9.331183537142351e-05 | Time: 6.93s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 49/200 [05:11<15:37,  6.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 49/200 | Train Loss: 9.314632916357368e-05 | Time: 5.69s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 50/200 [05:18<15:48,  6.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 50/200 | Train Loss: 9.266989945899695e-05 | Time: 6.58s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 51/200 [05:23<15:21,  6.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 51/200 | Train Loss: 9.248766582459211e-05 | Time: 5.85s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 52/200 [05:30<15:21,  6.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 52/200 | Train Loss: 9.111529652727768e-05 | Time: 6.33s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 53/200 [05:36<15:14,  6.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 53/200 | Train Loss: 8.882123074727133e-05 | Time: 6.2s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 54/200 [05:42<14:53,  6.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 54/200 | Train Loss: 8.706046355655417e-05 | Time: 5.88s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 55/200 [05:48<15:01,  6.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 55/200 | Train Loss: 8.519968832843006e-05 | Time: 6.45s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 56/200 [05:54<14:29,  6.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 56/200 | Train Loss: 8.34684178698808e-05 | Time: 5.63s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 57/200 [06:01<14:58,  6.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 57/200 | Train Loss: 8.186904597096145e-05 | Time: 6.84s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 58/200 [06:06<14:21,  6.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 58/200 | Train Loss: 8.040765533223748e-05 | Time: 5.55s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 59/200 [06:13<14:39,  6.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 59/200 | Train Loss: 7.892186113167554e-05 | Time: 6.65s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 60/200 [06:18<14:03,  6.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 60/200 | Train Loss: 7.838320743758231e-05 | Time: 5.51s (cuda) | LR: 8.388608000000005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 61/200 [06:25<14:26,  6.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 61/200 | Train Loss: 7.728775381110609e-05 | Time: 6.73s (cuda) | LR: 6.7108864000000044e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 62/200 [06:31<13:59,  6.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 62/200 | Train Loss: 6.098553421907127e-05 | Time: 5.74s (cuda) | LR: 6.7108864000000044e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 63/200 [06:38<14:18,  6.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 63/200 | Train Loss: 5.2002393204020336e-05 | Time: 6.69s (cuda) | LR: 6.7108864000000044e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 64/200 [06:43<13:38,  6.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 64/200 | Train Loss: 5.253678682493046e-05 | Time: 5.44s (cuda) | LR: 5.368709120000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▎      | 65/200 [06:50<13:55,  6.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 65/200 | Train Loss: 4.456890019355342e-05 | Time: 6.58s (cuda) | LR: 5.368709120000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 66/200 [06:55<13:24,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 66/200 | Train Loss: 4.008863470517099e-05 | Time: 5.57s (cuda) | LR: 5.368709120000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▎      | 67/200 [07:02<13:54,  6.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 67/200 | Train Loss: 4.040004932903685e-05 | Time: 6.9s (cuda) | LR: 4.294967296000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 68/200 [07:08<13:16,  6.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 68/200 | Train Loss: 3.446186019573361e-05 | Time: 5.48s (cuda) | LR: 4.294967296000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 69/200 [07:14<13:19,  6.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 69/200 | Train Loss: 3.1503106583841145e-05 | Time: 6.27s (cuda) | LR: 4.294967296000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 70/200 [07:20<13:00,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 70/200 | Train Loss: 3.1692306947661564e-05 | Time: 5.76s (cuda) | LR: 3.4359738368000033e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 71/200 [07:26<12:51,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 71/200 | Train Loss: 2.7369529561838135e-05 | Time: 5.94s (cuda) | LR: 3.4359738368000033e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 72/200 [07:32<12:58,  6.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 72/200 | Train Loss: 2.5489687686786056e-05 | Time: 6.31s (cuda) | LR: 3.4359738368000033e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▋      | 73/200 [07:38<12:41,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 73/200 | Train Loss: 2.529530320316553e-05 | Time: 5.79s (cuda) | LR: 3.4359738368000033e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 74/200 [07:44<12:56,  6.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 74/200 | Train Loss: 2.5374876713613048e-05 | Time: 6.54s (cuda) | LR: 2.7487790694400027e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 75/200 [07:50<12:27,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 75/200 | Train Loss: 2.1933414245722815e-05 | Time: 5.54s (cuda) | LR: 2.7487790694400027e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 76/200 [07:56<12:48,  6.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 76/200 | Train Loss: 2.046031477220822e-05 | Time: 6.7s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 77/200 [08:02<12:22,  6.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 77/200 | Train Loss: 1.8081935195368715e-05 | Time: 5.66s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 78/200 [08:09<12:36,  6.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 78/200 | Train Loss: 1.74171946127899e-05 | Time: 6.6s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 79/200 [08:14<12:05,  5.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 79/200 | Train Loss: 1.7379083146806806e-05 | Time: 5.5s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 80/200 [08:21<12:23,  6.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 80/200 | Train Loss: 1.726246773614548e-05 | Time: 6.66s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 81/200 [08:26<11:53,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 81/200 | Train Loss: 1.7056248907465488e-05 | Time: 5.53s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 82/200 [08:33<12:11,  6.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 82/200 | Train Loss: 1.6797839634818956e-05 | Time: 6.67s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 83/200 [08:39<11:40,  5.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 83/200 | Train Loss: 1.6604648408247158e-05 | Time: 5.49s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 84/200 [08:45<11:56,  6.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 84/200 | Train Loss: 1.6378024156438187e-05 | Time: 6.61s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▎     | 85/200 [08:51<11:24,  5.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 85/200 | Train Loss: 1.6081434296211228e-05 | Time: 5.44s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 86/200 [08:57<11:26,  6.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 86/200 | Train Loss: 1.582074946782086e-05 | Time: 6.18s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▎     | 87/200 [09:03<11:16,  5.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 87/200 | Train Loss: 1.560833516123239e-05 | Time: 5.9s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 88/200 [09:08<10:54,  5.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 88/200 | Train Loss: 1.5363335478468798e-05 | Time: 5.51s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 89/200 [09:15<11:03,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 89/200 | Train Loss: 1.5172907296800986e-05 | Time: 6.29s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 90/200 [09:20<10:36,  5.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 90/200 | Train Loss: 1.4965848095016554e-05 | Time: 5.32s (cuda) | LR: 2.1990232555520023e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 91/200 [09:26<10:52,  5.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 91/200 | Train Loss: 1.4686915164929815e-05 | Time: 6.47s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 92/200 [09:32<10:29,  5.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 92/200 | Train Loss: 1.2878527741122525e-05 | Time: 5.47s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▋     | 93/200 [09:38<10:40,  5.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 93/200 | Train Loss: 1.2308186342124827e-05 | Time: 6.35s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 94/200 [09:43<10:13,  5.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 94/200 | Train Loss: 1.2218693882459775e-05 | Time: 5.31s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 95/200 [09:50<10:28,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 95/200 | Train Loss: 1.2180093108327128e-05 | Time: 6.44s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 96/200 [09:55<10:01,  5.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 96/200 | Train Loss: 1.2073998732375912e-05 | Time: 5.32s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 97/200 [10:02<10:11,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 97/200 | Train Loss: 1.192901618196629e-05 | Time: 6.29s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 98/200 [10:07<09:54,  5.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 98/200 | Train Loss: 1.1789223208324984e-05 | Time: 5.57s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|████▉     | 99/200 [10:12<09:31,  5.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 99/200 | Train Loss: 1.164587683888385e-05 | Time: 5.25s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 100/200 [10:19<09:46,  5.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100/200 | Train Loss: 1.1499580068630166e-05 | Time: 6.36s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 101/200 [10:24<09:21,  5.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 101/200 | Train Loss: 1.1378539056750014e-05 | Time: 5.22s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 102/200 [10:31<09:42,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 102/200 | Train Loss: 1.1186569281562697e-05 | Time: 6.56s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 103/200 [10:36<09:19,  5.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 103/200 | Train Loss: 1.1100564734078944e-05 | Time: 5.35s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 104/200 [10:42<09:33,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 104/200 | Train Loss: 1.0982342246279586e-05 | Time: 6.48s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▎    | 105/200 [10:48<09:09,  5.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 105/200 | Train Loss: 1.0844923053809907e-05 | Time: 5.34s (cuda) | LR: 1.7592186044416019e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 106/200 [10:54<09:26,  6.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 106/200 | Train Loss: 1.0717850273067597e-05 | Time: 6.58s (cuda) | LR: 1.4073748835532816e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▎    | 107/200 [11:00<09:02,  5.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 107/200 | Train Loss: 9.453588063479401e-06 | Time: 5.39s (cuda) | LR: 1.4073748835532816e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 108/200 [11:06<09:13,  6.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 108/200 | Train Loss: 9.031826266436838e-06 | Time: 6.43s (cuda) | LR: 1.4073748835532816e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 109/200 [11:12<08:57,  5.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 109/200 | Train Loss: 9.052893801708706e-06 | Time: 5.64s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 110/200 [11:17<08:44,  5.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 110/200 | Train Loss: 8.17463660496287e-06 | Time: 5.63s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 111/200 [11:24<08:46,  5.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 111/200 | Train Loss: 7.946956429805141e-06 | Time: 6.14s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 112/200 [11:29<08:26,  5.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 112/200 | Train Loss: 7.934586392366327e-06 | Time: 5.37s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▋    | 113/200 [11:35<08:42,  6.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 113/200 | Train Loss: 7.896715942479204e-06 | Time: 6.6s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 114/200 [11:41<08:18,  5.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 114/200 | Train Loss: 7.831221410015132e-06 | Time: 5.29s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▊    | 115/200 [11:47<08:28,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 115/200 | Train Loss: 7.776048732921481e-06 | Time: 6.42s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 116/200 [11:52<08:05,  5.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 116/200 | Train Loss: 7.713934792263899e-06 | Time: 5.3s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 117/200 [11:59<08:16,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 117/200 | Train Loss: 7.623189958394505e-06 | Time: 6.45s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 118/200 [12:04<07:56,  5.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 118/200 | Train Loss: 7.567256943730172e-06 | Time: 5.39s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 119/200 [12:11<08:00,  5.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 119/200 | Train Loss: 7.487641596526373e-06 | Time: 6.21s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 120/200 [12:16<07:44,  5.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 120/200 | Train Loss: 7.426900538121117e-06 | Time: 5.51s (cuda) | LR: 1.1258999068426254e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 121/200 [12:22<07:35,  5.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 121/200 | Train Loss: 7.334077963605523e-06 | Time: 5.69s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 122/200 [12:28<07:33,  5.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 122/200 | Train Loss: 6.676857537968317e-06 | Time: 5.9s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 123/200 [12:33<07:18,  5.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 123/200 | Train Loss: 6.523503088828875e-06 | Time: 5.44s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 124/200 [12:39<07:28,  5.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 124/200 | Train Loss: 6.481851869466482e-06 | Time: 6.35s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▎   | 125/200 [12:45<07:12,  5.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 125/200 | Train Loss: 6.4576524891890585e-06 | Time: 5.47s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 126/200 [12:51<07:20,  5.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 126/200 | Train Loss: 6.410508831322659e-06 | Time: 6.4s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▎   | 127/200 [12:57<07:00,  5.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 127/200 | Train Loss: 6.364515229506651e-06 | Time: 5.3s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 128/200 [13:03<07:11,  5.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 128/200 | Train Loss: 6.3165371102513745e-06 | Time: 6.54s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 129/200 [13:09<06:52,  5.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 129/200 | Train Loss: 6.265262072702171e-06 | Time: 5.39s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 130/200 [13:15<07:01,  6.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 130/200 | Train Loss: 6.213703272806015e-06 | Time: 6.48s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 131/200 [13:20<06:41,  5.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 131/200 | Train Loss: 6.170053893583827e-06 | Time: 5.35s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 132/200 [13:26<06:30,  5.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 132/200 | Train Loss: 6.105942702561151e-06 | Time: 5.58s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▋   | 133/200 [13:32<06:29,  5.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 133/200 | Train Loss: 6.05967034061905e-06 | Time: 5.98s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 134/200 [13:37<06:17,  5.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 134/200 | Train Loss: 6.016886345605599e-06 | Time: 5.5s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 135/200 [13:44<06:29,  5.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 135/200 | Train Loss: 5.964640877209604e-06 | Time: 6.6s (cuda) | LR: 9.007199254741003e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 136/200 [13:49<06:10,  5.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 136/200 | Train Loss: 5.914996563660679e-06 | Time: 5.31s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 137/200 [13:56<06:13,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 137/200 | Train Loss: 5.435798811959103e-06 | Time: 6.28s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 138/200 [14:01<05:54,  5.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 138/200 | Train Loss: 5.33256343260291e-06 | Time: 5.23s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 139/200 [14:07<06:04,  5.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 139/200 | Train Loss: 5.308048457663972e-06 | Time: 6.54s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 140/200 [14:13<05:46,  5.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 140/200 | Train Loss: 5.2884201977576595e-06 | Time: 5.31s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 141/200 [14:19<05:51,  5.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 141/200 | Train Loss: 5.255395535641583e-06 | Time: 6.39s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 142/200 [14:24<05:33,  5.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 142/200 | Train Loss: 5.218447768129408e-06 | Time: 5.25s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 143/200 [14:30<05:23,  5.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 143/200 | Train Loss: 5.190965566725936e-06 | Time: 5.51s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 144/200 [14:36<05:27,  5.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 144/200 | Train Loss: 5.1592123782029375e-06 | Time: 6.27s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▎  | 145/200 [14:42<05:13,  5.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 145/200 | Train Loss: 5.115273779665586e-06 | Time: 5.32s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 146/200 [14:48<05:18,  5.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 146/200 | Train Loss: 5.0816015573218465e-06 | Time: 6.36s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 147/200 [14:53<05:03,  5.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 147/200 | Train Loss: 5.04785384691786e-06 | Time: 5.35s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 148/200 [15:00<05:11,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 148/200 | Train Loss: 5.012972906115465e-06 | Time: 6.62s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 149/200 [15:05<04:57,  5.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 149/200 | Train Loss: 4.97570181323681e-06 | Time: 5.45s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 150/200 [15:12<04:59,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 150/200 | Train Loss: 4.943174644722603e-06 | Time: 6.37s (cuda) | LR: 7.205759403792803e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 151/200 [15:17<04:43,  5.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 151/200 | Train Loss: 4.9192340156878345e-06 | Time: 5.32s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 152/200 [15:23<04:46,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 152/200 | Train Loss: 4.558860382530838e-06 | Time: 6.4s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 153/200 [15:29<04:30,  5.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 153/200 | Train Loss: 4.487210389925167e-06 | Time: 5.21s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 154/200 [15:34<04:25,  5.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 154/200 | Train Loss: 4.468001861823723e-06 | Time: 5.85s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 155/200 [15:40<04:21,  5.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 155/200 | Train Loss: 4.454514964891132e-06 | Time: 5.9s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 156/200 [15:46<04:07,  5.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 156/200 | Train Loss: 4.433964022609871e-06 | Time: 5.21s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 157/200 [15:52<04:12,  5.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 157/200 | Train Loss: 4.40819621871924e-06 | Time: 6.43s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 158/200 [15:57<03:58,  5.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 158/200 | Train Loss: 4.3815161916427314e-06 | Time: 5.23s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 159/200 [16:04<04:00,  5.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 159/200 | Train Loss: 4.356323643150972e-06 | Time: 6.31s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 160/200 [16:09<03:49,  5.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 160/200 | Train Loss: 4.336805432103574e-06 | Time: 5.45s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 161/200 [16:15<03:51,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 161/200 | Train Loss: 4.311411885282723e-06 | Time: 6.38s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 162/200 [16:21<03:38,  5.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 162/200 | Train Loss: 4.282331701688236e-06 | Time: 5.27s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 163/200 [16:27<03:33,  5.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 163/200 | Train Loss: 4.259857632860076e-06 | Time: 5.88s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 164/200 [16:32<03:27,  5.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 164/200 | Train Loss: 4.2304391172365285e-06 | Time: 5.7s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▎ | 165/200 [16:38<03:17,  5.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 165/200 | Train Loss: 4.2101564758922905e-06 | Time: 5.38s (cuda) | LR: 5.764607523034243e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 166/200 [16:44<03:18,  5.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 166/200 | Train Loss: 4.18280342273647e-06 | Time: 6.32s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 167/200 [16:49<03:07,  5.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 167/200 | Train Loss: 3.91786488762591e-06 | Time: 5.31s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 168/200 [16:56<03:09,  5.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 168/200 | Train Loss: 3.8706775740138255e-06 | Time: 6.47s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 169/200 [17:01<02:56,  5.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 169/200 | Train Loss: 3.86031251764507e-06 | Time: 5.2s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 170/200 [17:07<02:57,  5.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 170/200 | Train Loss: 3.844495950033888e-06 | Time: 6.45s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 171/200 [17:13<02:45,  5.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 171/200 | Train Loss: 3.834471954178298e-06 | Time: 5.21s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 172/200 [17:19<02:45,  5.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 172/200 | Train Loss: 3.8144112295412924e-06 | Time: 6.4s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 173/200 [17:24<02:33,  5.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 173/200 | Train Loss: 3.792488314502407e-06 | Time: 5.18s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 174/200 [17:30<02:27,  5.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 174/200 | Train Loss: 3.7766772038594354e-06 | Time: 5.62s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 175/200 [17:36<02:24,  5.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 175/200 | Train Loss: 3.755343868760974e-06 | Time: 5.99s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 176/200 [17:41<02:15,  5.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 176/200 | Train Loss: 3.743026354641188e-06 | Time: 5.4s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 177/200 [17:47<02:14,  5.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 177/200 | Train Loss: 3.7256208997860085e-06 | Time: 6.25s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 178/200 [17:53<02:05,  5.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 178/200 | Train Loss: 3.703330094140256e-06 | Time: 5.32s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 179/200 [17:59<02:03,  5.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 179/200 | Train Loss: 3.6845206068392145e-06 | Time: 6.35s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 180/200 [18:04<01:53,  5.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 180/200 | Train Loss: 3.6678052310890052e-06 | Time: 5.26s (cuda) | LR: 4.6116860184273944e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 181/200 [18:11<01:52,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 181/200 | Train Loss: 3.6511689813778503e-06 | Time: 6.5s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 182/200 [18:16<01:43,  5.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 182/200 | Train Loss: 3.4483091440051794e-06 | Time: 5.24s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 183/200 [18:22<01:39,  5.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 183/200 | Train Loss: 3.4178287933173124e-06 | Time: 6.1s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 184/200 [18:28<01:33,  5.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 184/200 | Train Loss: 3.40724704983586e-06 | Time: 5.8s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▎| 185/200 [18:34<01:26,  5.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 185/200 | Train Loss: 3.394984560145531e-06 | Time: 5.59s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 186/200 [18:40<01:23,  5.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 186/200 | Train Loss: 3.3851774787763134e-06 | Time: 6.4s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 187/200 [18:45<01:14,  5.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 187/200 | Train Loss: 3.372001174284378e-06 | Time: 5.24s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 188/200 [18:52<01:11,  5.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 188/200 | Train Loss: 3.3582141441002022e-06 | Time: 6.39s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 189/200 [18:57<01:03,  5.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 189/200 | Train Loss: 3.345701088619535e-06 | Time: 5.35s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 190/200 [19:04<01:00,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 190/200 | Train Loss: 3.334504071972333e-06 | Time: 6.57s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 191/200 [19:09<00:53,  5.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 191/200 | Train Loss: 3.317104528832715e-06 | Time: 5.68s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 192/200 [19:16<00:48,  6.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 192/200 | Train Loss: 3.307384304207517e-06 | Time: 6.46s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▋| 193/200 [19:21<00:40,  5.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 193/200 | Train Loss: 3.29325303027872e-06 | Time: 5.32s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 194/200 [19:27<00:36,  6.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 194/200 | Train Loss: 3.279236580056022e-06 | Time: 6.39s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 195/200 [19:33<00:29,  5.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 195/200 | Train Loss: 3.2624909636069788e-06 | Time: 5.35s (cuda) | LR: 3.689348814741916e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 196/200 [19:39<00:23,  5.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 196/200 | Train Loss: 3.25239852827508e-06 | Time: 5.97s (cuda) | LR: 2.9514790517935326e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 197/200 [19:45<00:17,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 197/200 | Train Loss: 3.0981609597802162e-06 | Time: 6.14s (cuda) | LR: 2.9514790517935326e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 198/200 [19:50<00:11,  5.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 198/200 | Train Loss: 3.0763708309677895e-06 | Time: 5.32s (cuda) | LR: 2.9514790517935326e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 199/200 [19:57<00:05,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 199/200 | Train Loss: 3.0682040232932195e-06 | Time: 6.56s (cuda) | LR: 2.9514790517935326e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [20:02<00:00,  6.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 200/200 | Train Loss: 3.056057266803691e-06 | Time: 5.36s (cuda) | LR: 2.9514790517935326e-07\n",
            "\n",
            "Epoch with Least Loss: 200 | Loss: 3.0560573e-06 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize prediction lists\n",
        "# Initialize prediction lists\n",
        "prediction_list = [[] for _ in range(1)]\n",
        "total_vars=1\n",
        "# Inference loop\n",
        "model_mean = MyResidualSirenNet(obj).to(device)\n",
        "state_dict = torch.load(os.path.join(outpath, '200_std.pth'))['model_state_dict']\n",
        "model_mean.load_state_dict(state_dict)\n",
        "with torch.no_grad():\n",
        "    for i in range(0, torch_coords.shape[0], group_size):\n",
        "        coords = torch_coords[i:min(i + group_size, torch_coords.shape[0])].type(torch.float32).to(device)\n",
        "        vals = model_mean(coords)\n",
        "        vals = vals.to('cpu')\n",
        "\n",
        "        for j in range(total_vars):\n",
        "            prediction_list[j].append(vals[:, j])\n",
        "\n",
        "# Extract and concatenate predictions\n",
        "extracted_list = [[] for _ in range(1)]\n",
        "for i in range(len(prediction_list[0])):\n",
        "    for j in range(1):\n",
        "        el = prediction_list[j][i].detach().numpy()\n",
        "        extracted_list[j].append(el)\n",
        "\n",
        "for j in range(1):\n",
        "    extracted_list[j] = np.concatenate(extracted_list[j], dtype='float32')\n",
        "\n",
        "# Final prediction (normalized)\n",
        "n_predictions_stds = np.array(extracted_list).T\n",
        "print(n_predictions_stds.shape)\n",
        "# Compute PSNR\n",
        "#findMultiVariatePSNR(var_name[0], total_vars, n_val[:,0], n_predictions_means[:,0])\n",
        "print(\"std\",compute_PSNR(n_val[:,1],n_predictions_stds[:,0]))\n",
        "# Compute RMSE\n",
        "rmse = compute_rmse(n_val[:,1], n_predictions_stds[:,0])\n",
        "print(\"RMSE:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZbOQXB_kwk5",
        "outputId": "0033869e-7a16-460c-f375-be1ca074cf80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(262144, 1)\n",
            "std 61.882343845798715\n",
            "RMSE: 0.001610322285992644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_predictions = np.concatenate([n_predictions_means, n_predictions_stds], axis=1)\n",
        "# !rm -rf /kaggle/working/*"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-26T20:39:05.386663Z",
          "iopub.execute_input": "2025-05-26T20:39:05.386998Z",
          "iopub.status.idle": "2025-05-26T20:39:05.390530Z",
          "shell.execute_reply.started": "2025-05-26T20:39:05.386966Z",
          "shell.execute_reply": "2025-05-26T20:39:05.389710Z"
        },
        "id": "_CEE5B8g5lmT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.path.getsize('/kaggle/working/models/train_3d_data_200ep_6rb_320n_512bs_5e-05lr_Truedecay_0.8dr_decayingAtInterval15.pth') / (1024 ** 2), 'MB')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-26T20:42:22.099537Z",
          "iopub.execute_input": "2025-05-26T20:42:22.099844Z",
          "iopub.status.idle": "2025-05-26T20:42:22.105129Z",
          "shell.execute_reply.started": "2025-05-26T20:42:22.099821Z",
          "shell.execute_reply": "2025-05-26T20:42:22.104165Z"
        },
        "id": "6UBTlK7L5lmT",
        "outputId": "69ceab23-5b68-44f6-bd71-ecdd8769add2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "4.731752395629883 MB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # vti saving path\n",
        "vti_path = args.vti_path\n",
        "if not os.path.exists(vti_path):\n",
        "    os.makedirs(vti_path)\n",
        "# vti name\n",
        "vti_name = args.vti_name\n",
        "isMaskPresent = False\n",
        "mask_arr = []\n",
        "total_vars=2\n",
        "makeVTI(data,real_data, n_predictions, n_pts, total_vars, var_name, dim, isMaskPresent, mask_arr, vti_path, vti_name)"
      ],
      "metadata": {
        "_uuid": "8987b9b8-de2f-448c-995c-28bee1a033eb",
        "_cell_guid": "6f9d6b16-aa9c-4808-81e8-a4d1e00459d2",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-05-26T20:39:05.443004Z",
          "iopub.status.idle": "2025-05-26T20:39:05.443267Z",
          "shell.execute_reply": "2025-05-26T20:39:05.443158Z"
        },
        "id": "htWe2iW35lmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc342256-30c6-4bed-fb73-3cd3cbc1d7a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vti File written successfully at ./data/predicted.vti\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1tNS_Rattjqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KI_p5bplWePx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}