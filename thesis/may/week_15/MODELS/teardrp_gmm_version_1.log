nohup: ignoring input
Using device: cuda
Training started
Epoch 0 | Loss: 0.013211 | LR: 0.000050
Epoch 1 | Loss: 0.011461 | LR: 0.000050
Epoch 2 | Loss: 0.011413 | LR: 0.000050
Epoch 3 | Loss: 0.011405 | LR: 0.000050
Epoch 4 | Loss: 0.011381 | LR: 0.000050
Epoch 5 | Loss: 0.011382 | LR: 0.000050
Epoch 6 | Loss: 0.011376 | LR: 0.000050
Epoch 7 | Loss: 0.011359 | LR: 0.000050
Epoch 8 | Loss: 0.011356 | LR: 0.000050
Epoch 9 | Loss: 0.011346 | LR: 0.000050
Epoch 10 | Loss: 0.011319 | LR: 0.000050
Epoch 11 | Loss: 0.011312 | LR: 0.000050
Epoch 12 | Loss: 0.011287 | LR: 0.000050
Epoch 13 | Loss: 0.011281 | LR: 0.000050
Epoch 14 | Loss: 0.011259 | LR: 0.000040
Epoch 15 | Loss: 0.011212 | LR: 0.000040
Epoch 16 | Loss: 0.011174 | LR: 0.000040
Epoch 17 | Loss: 0.011151 | LR: 0.000040
Epoch 18 | Loss: 0.011126 | LR: 0.000040
Epoch 19 | Loss: 0.011101 | LR: 0.000040
Epoch 20 | Loss: 0.011076 | LR: 0.000040
Epoch 21 | Loss: 0.011049 | LR: 0.000040
Epoch 22 | Loss: 0.011029 | LR: 0.000040
Epoch 23 | Loss: 0.011013 | LR: 0.000040
Epoch 24 | Loss: 0.010992 | LR: 0.000040
Epoch 25 | Loss: 0.010977 | LR: 0.000040
Epoch 26 | Loss: 0.010961 | LR: 0.000040
Epoch 27 | Loss: 0.010940 | LR: 0.000040
Epoch 28 | Loss: 0.010927 | LR: 0.000040
Epoch 29 | Loss: 0.010917 | LR: 0.000032
Epoch 30 | Loss: 0.010817 | LR: 0.000032
Epoch 31 | Loss: 0.010778 | LR: 0.000032
Epoch 32 | Loss: 0.010749 | LR: 0.000032
Epoch 33 | Loss: 0.010721 | LR: 0.000032
Epoch 34 | Loss: 0.010696 | LR: 0.000032
Epoch 35 | Loss: 0.010677 | LR: 0.000032
Epoch 36 | Loss: 0.010656 | LR: 0.000032
Epoch 37 | Loss: 0.010640 | LR: 0.000032
Epoch 38 | Loss: 0.010625 | LR: 0.000032
Epoch 39 | Loss: 0.010612 | LR: 0.000032
Epoch 40 | Loss: 0.010600 | LR: 0.000032
Epoch 41 | Loss: 0.010586 | LR: 0.000032
Epoch 42 | Loss: 0.010577 | LR: 0.000032
Epoch 43 | Loss: 0.010567 | LR: 0.000032
Epoch 44 | Loss: 0.010557 | LR: 0.000026
Epoch 45 | Loss: 0.010442 | LR: 0.000026
Epoch 46 | Loss: 0.010406 | LR: 0.000026
Epoch 47 | Loss: 0.010385 | LR: 0.000026
Epoch 48 | Loss: 0.010364 | LR: 0.000026
Epoch 49 | Loss: 0.010350 | LR: 0.000026
Epoch 50 | Loss: 0.010334 | LR: 0.000026
Epoch 51 | Loss: 0.010324 | LR: 0.000026
Epoch 52 | Loss: 0.010313 | LR: 0.000026
Epoch 53 | Loss: 0.010301 | LR: 0.000026
Epoch 54 | Loss: 0.010291 | LR: 0.000026
Epoch 55 | Loss: 0.010280 | LR: 0.000026
Epoch 56 | Loss: 0.010275 | LR: 0.000026
Epoch 57 | Loss: 0.010265 | LR: 0.000026
Epoch 58 | Loss: 0.010258 | LR: 0.000026
Epoch 59 | Loss: 0.010252 | LR: 0.000020
Epoch 60 | Loss: 0.010131 | LR: 0.000020
Epoch 61 | Loss: 0.010105 | LR: 0.000020
Epoch 62 | Loss: 0.010088 | LR: 0.000020
Epoch 63 | Loss: 0.010073 | LR: 0.000020
Epoch 64 | Loss: 0.010062 | LR: 0.000020
Epoch 65 | Loss: 0.010050 | LR: 0.000020
Epoch 66 | Loss: 0.010042 | LR: 0.000020
Epoch 67 | Loss: 0.010034 | LR: 0.000020
Epoch 68 | Loss: 0.010026 | LR: 0.000020
Epoch 69 | Loss: 0.010020 | LR: 0.000020
Epoch 70 | Loss: 0.010013 | LR: 0.000020
Epoch 71 | Loss: 0.010008 | LR: 0.000020
Epoch 72 | Loss: 0.010001 | LR: 0.000020
Epoch 73 | Loss: 0.009997 | LR: 0.000020
Epoch 74 | Loss: 0.009989 | LR: 0.000016
Epoch 75 | Loss: 0.009875 | LR: 0.000016
Epoch 76 | Loss: 0.009854 | LR: 0.000016
Epoch 77 | Loss: 0.009841 | LR: 0.000016
Epoch 78 | Loss: 0.009829 | LR: 0.000016
Epoch 79 | Loss: 0.009821 | LR: 0.000016
Epoch 80 | Loss: 0.009813 | LR: 0.000016
Epoch 81 | Loss: 0.009808 | LR: 0.000016
Epoch 82 | Loss: 0.009800 | LR: 0.000016
Epoch 83 | Loss: 0.009794 | LR: 0.000016
Epoch 84 | Loss: 0.009789 | LR: 0.000016
Epoch 85 | Loss: 0.009785 | LR: 0.000016
Epoch 86 | Loss: 0.009779 | LR: 0.000016
Epoch 87 | Loss: 0.009777 | LR: 0.000016
Epoch 88 | Loss: 0.009771 | LR: 0.000016
Epoch 89 | Loss: 0.009767 | LR: 0.000013
Epoch 90 | Loss: 0.009662 | LR: 0.000013
Epoch 91 | Loss: 0.009645 | LR: 0.000013
Epoch 92 | Loss: 0.009635 | LR: 0.000013
Epoch 93 | Loss: 0.009629 | LR: 0.000013
Epoch 94 | Loss: 0.009623 | LR: 0.000013
Epoch 95 | Loss: 0.009616 | LR: 0.000013
Epoch 96 | Loss: 0.009611 | LR: 0.000013
Epoch 97 | Loss: 0.009604 | LR: 0.000013
Epoch 98 | Loss: 0.009602 | LR: 0.000013
Epoch 99 | Loss: 0.009598 | LR: 0.000013
Epoch 100 | Loss: 0.009593 | LR: 0.000013
Epoch 101 | Loss: 0.009590 | LR: 0.000013
Epoch 102 | Loss: 0.009588 | LR: 0.000013
Epoch 103 | Loss: 0.009583 | LR: 0.000013
Epoch 104 | Loss: 0.009581 | LR: 0.000010
Epoch 105 | Loss: 0.009486 | LR: 0.000010
Epoch 106 | Loss: 0.009474 | LR: 0.000010
Epoch 107 | Loss: 0.009466 | LR: 0.000010
Epoch 108 | Loss: 0.009460 | LR: 0.000010
Epoch 109 | Loss: 0.009456 | LR: 0.000010
Epoch 110 | Loss: 0.009450 | LR: 0.000010
Epoch 111 | Loss: 0.009448 | LR: 0.000010
Epoch 112 | Loss: 0.009444 | LR: 0.000010
Epoch 113 | Loss: 0.009440 | LR: 0.000010
Epoch 114 | Loss: 0.009439 | LR: 0.000010
Epoch 115 | Loss: 0.009433 | LR: 0.000010
Epoch 116 | Loss: 0.009434 | LR: 0.000010
Epoch 117 | Loss: 0.009429 | LR: 0.000010
Epoch 118 | Loss: 0.009427 | LR: 0.000010
Epoch 119 | Loss: 0.009422 | LR: 0.000008
Epoch 120 | Loss: 0.009341 | LR: 0.000008
Epoch 121 | Loss: 0.009332 | LR: 0.000008
Epoch 122 | Loss: 0.009327 | LR: 0.000008
Epoch 123 | Loss: 0.009323 | LR: 0.000008
Epoch 124 | Loss: 0.009318 | LR: 0.000008
Epoch 125 | Loss: 0.009316 | LR: 0.000008
Epoch 126 | Loss: 0.009314 | LR: 0.000008
Epoch 127 | Loss: 0.009311 | LR: 0.000008
Epoch 128 | Loss: 0.009307 | LR: 0.000008
Epoch 129 | Loss: 0.009306 | LR: 0.000008
Epoch 130 | Loss: 0.009303 | LR: 0.000008
Epoch 131 | Loss: 0.009301 | LR: 0.000008
Epoch 132 | Loss: 0.009300 | LR: 0.000008
Epoch 133 | Loss: 0.009298 | LR: 0.000008
Epoch 134 | Loss: 0.009294 | LR: 0.000007
Epoch 135 | Loss: 0.009225 | LR: 0.000007
Epoch 136 | Loss: 0.009215 | LR: 0.000007
Epoch 137 | Loss: 0.009213 | LR: 0.000007
Epoch 138 | Loss: 0.009209 | LR: 0.000007
Epoch 139 | Loss: 0.009206 | LR: 0.000007
Epoch 140 | Loss: 0.009204 | LR: 0.000007
Epoch 141 | Loss: 0.009202 | LR: 0.000007
Epoch 142 | Loss: 0.009200 | LR: 0.000007
Epoch 143 | Loss: 0.009198 | LR: 0.000007
Epoch 144 | Loss: 0.009197 | LR: 0.000007
Epoch 145 | Loss: 0.009195 | LR: 0.000007
Epoch 146 | Loss: 0.009193 | LR: 0.000007
Epoch 147 | Loss: 0.009192 | LR: 0.000007
Epoch 148 | Loss: 0.009190 | LR: 0.000007
Epoch 149 | Loss: 0.009188 | LR: 0.000005
Epoch 150 | Loss: 0.009127 | LR: 0.000005
Epoch 151 | Loss: 0.009121 | LR: 0.000005
Epoch 152 | Loss: 0.009119 | LR: 0.000005
Epoch 153 | Loss: 0.009117 | LR: 0.000005
Epoch 154 | Loss: 0.009116 | LR: 0.000005
Epoch 155 | Loss: 0.009113 | LR: 0.000005
Epoch 156 | Loss: 0.009111 | LR: 0.000005
Epoch 157 | Loss: 0.009109 | LR: 0.000005
Epoch 158 | Loss: 0.009108 | LR: 0.000005
Epoch 159 | Loss: 0.009107 | LR: 0.000005
Epoch 160 | Loss: 0.009106 | LR: 0.000005
Epoch 161 | Loss: 0.009104 | LR: 0.000005
Epoch 162 | Loss: 0.009103 | LR: 0.000005
Epoch 163 | Loss: 0.009102 | LR: 0.000005
Epoch 164 | Loss: 0.009101 | LR: 0.000004
Epoch 165 | Loss: 0.009049 | LR: 0.000004
Epoch 166 | Loss: 0.009044 | LR: 0.000004
Epoch 167 | Loss: 0.009041 | LR: 0.000004
Epoch 168 | Loss: 0.009041 | LR: 0.000004
Epoch 169 | Loss: 0.009038 | LR: 0.000004
Epoch 170 | Loss: 0.009038 | LR: 0.000004
Epoch 171 | Loss: 0.009037 | LR: 0.000004
Epoch 172 | Loss: 0.009035 | LR: 0.000004
Epoch 173 | Loss: 0.009035 | LR: 0.000004
Epoch 174 | Loss: 0.009034 | LR: 0.000004
Epoch 175 | Loss: 0.009033 | LR: 0.000004
Epoch 176 | Loss: 0.009031 | LR: 0.000004
Epoch 177 | Loss: 0.009030 | LR: 0.000004
Epoch 178 | Loss: 0.009029 | LR: 0.000004
Epoch 179 | Loss: 0.009029 | LR: 0.000003
Epoch 180 | Loss: 0.008985 | LR: 0.000003
Epoch 181 | Loss: 0.008981 | LR: 0.000003
Epoch 182 | Loss: 0.008980 | LR: 0.000003
Epoch 183 | Loss: 0.008979 | LR: 0.000003
Epoch 184 | Loss: 0.008977 | LR: 0.000003
Epoch 185 | Loss: 0.008977 | LR: 0.000003
Epoch 186 | Loss: 0.008976 | LR: 0.000003
Epoch 187 | Loss: 0.008975 | LR: 0.000003
Epoch 188 | Loss: 0.008975 | LR: 0.000003
Epoch 189 | Loss: 0.008973 | LR: 0.000003
Epoch 190 | Loss: 0.008973 | LR: 0.000003
Epoch 191 | Loss: 0.008972 | LR: 0.000003
Epoch 192 | Loss: 0.008971 | LR: 0.000003
Epoch 193 | Loss: 0.008970 | LR: 0.000003
Epoch 194 | Loss: 0.008969 | LR: 0.000003
Epoch 195 | Loss: 0.008933 | LR: 0.000003
Epoch 196 | Loss: 0.008930 | LR: 0.000003
Epoch 197 | Loss: 0.008929 | LR: 0.000003
Epoch 198 | Loss: 0.008928 | LR: 0.000003
Epoch 199 | Loss: 0.008928 | LR: 0.000003
Epoch 200 | Loss: 0.008926 | LR: 0.000003
Epoch 201 | Loss: 0.008925 | LR: 0.000003
Epoch 202 | Loss: 0.008925 | LR: 0.000003
Epoch 203 | Loss: 0.008925 | LR: 0.000003
Epoch 204 | Loss: 0.008924 | LR: 0.000003
Epoch 205 | Loss: 0.008923 | LR: 0.000003
Epoch 206 | Loss: 0.008923 | LR: 0.000003
Epoch 207 | Loss: 0.008921 | LR: 0.000003
Epoch 208 | Loss: 0.008921 | LR: 0.000003
Epoch 209 | Loss: 0.008920 | LR: 0.000002
Epoch 210 | Loss: 0.008890 | LR: 0.000002
Epoch 211 | Loss: 0.008887 | LR: 0.000002
Epoch 212 | Loss: 0.008887 | LR: 0.000002
Epoch 213 | Loss: 0.008887 | LR: 0.000002
Epoch 214 | Loss: 0.008886 | LR: 0.000002
Epoch 215 | Loss: 0.008885 | LR: 0.000002
Epoch 216 | Loss: 0.008885 | LR: 0.000002
Epoch 217 | Loss: 0.008884 | LR: 0.000002
Epoch 218 | Loss: 0.008884 | LR: 0.000002
Epoch 219 | Loss: 0.008883 | LR: 0.000002
Epoch 220 | Loss: 0.008883 | LR: 0.000002
Epoch 221 | Loss: 0.008882 | LR: 0.000002
Epoch 222 | Loss: 0.008882 | LR: 0.000002
Epoch 223 | Loss: 0.008881 | LR: 0.000002
Epoch 224 | Loss: 0.008881 | LR: 0.000002
Epoch 225 | Loss: 0.008856 | LR: 0.000002
Epoch 226 | Loss: 0.008853 | LR: 0.000002
Epoch 227 | Loss: 0.008853 | LR: 0.000002
Epoch 228 | Loss: 0.008852 | LR: 0.000002
Epoch 229 | Loss: 0.008852 | LR: 0.000002
Epoch 230 | Loss: 0.008851 | LR: 0.000002
Epoch 231 | Loss: 0.008851 | LR: 0.000002
Epoch 232 | Loss: 0.008850 | LR: 0.000002
Epoch 233 | Loss: 0.008850 | LR: 0.000002
Epoch 234 | Loss: 0.008849 | LR: 0.000002
Epoch 235 | Loss: 0.008849 | LR: 0.000002
Epoch 236 | Loss: 0.008849 | LR: 0.000002
Epoch 237 | Loss: 0.008848 | LR: 0.000002
Epoch 238 | Loss: 0.008848 | LR: 0.000002
Epoch 239 | Loss: 0.008848 | LR: 0.000001
Epoch 240 | Loss: 0.008827 | LR: 0.000001
Epoch 241 | Loss: 0.008825 | LR: 0.000001
Epoch 242 | Loss: 0.008824 | LR: 0.000001
Epoch 243 | Loss: 0.008824 | LR: 0.000001
Epoch 244 | Loss: 0.008824 | LR: 0.000001
Epoch 245 | Loss: 0.008824 | LR: 0.000001
Epoch 246 | Loss: 0.008823 | LR: 0.000001
Epoch 247 | Loss: 0.008823 | LR: 0.000001
Epoch 248 | Loss: 0.008823 | LR: 0.000001
Epoch 249 | Loss: 0.008822 | LR: 0.000001
Epoch 250 | Loss: 0.008822 | LR: 0.000001
Epoch 251 | Loss: 0.008821 | LR: 0.000001
Epoch 252 | Loss: 0.008821 | LR: 0.000001
Epoch 253 | Loss: 0.008821 | LR: 0.000001
Epoch 254 | Loss: 0.008821 | LR: 0.000001
Epoch 255 | Loss: 0.008803 | LR: 0.000001
Epoch 256 | Loss: 0.008802 | LR: 0.000001
Epoch 257 | Loss: 0.008802 | LR: 0.000001
Epoch 258 | Loss: 0.008801 | LR: 0.000001
Epoch 259 | Loss: 0.008801 | LR: 0.000001
Epoch 260 | Loss: 0.008801 | LR: 0.000001
Epoch 261 | Loss: 0.008801 | LR: 0.000001
Epoch 262 | Loss: 0.008800 | LR: 0.000001
Epoch 263 | Loss: 0.008800 | LR: 0.000001
Epoch 264 | Loss: 0.008800 | LR: 0.000001
Epoch 265 | Loss: 0.008799 | LR: 0.000001
Epoch 266 | Loss: 0.008799 | LR: 0.000001
Epoch 267 | Loss: 0.008799 | LR: 0.000001
Epoch 268 | Loss: 0.008799 | LR: 0.000001
Epoch 269 | Loss: 0.008798 | LR: 0.000001
Epoch 270 | Loss: 0.008784 | LR: 0.000001
Epoch 271 | Loss: 0.008783 | LR: 0.000001
Epoch 272 | Loss: 0.008783 | LR: 0.000001
Epoch 273 | Loss: 0.008783 | LR: 0.000001
Epoch 274 | Loss: 0.008782 | LR: 0.000001
Epoch 275 | Loss: 0.008782 | LR: 0.000001
Epoch 276 | Loss: 0.008782 | LR: 0.000001
Epoch 277 | Loss: 0.008782 | LR: 0.000001
Epoch 278 | Loss: 0.008782 | LR: 0.000001
Epoch 279 | Loss: 0.008781 | LR: 0.000001
Epoch 280 | Loss: 0.008781 | LR: 0.000001
Epoch 281 | Loss: 0.008781 | LR: 0.000001
Epoch 282 | Loss: 0.008781 | LR: 0.000001
Epoch 283 | Loss: 0.008780 | LR: 0.000001
Epoch 284 | Loss: 0.008780 | LR: 0.000001
Epoch 285 | Loss: 0.008768 | LR: 0.000001
Epoch 286 | Loss: 0.008768 | LR: 0.000001
Epoch 287 | Loss: 0.008767 | LR: 0.000001
Epoch 288 | Loss: 0.008767 | LR: 0.000001
Epoch 289 | Loss: 0.008767 | LR: 0.000001
Epoch 290 | Loss: 0.008767 | LR: 0.000001
Epoch 291 | Loss: 0.008767 | LR: 0.000001
Epoch 292 | Loss: 0.008767 | LR: 0.000001
Epoch 293 | Loss: 0.008766 | LR: 0.000001
Epoch 294 | Loss: 0.008766 | LR: 0.000001
Epoch 295 | Loss: 0.008766 | LR: 0.000001
Epoch 296 | Loss: 0.008766 | LR: 0.000001
Epoch 297 | Loss: 0.008766 | LR: 0.000001
Epoch 298 | Loss: 0.008766 | LR: 0.000001
Epoch 299 | Loss: 0.008765 | LR: 0.000001
Epoch 300 | Loss: 0.008755 | LR: 0.000001
Training complete in 165m 38s
PSNR: 26.62, RMSE: 0.0934
PSNR vs Original File: 23.42, RMSE: 0.1348
Loading combined VTI...
Loading model...
Traceback (most recent call last):
  File "/home/tsudhakar/teardrop/Knowledge_Distillation_v1.py", line 305, in <module>
    state = torch.load(args.model_path, map_location=device)
                       ^^^^^^^^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'model_path'
